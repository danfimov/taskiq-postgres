{"config":{"lang":["ru"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":"<p>PostgreSQL integration for Taskiq with support for asyncpg, psqlpy, psycopg and aiopg drivers.</p>"},{"location":"#motivation","title":"Motivation","text":"<p>There are too many libraries for PostgreSQL and Taskiq integration. Although they have different view on interface and different functionality. To address this issue I created this library with a common interface for most popular PostgreSQL drivers that handle similarity across functionality of:</p> <ul> <li>result backends;</li> <li>brokers;</li> <li>schedule sources.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Depending on your preferred PostgreSQL driver, you can install this library with the corresponding extra:</p> asyncpgpsqlpypsycopgaiopg <pre><code>pip install taskiq-postgres[asyncpg]\n</code></pre> <pre><code>pip install taskiq-postgres[psqlpy]\n</code></pre> <pre><code>pip install taskiq-postgres[psycopg]\n</code></pre> <pre><code>pip install taskiq-postgres[aiopg]\n</code></pre>"},{"location":"#quick-start","title":"Quick start","text":""},{"location":"#basic-task-processing","title":"Basic task processing","text":"<ol> <li> <p>Define your broker:</p> asyncpgpsqlpypsycopgaiopg <pre><code># broker_example.py\nimport asyncio\nfrom taskiq_pg.asyncpg import AsyncpgBroker, AsyncpgResultBackend\n\n\ndsn = \"postgres://taskiq_postgres:look_in_vault@localhost:5432/taskiq_postgres\"\nbroker = AsyncpgBroker(dsn).with_result_backend(AsyncpgResultBackend(dsn))\n\n\n@broker.task(\"solve_all_problems\")\nasync def best_task_ever() -&gt; None:\n    \"\"\"Solve all problems in the world.\"\"\"\n    await asyncio.sleep(2)\n    print(\"All problems are solved!\")\n\n\nasync def main():\n    await broker.startup()\n    task = await best_task_ever.kiq()\n    print(await task.wait_result())\n    await broker.shutdown()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <pre><code># broker_example.py\nimport asyncio\nfrom taskiq_pg.psqlpy import PSQLPyBroker, PSQLPyResultBackend\n\n\ndsn = \"postgres://taskiq_postgres:look_in_vault@localhost:5432/taskiq_postgres\"\nbroker = PSQLPyBroker(dsn).with_result_backend(PSQLPyResultBackend(dsn))\n\n\n@broker.task(\"solve_all_problems\")\nasync def best_task_ever() -&gt; None:\n    \"\"\"Solve all problems in the world.\"\"\"\n    await asyncio.sleep(2)\n    print(\"All problems are solved!\")\n\n\nasync def main():\n    await broker.startup()\n    task = await best_task_ever.kiq()\n    print(await task.wait_result())\n    await broker.shutdown()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <pre><code># broker_example.py\nimport asyncio\nfrom taskiq_pg.psycopg import PsycopgBroker, PsycopgResultBackend\n\n\ndsn = \"postgres://taskiq_postgres:look_in_vault@localhost:5432/taskiq_postgres\"\nbroker = PsycopgBroker(dsn).with_result_backend(PsycopgResultBackend(dsn))\n\n\n@broker.task(\"solve_all_problems\")\nasync def best_task_ever() -&gt; None:\n    \"\"\"Solve all problems in the world.\"\"\"\n    await asyncio.sleep(2)\n    print(\"All problems are solved!\")\n\n\nasync def main():\n    await broker.startup()\n    task = await best_task_ever.kiq()\n    print(await task.wait_result())\n    await broker.shutdown()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <pre><code># broker_example.py\nimport asyncio\nfrom taskiq_pg.aiopg import AiopgBroker, AiopgResultBackend\n\n\ndsn = \"postgres://taskiq_postgres:look_in_vault@localhost:5432/taskiq_postgres\"\nbroker = AiopgBroker(dsn).with_result_backend(AiopgResultBackend(dsn))\n\n\n@broker.task(\"solve_all_problems\")\nasync def best_task_ever() -&gt; None:\n    \"\"\"Solve all problems in the world.\"\"\"\n    await asyncio.sleep(2)\n    print(\"All problems are solved!\")\n\n\nasync def main():\n    await broker.startup()\n    task = await best_task_ever.kiq()\n    print(await task.wait_result())\n    await broker.shutdown()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> </li> <li> <p>Start a worker to process tasks (by default taskiq runs two instances of worker):</p> <pre><code>taskiq worker broker_example:broker\n</code></pre> </li> <li> <p>Run <code>broker_example.py</code> file to send a task to the worker:</p> <pre><code>python broker_example.py\n</code></pre> </li> </ol> <p>Your experience with other drivers will be pretty similar. Just change the import statement and that's it.</p>"},{"location":"#task-scheduling","title":"Task scheduling","text":"<ol> <li> <p>Define your broker and schedule source:</p> asyncpgpsqlpypsycopgaiopg <pre><code># scheduler_example.py\nimport asyncio\nfrom taskiq import TaskiqScheduler\nfrom taskiq_pg.asyncpg import AsyncpgBroker, AsyncpgScheduleSource\n\n\ndsn = \"postgres://taskiq_postgres:look_in_vault@localhost:5432/taskiq_postgres\"\nbroker = AsyncpgBroker(dsn)\nscheduler = TaskiqScheduler(\n    broker=broker,\n    sources=[AsyncpgScheduleSource(\n        dsn=dsn,\n        broker=broker,\n    )],\n)\n\n\n@broker.task(\n    task_name=\"solve_all_problems\",\n    schedule=[\n        {\n            \"cron\": \"*/1 * * * *\",  # type: str, either cron or time should be specified.\n            \"cron_offset\": None,  # type: str | None, can be omitted.\n            \"time\": None,  # type: datetime | None, either cron or time should be specified.\n            \"args\": [], # type list[Any] | None, can be omitted.\n            \"kwargs\": {}, # type: dict[str, Any] | None, can be omitted.\n            \"labels\": {}, # type: dict[str, Any] | None, can be omitted.\n        },\n    ],\n)\nasync def best_task_ever() -&gt; None:\n    \"\"\"Solve all problems in the world.\"\"\"\n    await asyncio.sleep(2)\n    print(\"All problems are solved!\")\n</code></pre> <pre><code># scheduler_example.py\nimport asyncio\nfrom taskiq import TaskiqScheduler\nfrom taskiq_pg.psqlpy import PSQLPyBroker, PSQLPyScheduleSource\n\n\ndsn = \"postgres://taskiq_postgres:look_in_vault@localhost:5432/taskiq_postgres\"\nbroker = PSQLPyBroker(dsn)\nscheduler = TaskiqScheduler(\n    broker=broker,\n    sources=[PSQLPyScheduleSource(\n        dsn=dsn,\n        broker=broker,\n    )],\n)\n\n\n@broker.task(\n    task_name=\"solve_all_problems\",\n    schedule=[\n        {\n            \"cron\": \"*/1 * * * *\",  # type: str, either cron or time should be specified.\n            \"cron_offset\": None,  # type: str | None, can be omitted.\n            \"time\": None,  # type: datetime | None, either cron or time should be specified.\n            \"args\": [], # type list[Any] | None, can be omitted.\n            \"kwargs\": {}, # type: dict[str, Any] | None, can be omitted.\n            \"labels\": {}, # type: dict[str, Any] | None, can be omitted.\n        },\n    ],\n)\nasync def best_task_ever() -&gt; None:\n    \"\"\"Solve all problems in the world.\"\"\"\n    await asyncio.sleep(2)\n    print(\"All problems are solved!\")\n</code></pre> <pre><code># scheduler_example.py\nimport asyncio\nfrom taskiq import TaskiqScheduler\nfrom taskiq_pg.psycopg import PsycopgBroker, PsycopgScheduleSource\n\n\ndsn = \"postgres://taskiq_postgres:look_in_vault@localhost:5432/taskiq_postgres\"\nbroker = PsycopgBroker(dsn)\nscheduler = TaskiqScheduler(\n    broker=broker,\n    sources=[PsycopgScheduleSource(\n        dsn=dsn,\n        broker=broker,\n    )],\n)\n\n\n@broker.task(\n    task_name=\"solve_all_problems\",\n    schedule=[\n        {\n            \"cron\": \"*/1 * * * *\",  # type: str, either cron or time should be specified.\n            \"cron_offset\": None,  # type: str | None, can be omitted.\n            \"time\": None,  # type: datetime | None, either cron or time should be specified.\n            \"args\": [], # type list[Any] | None, can be omitted.\n            \"kwargs\": {}, # type: dict[str, Any] | None, can be omitted.\n            \"labels\": {}, # type: dict[str, Any] | None, can be omitted.\n        },\n    ],\n)\nasync def best_task_ever() -&gt; None:\n    \"\"\"Solve all problems in the world.\"\"\"\n    await asyncio.sleep(2)\n    print(\"All problems are solved!\")\n</code></pre> <pre><code># scheduler_example.py\nimport asyncio\nfrom taskiq import TaskiqScheduler\nfrom taskiq_pg.aiopg import AiopgBroker, AiopgScheduleSource\n\n\ndsn = \"postgres://taskiq_postgres:look_in_vault@localhost:5432/taskiq_postgres\"\nbroker = AiopgBroker(dsn)\nscheduler = TaskiqScheduler(\n    broker=broker,\n    sources=[AiopgScheduleSource(\n        dsn=dsn,\n        broker=broker,\n    )],\n)\n\n\n@broker.task(\n    task_name=\"solve_all_problems\",\n    schedule=[\n        {\n            \"cron\": \"*/1 * * * *\",  # type: str, either cron or time should be specified.\n            \"cron_offset\": None,  # type: str | None, can be omitted.\n            \"time\": None,  # type: datetime | None, either cron or time should be specified.\n            \"args\": [], # type list[Any] | None, can be omitted.\n            \"kwargs\": {}, # type: dict[str, Any] | None, can be omitted.\n            \"labels\": {}, # type: dict[str, Any] | None, can be omitted.\n        },\n    ],\n)\nasync def best_task_ever() -&gt; None:\n    \"\"\"Solve all problems in the world.\"\"\"\n    await asyncio.sleep(2)\n    print(\"All problems are solved!\")\n</code></pre> </li> <li> <p>Start worker processes:</p> <pre><code>taskiq worker scheduler_example:broker\n</code></pre> </li> <li> <p>Run scheduler process:</p> <pre><code>taskiq scheduler scheduler_example:scheduler\n</code></pre> </li> </ol>"},{"location":"contributing/","title":"Contributing and Development","text":""},{"location":"contributing/#development","title":"Development","text":"<p>This project uses modern Python development tools:</p> <ul> <li>uv \u2014 fast Python package installer and resolver</li> <li>ruff \u2014 extremely fast Python linter and formatter</li> </ul>"},{"location":"contributing/#setup-development-environment","title":"Setup Development Environment","text":"<pre><code># Clone the repository\ngit clone https://github.com/danfimov/taskiq-postgres.git\ncd taskiq-postgres\n\n# Create a virtual environment (optional but recommended)\nmake venv\n\n# Install dependencies\nmake init\n</code></pre> <p>You can see other useful commands by running <code>make help</code>.</p>"},{"location":"contributing/#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please:</p> <ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Add tests for new functionality</li> <li>Ensure all tests pass</li> <li>Submit a pull request</li> </ol>"},{"location":"reference/","title":"API","text":""},{"location":"reference/#taskiq_pg","title":"taskiq_pg","text":""},{"location":"reference/#taskiq_pg.aiopg","title":"aiopg","text":""},{"location":"reference/#taskiq_pg.aiopg.AiopgResultBackend","title":"AiopgResultBackend","text":"<pre><code>AiopgResultBackend(\n    dsn=\"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results=True,\n    table_name=\"taskiq_results\",\n    field_for_task_id=\"VarChar\",\n    serializer=None,\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresResultBackend</code></p> <p>Result backend for TaskIQ based on Aiopg.</p> <p>Construct new result backend.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>Callable[[], str] | str | None</code>, default:                   <code>'postgres://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>connection string to PostgreSQL, or callable returning one.</p> </li> <li> <code>keep_results</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>flag to not remove results from the database after reading.</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_results'</code> )           \u2013            <p>name of the table to store results.</p> </li> <li> <code>field_for_task_id</code>               (<code>Literal['VarChar', 'Text', 'Uuid']</code>, default:                   <code>'VarChar'</code> )           \u2013            <p>type of the field to store task_id.</p> </li> <li> <code>serializer</code>               (<code>TaskiqSerializer | None</code>, default:                   <code>None</code> )           \u2013            <p>serializer class to serialize/deserialize result from task.</p> </li> <li> <code>connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>additional arguments for creating connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/result_backend.py</code> <pre><code>def __init__(\n    self,\n    dsn: tp.Callable[[], str] | str | None = \"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results: bool = True,\n    table_name: str = \"taskiq_results\",\n    field_for_task_id: tp.Literal[\"VarChar\", \"Text\", \"Uuid\"] = \"VarChar\",\n    serializer: TaskiqSerializer | None = None,\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Construct new result backend.\n\n    Args:\n        dsn: connection string to PostgreSQL, or callable returning one.\n        keep_results: flag to not remove results from the database after reading.\n        table_name: name of the table to store results.\n        field_for_task_id: type of the field to store task_id.\n        serializer: serializer class to serialize/deserialize result from task.\n        connect_kwargs: additional arguments for creating connection pool.\n\n    \"\"\"\n    self._dsn: tp.Final = dsn\n    self.keep_results: tp.Final = keep_results\n    self.table_name: tp.Final = table_name\n    self.field_for_task_id: tp.Final = field_for_task_id\n    self.connect_kwargs: tp.Final = connect_kwargs\n    self.serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgResultBackend.keep_results","title":"keep_results  <code>instance-attribute</code>","text":"<pre><code>keep_results = keep_results\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgResultBackend.table_name","title":"table_name  <code>instance-attribute</code>","text":"<pre><code>table_name = table_name\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgResultBackend.field_for_task_id","title":"field_for_task_id  <code>instance-attribute</code>","text":"<pre><code>field_for_task_id = field_for_task_id\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgResultBackend.connect_kwargs","title":"connect_kwargs  <code>instance-attribute</code>","text":"<pre><code>connect_kwargs = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgResultBackend.serializer","title":"serializer  <code>instance-attribute</code>","text":"<pre><code>serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgResultBackend.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.aiopg.AiopgResultBackend.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the result backend.</p> <p>Construct new connection pool and create new table for results if not exists.</p> Source code in <code>src/taskiq_pg/aiopg/result_backend.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the result backend.\n\n    Construct new connection pool\n    and create new table for results if not exists.\n    \"\"\"\n    try:\n        self._database_pool = await create_pool(\n            self.dsn,\n            **self.connect_kwargs,\n        )\n\n        async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n            await cursor.execute(\n                queries.CREATE_TABLE_QUERY.format(\n                    self.table_name,\n                    self.field_for_task_id,\n                ),\n            )\n            await cursor.execute(\n                queries.ADD_PROGRESS_COLUMN_QUERY.format(\n                    self.table_name,\n                    self.field_for_task_id,\n                ),\n            )\n            await cursor.execute(\n                queries.CREATE_INDEX_QUERY.format(\n                    self.table_name,\n                    self.table_name,\n                ),\n            )\n    except Exception as error:\n        raise exceptions.DatabaseConnectionError(str(error)) from error\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgResultBackend.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/aiopg/result_backend.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgResultBackend.set_result","title":"set_result  <code>async</code>","text":"<pre><code>set_result(task_id, result)\n</code></pre> <p>Set result to the PostgreSQL table.</p> <p>Parameters:</p> <ul> <li> <code>task_id</code>               (<code>Any</code>)           \u2013            <p>ID of the task.</p> </li> <li> <code>result</code>               (<code>TaskiqResult[_ReturnType]</code>)           \u2013            <p>result of the task.</p> </li> </ul> Source code in <code>src/taskiq_pg/aiopg/result_backend.py</code> <pre><code>async def set_result(\n    self,\n    task_id: tp.Any,\n    result: TaskiqResult[ReturnType],\n) -&gt; None:\n    \"\"\"\n    Set result to the PostgreSQL table.\n\n    Args:\n        task_id (Any): ID of the task.\n        result (TaskiqResult[_ReturnType]):  result of the task.\n\n    \"\"\"\n    dumped_result = self.serializer.dumpb(result)\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            queries.INSERT_RESULT_QUERY.format(\n                self.table_name,\n            ),\n            (\n                task_id,\n                dumped_result,\n                dumped_result,\n            ),\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgResultBackend.is_result_ready","title":"is_result_ready  <code>async</code>","text":"<pre><code>is_result_ready(task_id)\n</code></pre> <p>Return whether the result is ready.</p> <p>Parameters:</p> <ul> <li> <code>task_id</code>               (<code>Any</code>)           \u2013            <p>ID of the task.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the result is ready else False.</p> </li> </ul> Source code in <code>src/taskiq_pg/aiopg/result_backend.py</code> <pre><code>async def is_result_ready(\n    self,\n    task_id: tp.Any,\n) -&gt; bool:\n    \"\"\"\n    Return whether the result is ready.\n\n    Args:\n        task_id (Any): ID of the task.\n\n    Returns:\n        bool: True if the result is ready else False.\n\n    \"\"\"\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            queries.IS_RESULT_EXISTS_QUERY.format(\n                self.table_name,\n            ),\n            (task_id,),\n        )\n        result = await cursor.fetchone()\n        return bool(result[0]) if result else False\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgResultBackend.get_result","title":"get_result  <code>async</code>","text":"<pre><code>get_result(task_id, with_logs=False)\n</code></pre> <p>Retrieve result from the task.</p> <p>:param task_id: task's id. :param with_logs: if True it will download task's logs. :raises ResultIsMissingError: if there is no result when trying to get it. :return: TaskiqResult.</p> Source code in <code>src/taskiq_pg/aiopg/result_backend.py</code> <pre><code>async def get_result(\n    self,\n    task_id: tp.Any,\n    with_logs: bool = False,\n) -&gt; TaskiqResult[ReturnType]:\n    \"\"\"\n    Retrieve result from the task.\n\n    :param task_id: task's id.\n    :param with_logs: if True it will download task's logs.\n    :raises ResultIsMissingError: if there is no result when trying to get it.\n    :return: TaskiqResult.\n    \"\"\"\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            queries.SELECT_RESULT_QUERY.format(\n                self.table_name,\n            ),\n            (task_id,),\n        )\n        result = await cursor.fetchone()\n\n        if not result:\n            msg = f\"Cannot find record with task_id = {task_id} in PostgreSQL\"\n            raise exceptions.ResultIsMissingError(\n                msg,\n            )\n\n        result_in_bytes: bytes = result[0]\n\n        if not self.keep_results:\n            await cursor.execute(\n                queries.DELETE_RESULT_QUERY.format(\n                    self.table_name,\n                ),\n                (task_id,),\n            )\n\n        taskiq_result: TaskiqResult[ReturnType] = self.serializer.loadb(\n            result_in_bytes,\n        )\n\n        if not with_logs:\n            taskiq_result.log = None\n\n        return taskiq_result\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgResultBackend.set_progress","title":"set_progress  <code>async</code>","text":"<pre><code>set_progress(task_id, progress)\n</code></pre> <p>Saves progress.</p> <p>:param task_id: task's id. :param progress: progress of execution.</p> Source code in <code>src/taskiq_pg/aiopg/result_backend.py</code> <pre><code>async def set_progress(\n    self,\n    task_id: str,\n    progress: TaskProgress[tp.Any],\n) -&gt; None:\n    \"\"\"\n    Saves progress.\n\n    :param task_id: task's id.\n    :param progress: progress of execution.\n    \"\"\"\n    dumped_progress = self.serializer.dumpb(progress)\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            queries.INSERT_PROGRESS_QUERY.format(\n                self.table_name,\n            ),\n            (\n                task_id,\n                dumped_progress,\n                dumped_progress,\n            ),\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgResultBackend.get_progress","title":"get_progress  <code>async</code>","text":"<pre><code>get_progress(task_id)\n</code></pre> <p>Gets progress.</p> <p>:param task_id: task's id.</p> Source code in <code>src/taskiq_pg/aiopg/result_backend.py</code> <pre><code>async def get_progress(\n    self,\n    task_id: str,\n) -&gt; TaskProgress[tp.Any] | None:\n    \"\"\"\n    Gets progress.\n\n    :param task_id: task's id.\n    \"\"\"\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            queries.SELECT_PROGRESS_QUERY.format(\n                self.table_name,\n            ),\n            (task_id,),\n        )\n        progress = await cursor.fetchone()\n        if not progress or progress[0] is None:\n            return None\n        progress_in_bytes: bytes = progress[0]\n        taskiq_progress: TaskProgress[tp.Any] = self.serializer.loadb(progress_in_bytes)\n        return taskiq_progress\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgScheduleSource","title":"AiopgScheduleSource","text":"<pre><code>AiopgScheduleSource(\n    broker,\n    dsn=\"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name=\"taskiq_schedules\",\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresScheduleSource</code></p> <p>Schedule source that uses aiopg to store schedules in PostgreSQL.</p> <p>Initialize the PostgreSQL scheduler source.</p> <p>Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database. This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks across application restarts.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>str | Callable[[], str]</code>, default:                   <code>'postgresql://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>PostgreSQL connection string</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_schedules'</code> )           \u2013            <p>Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.</p> </li> <li> <code>broker</code>               (<code>AsyncBroker</code>)           \u2013            <p>The TaskIQ broker instance to use for finding and managing tasks. Required if startup_schedule is provided.</p> </li> <li> <code>**connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional keyword arguments passed to the database connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def __init__(\n    self,\n    broker: AsyncBroker,\n    dsn: str | tp.Callable[[], str] = \"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name: str = \"taskiq_schedules\",\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Initialize the PostgreSQL scheduler source.\n\n    Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database.\n    This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks\n    across application restarts.\n\n    Args:\n        dsn: PostgreSQL connection string\n        table_name: Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.\n        broker: The TaskIQ broker instance to use for finding and managing tasks.\n            Required if startup_schedule is provided.\n        **connect_kwargs: Additional keyword arguments passed to the database connection pool.\n\n    \"\"\"\n    self._broker: tp.Final = broker\n    self._dsn: tp.Final = dsn\n    self._table_name: tp.Final = table_name\n    self._connect_kwargs: tp.Final = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgScheduleSource.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.aiopg.AiopgScheduleSource.extract_scheduled_tasks_from_broker","title":"extract_scheduled_tasks_from_broker","text":"<pre><code>extract_scheduled_tasks_from_broker()\n</code></pre> <p>Extract schedules from tasks that were registered in broker.</p> <p>Returns:</p> <ul> <li> <code>list[ScheduledTask]</code>           \u2013            <p>A list of ScheduledTask instances extracted from the task's labels.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def extract_scheduled_tasks_from_broker(self) -&gt; list[ScheduledTask]:\n    \"\"\"\n    Extract schedules from tasks that were registered in broker.\n\n    Returns:\n        A list of ScheduledTask instances extracted from the task's labels.\n    \"\"\"\n    scheduled_tasks_for_creation: list[ScheduledTask] = []\n    for task_name, task in self._broker.get_all_tasks().items():\n        if \"schedule\" not in task.labels:\n            logger.debug(\"Task %s has no schedule, skipping\", task_name)\n            continue\n        if not isinstance(task.labels[\"schedule\"], list):\n            logger.warning(\n                \"Schedule for task %s is not a list, skipping\",\n                task_name,\n            )\n            continue\n        for schedule in task.labels[\"schedule\"]:\n            try:\n                new_schedule = ScheduledTask.model_validate(\n                    {\n                        \"task_name\": task_name,\n                        \"labels\": schedule.get(\"labels\", {}),\n                        \"args\": schedule.get(\"args\", []),\n                        \"kwargs\": schedule.get(\"kwargs\", {}),\n                        \"schedule_id\": str(uuid.uuid4()),\n                        \"cron\": schedule.get(\"cron\", None),\n                        \"cron_offset\": schedule.get(\"cron_offset\", None),\n                        \"interval\": schedule.get(\"interval\", None),\n                        \"time\": schedule.get(\"time\", None),\n                    },\n                )\n                scheduled_tasks_for_creation.append(new_schedule)\n            except ValidationError:  # noqa: PERF203\n                logger.exception(\n                    \"Schedule for task %s is not valid, skipping\",\n                    task_name,\n                )\n                continue\n    return scheduled_tasks_for_creation\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgScheduleSource.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the schedule source.</p> <p>Construct new connection pool, create new table for schedules if not exists and fill table with schedules from task labels.</p> Source code in <code>src/taskiq_pg/aiopg/schedule_source.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the schedule source.\n\n    Construct new connection pool, create new table for schedules if not exists\n    and fill table with schedules from task labels.\n    \"\"\"\n    try:\n        self._database_pool = await create_pool(\n            dsn=self.dsn,\n            **self._connect_kwargs,\n        )\n        async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n            await cursor.execute(CREATE_SCHEDULES_TABLE_QUERY.format(self._table_name))\n        scheduled_tasks_for_creation = self.extract_scheduled_tasks_from_broker()\n        await self._update_schedules_on_startup(scheduled_tasks_for_creation)\n    except Exception as error:\n        raise exceptions.DatabaseConnectionError(str(error)) from error\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgScheduleSource.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/aiopg/schedule_source.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgScheduleSource.get_schedules","title":"get_schedules  <code>async</code>","text":"<pre><code>get_schedules()\n</code></pre> <p>Fetch schedules from the database.</p> Source code in <code>src/taskiq_pg/aiopg/schedule_source.py</code> <pre><code>async def get_schedules(self) -&gt; list[\"ScheduledTask\"]:\n    \"\"\"Fetch schedules from the database.\"\"\"\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            SELECT_SCHEDULES_QUERY.format(self._table_name),\n        )\n        schedules, rows = [], await cursor.fetchall()\n    for schedule_id, task_name, schedule in rows:\n        schedules.append(\n            ScheduledTask.model_validate(\n                {\n                    \"schedule_id\": str(schedule_id),\n                    \"task_name\": task_name,\n                    \"labels\": schedule[\"labels\"],\n                    \"args\": schedule[\"args\"],\n                    \"kwargs\": schedule[\"kwargs\"],\n                    \"cron\": schedule[\"cron\"],\n                    \"cron_offset\": schedule[\"cron_offset\"],\n                    \"time\": schedule[\"time\"],\n                    \"interval\": schedule[\"interval\"],\n                },\n            ),\n        )\n    return schedules\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgScheduleSource.add_schedule","title":"add_schedule  <code>async</code>","text":"<pre><code>add_schedule(schedule)\n</code></pre> <p>Add a new schedule.</p> <p>Parameters:</p> <ul> <li> <code>schedule</code>               (<code>ScheduledTask</code>)           \u2013            <p>schedule to add.</p> </li> </ul> Source code in <code>src/taskiq_pg/aiopg/schedule_source.py</code> <pre><code>async def add_schedule(self, schedule: \"ScheduledTask\") -&gt; None:\n    \"\"\"\n    Add a new schedule.\n\n    Args:\n        schedule: schedule to add.\n    \"\"\"\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            INSERT_SCHEDULE_QUERY.format(self._table_name),\n            [\n                schedule.schedule_id,\n                schedule.task_name,\n                schedule.model_dump_json(\n                    exclude={\"schedule_id\", \"task_name\"},\n                ),\n            ],\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgScheduleSource.delete_schedule","title":"delete_schedule  <code>async</code>","text":"<pre><code>delete_schedule(schedule_id)\n</code></pre> <p>Method to delete schedule by id.</p> <p>This is useful for schedule cancelation.</p> <p>Parameters:</p> <ul> <li> <code>schedule_id</code>               (<code>str</code>)           \u2013            <p>id of schedule to delete.</p> </li> </ul> Source code in <code>src/taskiq_pg/aiopg/schedule_source.py</code> <pre><code>async def delete_schedule(self, schedule_id: str) -&gt; None:\n    \"\"\"\n    Method to delete schedule by id.\n\n    This is useful for schedule cancelation.\n\n    Args:\n        schedule_id: id of schedule to delete.\n    \"\"\"\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            DELETE_SCHEDULE_QUERY.format(self._table_name),\n            [schedule_id],\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.AiopgScheduleSource.post_send","title":"post_send  <code>async</code>","text":"<pre><code>post_send(task)\n</code></pre> <p>Delete a task after it's completed.</p> Source code in <code>src/taskiq_pg/aiopg/schedule_source.py</code> <pre><code>async def post_send(self, task: ScheduledTask) -&gt; None:\n    \"\"\"Delete a task after it's completed.\"\"\"\n    if task.time is not None:\n        await self.delete_schedule(task.schedule_id)\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.broker","title":"broker","text":""},{"location":"reference/#taskiq_pg.aiopg.queries","title":"queries","text":""},{"location":"reference/#taskiq_pg.aiopg.queries.CREATE_TABLE_QUERY","title":"CREATE_TABLE_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_TABLE_QUERY = \"\\nCREATE TABLE IF NOT EXISTS {} (\\n    task_id {} UNIQUE,\\n    result BYTEA,\\n    progress BYTEA\\n)\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.queries.ADD_PROGRESS_COLUMN_QUERY","title":"ADD_PROGRESS_COLUMN_QUERY  <code>module-attribute</code>","text":"<pre><code>ADD_PROGRESS_COLUMN_QUERY = \"\\nALTER TABLE {} ADD COLUMN IF NOT EXISTS progress BYTEA;\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.queries.CREATE_INDEX_QUERY","title":"CREATE_INDEX_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_INDEX_QUERY = \"\\nCREATE INDEX IF NOT EXISTS {}_task_id_idx ON {} USING HASH (task_id)\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.queries.INSERT_RESULT_QUERY","title":"INSERT_RESULT_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_RESULT_QUERY = \"\\nINSERT INTO {} VALUES (%s, %s, NULL)\\nON CONFLICT (task_id)\\nDO UPDATE\\nSET result = %s\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.queries.INSERT_PROGRESS_QUERY","title":"INSERT_PROGRESS_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_PROGRESS_QUERY = \"\\nINSERT INTO {} VALUES (%s, NULL, %s)\\nON CONFLICT (task_id)\\nDO UPDATE\\nSET progress = %s\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.queries.SELECT_PROGRESS_QUERY","title":"SELECT_PROGRESS_QUERY  <code>module-attribute</code>","text":"<pre><code>SELECT_PROGRESS_QUERY = (\n    \"\\nSELECT progress FROM {} WHERE task_id = %s\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.queries.IS_RESULT_EXISTS_QUERY","title":"IS_RESULT_EXISTS_QUERY  <code>module-attribute</code>","text":"<pre><code>IS_RESULT_EXISTS_QUERY = \"\\nSELECT EXISTS(\\n    SELECT 1 FROM {} WHERE task_id = %s and result IS NOT NULL\\n)\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.queries.SELECT_RESULT_QUERY","title":"SELECT_RESULT_QUERY  <code>module-attribute</code>","text":"<pre><code>SELECT_RESULT_QUERY = (\n    \"\\nSELECT result FROM {} WHERE task_id = %s\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.queries.DELETE_RESULT_QUERY","title":"DELETE_RESULT_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_RESULT_QUERY = (\n    \"\\nDELETE FROM {} WHERE task_id = %s\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.queries.CREATE_SCHEDULES_TABLE_QUERY","title":"CREATE_SCHEDULES_TABLE_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_SCHEDULES_TABLE_QUERY = \"\\nCREATE TABLE IF NOT EXISTS {} (\\n    id UUID PRIMARY KEY,\\n    task_name VARCHAR(100) NOT NULL,\\n    schedule JSONB NOT NULL,\\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\\n);\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.queries.INSERT_SCHEDULE_QUERY","title":"INSERT_SCHEDULE_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_SCHEDULE_QUERY = \"\\nINSERT INTO {} (id, task_name, schedule)\\nVALUES (%s, %s, %s)\\nON CONFLICT (id) DO UPDATE\\nSET task_name = EXCLUDED.task_name,\\n    schedule = EXCLUDED.schedule,\\n    updated_at = NOW();\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.queries.SELECT_SCHEDULES_QUERY","title":"SELECT_SCHEDULES_QUERY  <code>module-attribute</code>","text":"<pre><code>SELECT_SCHEDULES_QUERY = (\n    \"\\nSELECT id, task_name, schedule\\nFROM {};\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.queries.DELETE_ALL_SCHEDULES_QUERY","title":"DELETE_ALL_SCHEDULES_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_ALL_SCHEDULES_QUERY = '\\nDELETE FROM {};\\n'\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.queries.DELETE_SCHEDULE_QUERY","title":"DELETE_SCHEDULE_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_SCHEDULE_QUERY = '\\nDELETE FROM {} WHERE id = %s;\\n'\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.result_backend","title":"result_backend","text":""},{"location":"reference/#taskiq_pg.aiopg.result_backend.AiopgResultBackend","title":"AiopgResultBackend","text":"<pre><code>AiopgResultBackend(\n    dsn=\"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results=True,\n    table_name=\"taskiq_results\",\n    field_for_task_id=\"VarChar\",\n    serializer=None,\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresResultBackend</code></p> <p>Result backend for TaskIQ based on Aiopg.</p> <p>Construct new result backend.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>Callable[[], str] | str | None</code>, default:                   <code>'postgres://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>connection string to PostgreSQL, or callable returning one.</p> </li> <li> <code>keep_results</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>flag to not remove results from the database after reading.</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_results'</code> )           \u2013            <p>name of the table to store results.</p> </li> <li> <code>field_for_task_id</code>               (<code>Literal['VarChar', 'Text', 'Uuid']</code>, default:                   <code>'VarChar'</code> )           \u2013            <p>type of the field to store task_id.</p> </li> <li> <code>serializer</code>               (<code>TaskiqSerializer | None</code>, default:                   <code>None</code> )           \u2013            <p>serializer class to serialize/deserialize result from task.</p> </li> <li> <code>connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>additional arguments for creating connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/result_backend.py</code> <pre><code>def __init__(\n    self,\n    dsn: tp.Callable[[], str] | str | None = \"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results: bool = True,\n    table_name: str = \"taskiq_results\",\n    field_for_task_id: tp.Literal[\"VarChar\", \"Text\", \"Uuid\"] = \"VarChar\",\n    serializer: TaskiqSerializer | None = None,\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Construct new result backend.\n\n    Args:\n        dsn: connection string to PostgreSQL, or callable returning one.\n        keep_results: flag to not remove results from the database after reading.\n        table_name: name of the table to store results.\n        field_for_task_id: type of the field to store task_id.\n        serializer: serializer class to serialize/deserialize result from task.\n        connect_kwargs: additional arguments for creating connection pool.\n\n    \"\"\"\n    self._dsn: tp.Final = dsn\n    self.keep_results: tp.Final = keep_results\n    self.table_name: tp.Final = table_name\n    self.field_for_task_id: tp.Final = field_for_task_id\n    self.connect_kwargs: tp.Final = connect_kwargs\n    self.serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.result_backend.AiopgResultBackend.keep_results","title":"keep_results  <code>instance-attribute</code>","text":"<pre><code>keep_results = keep_results\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.result_backend.AiopgResultBackend.table_name","title":"table_name  <code>instance-attribute</code>","text":"<pre><code>table_name = table_name\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.result_backend.AiopgResultBackend.field_for_task_id","title":"field_for_task_id  <code>instance-attribute</code>","text":"<pre><code>field_for_task_id = field_for_task_id\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.result_backend.AiopgResultBackend.connect_kwargs","title":"connect_kwargs  <code>instance-attribute</code>","text":"<pre><code>connect_kwargs = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.result_backend.AiopgResultBackend.serializer","title":"serializer  <code>instance-attribute</code>","text":"<pre><code>serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.result_backend.AiopgResultBackend.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.aiopg.result_backend.AiopgResultBackend.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the result backend.</p> <p>Construct new connection pool and create new table for results if not exists.</p> Source code in <code>src/taskiq_pg/aiopg/result_backend.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the result backend.\n\n    Construct new connection pool\n    and create new table for results if not exists.\n    \"\"\"\n    try:\n        self._database_pool = await create_pool(\n            self.dsn,\n            **self.connect_kwargs,\n        )\n\n        async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n            await cursor.execute(\n                queries.CREATE_TABLE_QUERY.format(\n                    self.table_name,\n                    self.field_for_task_id,\n                ),\n            )\n            await cursor.execute(\n                queries.ADD_PROGRESS_COLUMN_QUERY.format(\n                    self.table_name,\n                    self.field_for_task_id,\n                ),\n            )\n            await cursor.execute(\n                queries.CREATE_INDEX_QUERY.format(\n                    self.table_name,\n                    self.table_name,\n                ),\n            )\n    except Exception as error:\n        raise exceptions.DatabaseConnectionError(str(error)) from error\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.result_backend.AiopgResultBackend.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/aiopg/result_backend.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.result_backend.AiopgResultBackend.set_result","title":"set_result  <code>async</code>","text":"<pre><code>set_result(task_id, result)\n</code></pre> <p>Set result to the PostgreSQL table.</p> <p>Parameters:</p> <ul> <li> <code>task_id</code>               (<code>Any</code>)           \u2013            <p>ID of the task.</p> </li> <li> <code>result</code>               (<code>TaskiqResult[_ReturnType]</code>)           \u2013            <p>result of the task.</p> </li> </ul> Source code in <code>src/taskiq_pg/aiopg/result_backend.py</code> <pre><code>async def set_result(\n    self,\n    task_id: tp.Any,\n    result: TaskiqResult[ReturnType],\n) -&gt; None:\n    \"\"\"\n    Set result to the PostgreSQL table.\n\n    Args:\n        task_id (Any): ID of the task.\n        result (TaskiqResult[_ReturnType]):  result of the task.\n\n    \"\"\"\n    dumped_result = self.serializer.dumpb(result)\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            queries.INSERT_RESULT_QUERY.format(\n                self.table_name,\n            ),\n            (\n                task_id,\n                dumped_result,\n                dumped_result,\n            ),\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.result_backend.AiopgResultBackend.is_result_ready","title":"is_result_ready  <code>async</code>","text":"<pre><code>is_result_ready(task_id)\n</code></pre> <p>Return whether the result is ready.</p> <p>Parameters:</p> <ul> <li> <code>task_id</code>               (<code>Any</code>)           \u2013            <p>ID of the task.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the result is ready else False.</p> </li> </ul> Source code in <code>src/taskiq_pg/aiopg/result_backend.py</code> <pre><code>async def is_result_ready(\n    self,\n    task_id: tp.Any,\n) -&gt; bool:\n    \"\"\"\n    Return whether the result is ready.\n\n    Args:\n        task_id (Any): ID of the task.\n\n    Returns:\n        bool: True if the result is ready else False.\n\n    \"\"\"\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            queries.IS_RESULT_EXISTS_QUERY.format(\n                self.table_name,\n            ),\n            (task_id,),\n        )\n        result = await cursor.fetchone()\n        return bool(result[0]) if result else False\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.result_backend.AiopgResultBackend.get_result","title":"get_result  <code>async</code>","text":"<pre><code>get_result(task_id, with_logs=False)\n</code></pre> <p>Retrieve result from the task.</p> <p>:param task_id: task's id. :param with_logs: if True it will download task's logs. :raises ResultIsMissingError: if there is no result when trying to get it. :return: TaskiqResult.</p> Source code in <code>src/taskiq_pg/aiopg/result_backend.py</code> <pre><code>async def get_result(\n    self,\n    task_id: tp.Any,\n    with_logs: bool = False,\n) -&gt; TaskiqResult[ReturnType]:\n    \"\"\"\n    Retrieve result from the task.\n\n    :param task_id: task's id.\n    :param with_logs: if True it will download task's logs.\n    :raises ResultIsMissingError: if there is no result when trying to get it.\n    :return: TaskiqResult.\n    \"\"\"\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            queries.SELECT_RESULT_QUERY.format(\n                self.table_name,\n            ),\n            (task_id,),\n        )\n        result = await cursor.fetchone()\n\n        if not result:\n            msg = f\"Cannot find record with task_id = {task_id} in PostgreSQL\"\n            raise exceptions.ResultIsMissingError(\n                msg,\n            )\n\n        result_in_bytes: bytes = result[0]\n\n        if not self.keep_results:\n            await cursor.execute(\n                queries.DELETE_RESULT_QUERY.format(\n                    self.table_name,\n                ),\n                (task_id,),\n            )\n\n        taskiq_result: TaskiqResult[ReturnType] = self.serializer.loadb(\n            result_in_bytes,\n        )\n\n        if not with_logs:\n            taskiq_result.log = None\n\n        return taskiq_result\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.result_backend.AiopgResultBackend.set_progress","title":"set_progress  <code>async</code>","text":"<pre><code>set_progress(task_id, progress)\n</code></pre> <p>Saves progress.</p> <p>:param task_id: task's id. :param progress: progress of execution.</p> Source code in <code>src/taskiq_pg/aiopg/result_backend.py</code> <pre><code>async def set_progress(\n    self,\n    task_id: str,\n    progress: TaskProgress[tp.Any],\n) -&gt; None:\n    \"\"\"\n    Saves progress.\n\n    :param task_id: task's id.\n    :param progress: progress of execution.\n    \"\"\"\n    dumped_progress = self.serializer.dumpb(progress)\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            queries.INSERT_PROGRESS_QUERY.format(\n                self.table_name,\n            ),\n            (\n                task_id,\n                dumped_progress,\n                dumped_progress,\n            ),\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.result_backend.AiopgResultBackend.get_progress","title":"get_progress  <code>async</code>","text":"<pre><code>get_progress(task_id)\n</code></pre> <p>Gets progress.</p> <p>:param task_id: task's id.</p> Source code in <code>src/taskiq_pg/aiopg/result_backend.py</code> <pre><code>async def get_progress(\n    self,\n    task_id: str,\n) -&gt; TaskProgress[tp.Any] | None:\n    \"\"\"\n    Gets progress.\n\n    :param task_id: task's id.\n    \"\"\"\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            queries.SELECT_PROGRESS_QUERY.format(\n                self.table_name,\n            ),\n            (task_id,),\n        )\n        progress = await cursor.fetchone()\n        if not progress or progress[0] is None:\n            return None\n        progress_in_bytes: bytes = progress[0]\n        taskiq_progress: TaskProgress[tp.Any] = self.serializer.loadb(progress_in_bytes)\n        return taskiq_progress\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.schedule_source","title":"schedule_source","text":""},{"location":"reference/#taskiq_pg.aiopg.schedule_source.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger('taskiq_pg.aiopg_schedule_source')\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.schedule_source.AiopgScheduleSource","title":"AiopgScheduleSource","text":"<pre><code>AiopgScheduleSource(\n    broker,\n    dsn=\"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name=\"taskiq_schedules\",\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresScheduleSource</code></p> <p>Schedule source that uses aiopg to store schedules in PostgreSQL.</p> <p>Initialize the PostgreSQL scheduler source.</p> <p>Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database. This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks across application restarts.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>str | Callable[[], str]</code>, default:                   <code>'postgresql://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>PostgreSQL connection string</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_schedules'</code> )           \u2013            <p>Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.</p> </li> <li> <code>broker</code>               (<code>AsyncBroker</code>)           \u2013            <p>The TaskIQ broker instance to use for finding and managing tasks. Required if startup_schedule is provided.</p> </li> <li> <code>**connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional keyword arguments passed to the database connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def __init__(\n    self,\n    broker: AsyncBroker,\n    dsn: str | tp.Callable[[], str] = \"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name: str = \"taskiq_schedules\",\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Initialize the PostgreSQL scheduler source.\n\n    Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database.\n    This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks\n    across application restarts.\n\n    Args:\n        dsn: PostgreSQL connection string\n        table_name: Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.\n        broker: The TaskIQ broker instance to use for finding and managing tasks.\n            Required if startup_schedule is provided.\n        **connect_kwargs: Additional keyword arguments passed to the database connection pool.\n\n    \"\"\"\n    self._broker: tp.Final = broker\n    self._dsn: tp.Final = dsn\n    self._table_name: tp.Final = table_name\n    self._connect_kwargs: tp.Final = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.schedule_source.AiopgScheduleSource.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.aiopg.schedule_source.AiopgScheduleSource.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the schedule source.</p> <p>Construct new connection pool, create new table for schedules if not exists and fill table with schedules from task labels.</p> Source code in <code>src/taskiq_pg/aiopg/schedule_source.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the schedule source.\n\n    Construct new connection pool, create new table for schedules if not exists\n    and fill table with schedules from task labels.\n    \"\"\"\n    try:\n        self._database_pool = await create_pool(\n            dsn=self.dsn,\n            **self._connect_kwargs,\n        )\n        async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n            await cursor.execute(CREATE_SCHEDULES_TABLE_QUERY.format(self._table_name))\n        scheduled_tasks_for_creation = self.extract_scheduled_tasks_from_broker()\n        await self._update_schedules_on_startup(scheduled_tasks_for_creation)\n    except Exception as error:\n        raise exceptions.DatabaseConnectionError(str(error)) from error\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.schedule_source.AiopgScheduleSource.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/aiopg/schedule_source.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.schedule_source.AiopgScheduleSource.get_schedules","title":"get_schedules  <code>async</code>","text":"<pre><code>get_schedules()\n</code></pre> <p>Fetch schedules from the database.</p> Source code in <code>src/taskiq_pg/aiopg/schedule_source.py</code> <pre><code>async def get_schedules(self) -&gt; list[\"ScheduledTask\"]:\n    \"\"\"Fetch schedules from the database.\"\"\"\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            SELECT_SCHEDULES_QUERY.format(self._table_name),\n        )\n        schedules, rows = [], await cursor.fetchall()\n    for schedule_id, task_name, schedule in rows:\n        schedules.append(\n            ScheduledTask.model_validate(\n                {\n                    \"schedule_id\": str(schedule_id),\n                    \"task_name\": task_name,\n                    \"labels\": schedule[\"labels\"],\n                    \"args\": schedule[\"args\"],\n                    \"kwargs\": schedule[\"kwargs\"],\n                    \"cron\": schedule[\"cron\"],\n                    \"cron_offset\": schedule[\"cron_offset\"],\n                    \"time\": schedule[\"time\"],\n                    \"interval\": schedule[\"interval\"],\n                },\n            ),\n        )\n    return schedules\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.schedule_source.AiopgScheduleSource.add_schedule","title":"add_schedule  <code>async</code>","text":"<pre><code>add_schedule(schedule)\n</code></pre> <p>Add a new schedule.</p> <p>Parameters:</p> <ul> <li> <code>schedule</code>               (<code>ScheduledTask</code>)           \u2013            <p>schedule to add.</p> </li> </ul> Source code in <code>src/taskiq_pg/aiopg/schedule_source.py</code> <pre><code>async def add_schedule(self, schedule: \"ScheduledTask\") -&gt; None:\n    \"\"\"\n    Add a new schedule.\n\n    Args:\n        schedule: schedule to add.\n    \"\"\"\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            INSERT_SCHEDULE_QUERY.format(self._table_name),\n            [\n                schedule.schedule_id,\n                schedule.task_name,\n                schedule.model_dump_json(\n                    exclude={\"schedule_id\", \"task_name\"},\n                ),\n            ],\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.schedule_source.AiopgScheduleSource.delete_schedule","title":"delete_schedule  <code>async</code>","text":"<pre><code>delete_schedule(schedule_id)\n</code></pre> <p>Method to delete schedule by id.</p> <p>This is useful for schedule cancelation.</p> <p>Parameters:</p> <ul> <li> <code>schedule_id</code>               (<code>str</code>)           \u2013            <p>id of schedule to delete.</p> </li> </ul> Source code in <code>src/taskiq_pg/aiopg/schedule_source.py</code> <pre><code>async def delete_schedule(self, schedule_id: str) -&gt; None:\n    \"\"\"\n    Method to delete schedule by id.\n\n    This is useful for schedule cancelation.\n\n    Args:\n        schedule_id: id of schedule to delete.\n    \"\"\"\n    async with self._database_pool.acquire() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            DELETE_SCHEDULE_QUERY.format(self._table_name),\n            [schedule_id],\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.schedule_source.AiopgScheduleSource.post_send","title":"post_send  <code>async</code>","text":"<pre><code>post_send(task)\n</code></pre> <p>Delete a task after it's completed.</p> Source code in <code>src/taskiq_pg/aiopg/schedule_source.py</code> <pre><code>async def post_send(self, task: ScheduledTask) -&gt; None:\n    \"\"\"Delete a task after it's completed.\"\"\"\n    if task.time is not None:\n        await self.delete_schedule(task.schedule_id)\n</code></pre>"},{"location":"reference/#taskiq_pg.aiopg.schedule_source.AiopgScheduleSource.extract_scheduled_tasks_from_broker","title":"extract_scheduled_tasks_from_broker","text":"<pre><code>extract_scheduled_tasks_from_broker()\n</code></pre> <p>Extract schedules from tasks that were registered in broker.</p> <p>Returns:</p> <ul> <li> <code>list[ScheduledTask]</code>           \u2013            <p>A list of ScheduledTask instances extracted from the task's labels.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def extract_scheduled_tasks_from_broker(self) -&gt; list[ScheduledTask]:\n    \"\"\"\n    Extract schedules from tasks that were registered in broker.\n\n    Returns:\n        A list of ScheduledTask instances extracted from the task's labels.\n    \"\"\"\n    scheduled_tasks_for_creation: list[ScheduledTask] = []\n    for task_name, task in self._broker.get_all_tasks().items():\n        if \"schedule\" not in task.labels:\n            logger.debug(\"Task %s has no schedule, skipping\", task_name)\n            continue\n        if not isinstance(task.labels[\"schedule\"], list):\n            logger.warning(\n                \"Schedule for task %s is not a list, skipping\",\n                task_name,\n            )\n            continue\n        for schedule in task.labels[\"schedule\"]:\n            try:\n                new_schedule = ScheduledTask.model_validate(\n                    {\n                        \"task_name\": task_name,\n                        \"labels\": schedule.get(\"labels\", {}),\n                        \"args\": schedule.get(\"args\", []),\n                        \"kwargs\": schedule.get(\"kwargs\", {}),\n                        \"schedule_id\": str(uuid.uuid4()),\n                        \"cron\": schedule.get(\"cron\", None),\n                        \"cron_offset\": schedule.get(\"cron_offset\", None),\n                        \"interval\": schedule.get(\"interval\", None),\n                        \"time\": schedule.get(\"time\", None),\n                    },\n                )\n                scheduled_tasks_for_creation.append(new_schedule)\n            except ValidationError:  # noqa: PERF203\n                logger.exception(\n                    \"Schedule for task %s is not valid, skipping\",\n                    task_name,\n                )\n                continue\n    return scheduled_tasks_for_creation\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg","title":"asyncpg","text":""},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgBroker","title":"AsyncpgBroker","text":"<pre><code>AsyncpgBroker(\n    dsn=\"postgresql://postgres:postgres@localhost:5432/postgres\",\n    result_backend=None,\n    task_id_generator=None,\n    channel_name=\"taskiq\",\n    table_name=\"taskiq_messages\",\n    max_retry_attempts=5,\n    read_kwargs=None,\n    write_kwargs=None,\n)\n</code></pre> <p>               Bases: <code>BasePostgresBroker</code></p> <p>Broker that uses asyncpg as driver and PostgreSQL with LISTEN/NOTIFY mechanism.</p> <p>Construct a new broker.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>str | Callable[[], str]</code>, default:                   <code>'postgresql://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>connection string to PostgreSQL, or callable returning one.</p> </li> <li> <code>result_backend</code>               (<code>AsyncResultBackend[_T] | None</code>, default:                   <code>None</code> )           \u2013            <p>Custom result backend.</p> </li> <li> <code>task_id_generator</code>               (<code>Callable[[], str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Custom task_id generator.</p> </li> <li> <code>channel_name</code>               (<code>str</code>, default:                   <code>'taskiq'</code> )           \u2013            <p>Name of the channel to listen on.</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_messages'</code> )           \u2013            <p>Name of the table to store messages.</p> </li> <li> <code>max_retry_attempts</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>Maximum number of message processing attempts.</p> </li> <li> <code>read_kwargs</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional arguments for read connection creation.</p> </li> <li> <code>write_kwargs</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional arguments for write pool creation.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/broker.py</code> <pre><code>def __init__(  # noqa: PLR0913\n    self,\n    dsn: str | tp.Callable[[], str] = \"postgresql://postgres:postgres@localhost:5432/postgres\",\n    result_backend: AsyncResultBackend[_T] | None = None,\n    task_id_generator: tp.Callable[[], str] | None = None,\n    channel_name: str = \"taskiq\",\n    table_name: str = \"taskiq_messages\",\n    max_retry_attempts: int = 5,\n    read_kwargs: dict[str, tp.Any] | None = None,\n    write_kwargs: dict[str, tp.Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Construct a new broker.\n\n    Args:\n        dsn: connection string to PostgreSQL, or callable returning one.\n        result_backend: Custom result backend.\n        task_id_generator: Custom task_id generator.\n        channel_name: Name of the channel to listen on.\n        table_name: Name of the table to store messages.\n        max_retry_attempts: Maximum number of message processing attempts.\n        read_kwargs: Additional arguments for read connection creation.\n        write_kwargs: Additional arguments for write pool creation.\n\n    \"\"\"\n    super().__init__(\n        result_backend=result_backend,\n        task_id_generator=task_id_generator,\n    )\n    self._dsn: str | tp.Callable[[], str] = dsn\n    self.channel_name: str = channel_name\n    self.table_name: str = table_name\n    self.read_kwargs: dict[str, tp.Any] = read_kwargs or {}\n    self.write_kwargs: dict[str, tp.Any] = write_kwargs or {}\n    self.max_retry_attempts: int = max_retry_attempts\n    self._queue: asyncio.Queue[str] | None = None\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgBroker.channel_name","title":"channel_name  <code>instance-attribute</code>","text":"<pre><code>channel_name = channel_name\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgBroker.table_name","title":"table_name  <code>instance-attribute</code>","text":"<pre><code>table_name = table_name\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgBroker.read_kwargs","title":"read_kwargs  <code>instance-attribute</code>","text":"<pre><code>read_kwargs = read_kwargs or {}\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgBroker.write_kwargs","title":"write_kwargs  <code>instance-attribute</code>","text":"<pre><code>write_kwargs = write_kwargs or {}\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgBroker.max_retry_attempts","title":"max_retry_attempts  <code>instance-attribute</code>","text":"<pre><code>max_retry_attempts = max_retry_attempts\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgBroker.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>A string with dsn or None if dsn isn't set yet.</p> </li> </ul>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgBroker.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the broker.</p> Source code in <code>src/taskiq_pg/asyncpg/broker.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"Initialize the broker.\"\"\"\n    await super().startup()\n\n    self._read_conn = await asyncpg.connect(self.dsn, **self.read_kwargs)\n    self._write_pool = await asyncpg.create_pool(self.dsn, **self.write_kwargs)\n\n    if self._read_conn is None:\n        msg = \"_read_conn not initialized\"\n        raise RuntimeError(msg)\n\n    async with self._write_pool.acquire() as conn:\n        await conn.execute(CREATE_MESSAGE_TABLE_QUERY.format(self.table_name))\n\n    await self._read_conn.add_listener(self.channel_name, self._notification_handler)\n    self._queue = asyncio.Queue()\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgBroker.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close all connections on shutdown.</p> Source code in <code>src/taskiq_pg/asyncpg/broker.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close all connections on shutdown.\"\"\"\n    await super().shutdown()\n    if self._read_conn is not None:\n        await self._read_conn.remove_listener(self.channel_name, self._notification_handler)\n        await self._read_conn.close()\n    if self._write_pool is not None:\n        await self._write_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgBroker.kick","title":"kick  <code>async</code>","text":"<pre><code>kick(message)\n</code></pre> <p>Send message to the channel.</p> <p>Inserts the message into the database and sends a NOTIFY.</p> <p>:param message: Message to send.</p> Source code in <code>src/taskiq_pg/asyncpg/broker.py</code> <pre><code>async def kick(self, message: BrokerMessage) -&gt; None:\n    \"\"\"\n    Send message to the channel.\n\n    Inserts the message into the database and sends a NOTIFY.\n\n    :param message: Message to send.\n    \"\"\"\n    if self._write_pool is None:\n        msg = \"Please run startup before kicking.\"\n        raise ValueError(msg)\n\n    async with self._write_pool.acquire() as conn:\n        # Insert the message into the database\n        message_inserted_id = tp.cast(\n            \"int\",\n            await conn.fetchval(\n                INSERT_MESSAGE_QUERY.format(self.table_name),\n                message.task_id,\n                message.task_name,\n                message.message.decode(),\n                json.dumps(message.labels),\n            ),\n        )\n\n        delay_value = message.labels.get(\"delay\")\n        if delay_value is not None:\n            delay_seconds = int(delay_value)\n            _ = asyncio.create_task(  # noqa: RUF006\n                self._schedule_notification(message_inserted_id, delay_seconds),\n            )\n        else:\n            # Send a NOTIFY with the message ID as payload\n            _ = await conn.execute(\n                f\"NOTIFY {self.channel_name}, '{message_inserted_id}'\",\n            )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgBroker.listen","title":"listen  <code>async</code>","text":"<pre><code>listen()\n</code></pre> <p>Listen to the channel.</p> <p>Yields messages as they are received.</p> <p>:yields: AckableMessage instances.</p> Source code in <code>src/taskiq_pg/asyncpg/broker.py</code> <pre><code>async def listen(self) -&gt; AsyncGenerator[AckableMessage, None]:\n    \"\"\"\n    Listen to the channel.\n\n    Yields messages as they are received.\n\n    :yields: AckableMessage instances.\n    \"\"\"\n    if self._write_pool is None:\n        msg = \"Call startup before starting listening.\"\n        raise ValueError(msg)\n    if self._queue is None:\n        msg = \"Startup did not initialize the queue.\"\n        raise ValueError(msg)\n\n    while True:\n        try:\n            payload = await self._queue.get()\n            message_id = int(payload)\n            async with self._write_pool.acquire() as conn:\n                claimed = await conn.fetchrow(\n                    CLAIM_MESSAGE_QUERY.format(self.table_name),\n                    message_id,\n                )\n            if claimed is None:\n                continue\n            message_str = claimed[\"message\"]\n            if not isinstance(message_str, str):\n                msg = \"message is not a string\"\n                raise TypeError(msg)\n            message_data = message_str.encode()\n\n            async def ack(*, _message_id: int = message_id) -&gt; None:\n                if self._write_pool is None:\n                    msg = \"Call startup before starting listening.\"\n                    raise ValueError(msg)\n\n                async with self._write_pool.acquire() as conn:\n                    _ = await conn.execute(\n                        DELETE_MESSAGE_QUERY.format(self.table_name),\n                        _message_id,\n                    )\n\n            yield AckableMessage(data=message_data, ack=ack)\n        except Exception:\n            logger.exception(\"Error processing message\")\n            continue\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgResultBackend","title":"AsyncpgResultBackend","text":"<pre><code>AsyncpgResultBackend(\n    dsn=\"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results=True,\n    table_name=\"taskiq_results\",\n    field_for_task_id=\"VarChar\",\n    serializer=None,\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresResultBackend</code></p> <p>Result backend for TaskIQ based on asyncpg.</p> <p>Construct new result backend.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>Callable[[], str] | str | None</code>, default:                   <code>'postgres://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>connection string to PostgreSQL, or callable returning one.</p> </li> <li> <code>keep_results</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>flag to not remove results from the database after reading.</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_results'</code> )           \u2013            <p>name of the table to store results.</p> </li> <li> <code>field_for_task_id</code>               (<code>Literal['VarChar', 'Text', 'Uuid']</code>, default:                   <code>'VarChar'</code> )           \u2013            <p>type of the field to store task_id.</p> </li> <li> <code>serializer</code>               (<code>TaskiqSerializer | None</code>, default:                   <code>None</code> )           \u2013            <p>serializer class to serialize/deserialize result from task.</p> </li> <li> <code>connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>additional arguments for creating connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/result_backend.py</code> <pre><code>def __init__(\n    self,\n    dsn: tp.Callable[[], str] | str | None = \"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results: bool = True,\n    table_name: str = \"taskiq_results\",\n    field_for_task_id: tp.Literal[\"VarChar\", \"Text\", \"Uuid\"] = \"VarChar\",\n    serializer: TaskiqSerializer | None = None,\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Construct new result backend.\n\n    Args:\n        dsn: connection string to PostgreSQL, or callable returning one.\n        keep_results: flag to not remove results from the database after reading.\n        table_name: name of the table to store results.\n        field_for_task_id: type of the field to store task_id.\n        serializer: serializer class to serialize/deserialize result from task.\n        connect_kwargs: additional arguments for creating connection pool.\n\n    \"\"\"\n    self._dsn: tp.Final = dsn\n    self.keep_results: tp.Final = keep_results\n    self.table_name: tp.Final = table_name\n    self.field_for_task_id: tp.Final = field_for_task_id\n    self.connect_kwargs: tp.Final = connect_kwargs\n    self.serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgResultBackend.keep_results","title":"keep_results  <code>instance-attribute</code>","text":"<pre><code>keep_results = keep_results\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgResultBackend.table_name","title":"table_name  <code>instance-attribute</code>","text":"<pre><code>table_name = table_name\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgResultBackend.field_for_task_id","title":"field_for_task_id  <code>instance-attribute</code>","text":"<pre><code>field_for_task_id = field_for_task_id\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgResultBackend.connect_kwargs","title":"connect_kwargs  <code>instance-attribute</code>","text":"<pre><code>connect_kwargs = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgResultBackend.serializer","title":"serializer  <code>instance-attribute</code>","text":"<pre><code>serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgResultBackend.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgResultBackend.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the result backend.</p> <p>Construct new connection pool and create new table for results if not exists.</p> Source code in <code>src/taskiq_pg/asyncpg/result_backend.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the result backend.\n\n    Construct new connection pool and create new table for results if not exists.\n    \"\"\"\n    _database_pool = await asyncpg.create_pool(\n        dsn=self.dsn,\n        **self.connect_kwargs,\n    )\n    self._database_pool = _database_pool\n\n    await self._database_pool.execute(\n        queries.CREATE_TABLE_QUERY.format(\n            self.table_name,\n            self.field_for_task_id,\n        ),\n    )\n    await self._database_pool.execute(\n        queries.ADD_PROGRESS_COLUMN_QUERY.format(\n            self.table_name,\n        ),\n    )\n    await self._database_pool.execute(\n        queries.CREATE_INDEX_QUERY.format(\n            self.table_name,\n            self.table_name,\n        ),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgResultBackend.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/asyncpg/result_backend.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        await self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgResultBackend.set_result","title":"set_result  <code>async</code>","text":"<pre><code>set_result(task_id, result)\n</code></pre> <p>Set result to the PostgreSQL table.</p> <p>:param task_id: ID of the task. :param result: result of the task.</p> Source code in <code>src/taskiq_pg/asyncpg/result_backend.py</code> <pre><code>async def set_result(\n    self,\n    task_id: str,\n    result: TaskiqResult[ReturnType],\n) -&gt; None:\n    \"\"\"\n    Set result to the PostgreSQL table.\n\n    :param task_id: ID of the task.\n    :param result: result of the task.\n    \"\"\"\n    _ = await self._database_pool.execute(\n        queries.INSERT_RESULT_QUERY.format(\n            self.table_name,\n        ),\n        task_id,\n        self.serializer.dumpb(model_dump(result)),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgResultBackend.is_result_ready","title":"is_result_ready  <code>async</code>","text":"<pre><code>is_result_ready(task_id)\n</code></pre> <p>Returns whether the result is ready.</p> <p>:param task_id: ID of the task. :returns: True if the result is ready else False.</p> Source code in <code>src/taskiq_pg/asyncpg/result_backend.py</code> <pre><code>async def is_result_ready(self, task_id: str) -&gt; bool:\n    \"\"\"\n    Returns whether the result is ready.\n\n    :param task_id: ID of the task.\n    :returns: True if the result is ready else False.\n    \"\"\"\n    return tp.cast(\n        \"bool\",\n        await self._database_pool.fetchval(\n            queries.IS_RESULT_EXISTS_QUERY.format(\n                self.table_name,\n            ),\n            task_id,\n        ),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgResultBackend.get_result","title":"get_result  <code>async</code>","text":"<pre><code>get_result(task_id, with_logs=False)\n</code></pre> <p>Retrieve result from the task.</p> <p>:param task_id: task's id. :param with_logs: if True it will download task's logs. (deprecated in taskiq) :raises ResultIsMissingError: if there is no result when trying to get it. :return: TaskiqResult.</p> Source code in <code>src/taskiq_pg/asyncpg/result_backend.py</code> <pre><code>async def get_result(\n    self,\n    task_id: str,\n    with_logs: bool = False,\n) -&gt; TaskiqResult[ReturnType]:\n    \"\"\"\n    Retrieve result from the task.\n\n    :param task_id: task's id.\n    :param with_logs: if True it will download task's logs. (deprecated in taskiq)\n    :raises ResultIsMissingError: if there is no result when trying to get it.\n    :return: TaskiqResult.\n    \"\"\"\n    result_in_bytes = tp.cast(\n        \"bytes\",\n        await self._database_pool.fetchval(\n            queries.SELECT_RESULT_QUERY.format(\n                self.table_name,\n            ),\n            task_id,\n        ),\n    )\n    if not self.keep_results:\n        await self._database_pool.execute(\n            queries.DELETE_RESULT_QUERY.format(\n                self.table_name,\n            ),\n            task_id,\n        )\n    taskiq_result: tp.Final = model_validate(\n        TaskiqResult[ReturnType],\n        self.serializer.loadb(result_in_bytes),\n    )\n    if not with_logs:\n        taskiq_result.log = None\n    return taskiq_result\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgResultBackend.set_progress","title":"set_progress  <code>async</code>","text":"<pre><code>set_progress(task_id, progress)\n</code></pre> <p>Saves progress.</p> <p>:param task_id: task's id. :param progress: progress of execution.</p> Source code in <code>src/taskiq_pg/asyncpg/result_backend.py</code> <pre><code>async def set_progress(\n    self,\n    task_id: str,\n    progress: TaskProgress[tp.Any],\n) -&gt; None:\n    \"\"\"\n    Saves progress.\n\n    :param task_id: task's id.\n    :param progress: progress of execution.\n    \"\"\"\n    await self._database_pool.execute(\n        queries.INSERT_PROGRESS_QUERY.format(\n            self.table_name,\n        ),\n        task_id,\n        self.serializer.dumpb(model_dump(progress)),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgResultBackend.get_progress","title":"get_progress  <code>async</code>","text":"<pre><code>get_progress(task_id)\n</code></pre> <p>Gets progress.</p> <p>:param task_id: task's id.</p> Source code in <code>src/taskiq_pg/asyncpg/result_backend.py</code> <pre><code>async def get_progress(\n    self,\n    task_id: str,\n) -&gt; TaskProgress[tp.Any] | None:\n    \"\"\"\n    Gets progress.\n\n    :param task_id: task's id.\n    \"\"\"\n    progress_in_bytes = await self._database_pool.fetchval(\n        queries.SELECT_PROGRESS_QUERY.format(\n            self.table_name,\n        ),\n        task_id,\n    )\n    if progress_in_bytes is None:\n        return None\n    return model_validate(\n        TaskProgress[tp.Any],\n        self.serializer.loadb(progress_in_bytes),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgScheduleSource","title":"AsyncpgScheduleSource","text":"<pre><code>AsyncpgScheduleSource(\n    broker,\n    dsn=\"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name=\"taskiq_schedules\",\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresScheduleSource</code></p> <p>Schedule source that uses asyncpg to store schedules in PostgreSQL.</p> <p>Initialize the PostgreSQL scheduler source.</p> <p>Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database. This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks across application restarts.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>str | Callable[[], str]</code>, default:                   <code>'postgresql://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>PostgreSQL connection string</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_schedules'</code> )           \u2013            <p>Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.</p> </li> <li> <code>broker</code>               (<code>AsyncBroker</code>)           \u2013            <p>The TaskIQ broker instance to use for finding and managing tasks. Required if startup_schedule is provided.</p> </li> <li> <code>**connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional keyword arguments passed to the database connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def __init__(\n    self,\n    broker: AsyncBroker,\n    dsn: str | tp.Callable[[], str] = \"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name: str = \"taskiq_schedules\",\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Initialize the PostgreSQL scheduler source.\n\n    Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database.\n    This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks\n    across application restarts.\n\n    Args:\n        dsn: PostgreSQL connection string\n        table_name: Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.\n        broker: The TaskIQ broker instance to use for finding and managing tasks.\n            Required if startup_schedule is provided.\n        **connect_kwargs: Additional keyword arguments passed to the database connection pool.\n\n    \"\"\"\n    self._broker: tp.Final = broker\n    self._dsn: tp.Final = dsn\n    self._table_name: tp.Final = table_name\n    self._connect_kwargs: tp.Final = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgScheduleSource.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgScheduleSource.extract_scheduled_tasks_from_broker","title":"extract_scheduled_tasks_from_broker","text":"<pre><code>extract_scheduled_tasks_from_broker()\n</code></pre> <p>Extract schedules from tasks that were registered in broker.</p> <p>Returns:</p> <ul> <li> <code>list[ScheduledTask]</code>           \u2013            <p>A list of ScheduledTask instances extracted from the task's labels.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def extract_scheduled_tasks_from_broker(self) -&gt; list[ScheduledTask]:\n    \"\"\"\n    Extract schedules from tasks that were registered in broker.\n\n    Returns:\n        A list of ScheduledTask instances extracted from the task's labels.\n    \"\"\"\n    scheduled_tasks_for_creation: list[ScheduledTask] = []\n    for task_name, task in self._broker.get_all_tasks().items():\n        if \"schedule\" not in task.labels:\n            logger.debug(\"Task %s has no schedule, skipping\", task_name)\n            continue\n        if not isinstance(task.labels[\"schedule\"], list):\n            logger.warning(\n                \"Schedule for task %s is not a list, skipping\",\n                task_name,\n            )\n            continue\n        for schedule in task.labels[\"schedule\"]:\n            try:\n                new_schedule = ScheduledTask.model_validate(\n                    {\n                        \"task_name\": task_name,\n                        \"labels\": schedule.get(\"labels\", {}),\n                        \"args\": schedule.get(\"args\", []),\n                        \"kwargs\": schedule.get(\"kwargs\", {}),\n                        \"schedule_id\": str(uuid.uuid4()),\n                        \"cron\": schedule.get(\"cron\", None),\n                        \"cron_offset\": schedule.get(\"cron_offset\", None),\n                        \"interval\": schedule.get(\"interval\", None),\n                        \"time\": schedule.get(\"time\", None),\n                    },\n                )\n                scheduled_tasks_for_creation.append(new_schedule)\n            except ValidationError:  # noqa: PERF203\n                logger.exception(\n                    \"Schedule for task %s is not valid, skipping\",\n                    task_name,\n                )\n                continue\n    return scheduled_tasks_for_creation\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgScheduleSource.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the schedule source.</p> <p>Construct new connection pool, create new table for schedules if not exists and fill table with schedules from task labels.</p> Source code in <code>src/taskiq_pg/asyncpg/schedule_source.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the schedule source.\n\n    Construct new connection pool, create new table for schedules if not exists\n    and fill table with schedules from task labels.\n    \"\"\"\n    self._database_pool = await asyncpg.create_pool(\n        dsn=self.dsn,\n        **self._connect_kwargs,\n    )\n    await self._database_pool.execute(\n        CREATE_SCHEDULES_TABLE_QUERY.format(\n            self._table_name,\n        ),\n    )\n    scheduled_tasks_for_creation = self.extract_scheduled_tasks_from_broker()\n    await self._update_schedules_on_startup(scheduled_tasks_for_creation)\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgScheduleSource.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/asyncpg/schedule_source.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        await self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgScheduleSource.get_schedules","title":"get_schedules  <code>async</code>","text":"<pre><code>get_schedules()\n</code></pre> <p>Fetch schedules from the database.</p> Source code in <code>src/taskiq_pg/asyncpg/schedule_source.py</code> <pre><code>async def get_schedules(self) -&gt; list[\"ScheduledTask\"]:\n    \"\"\"Fetch schedules from the database.\"\"\"\n    async with self._database_pool.acquire() as conn:\n        rows_with_schedules = await conn.fetch(\n            SELECT_SCHEDULES_QUERY.format(self._table_name),\n        )\n    schedules = []\n    for row in rows_with_schedules:\n        schedule = json.loads(row[\"schedule\"])\n        schedules.append(\n            ScheduledTask.model_validate(\n                {\n                    \"schedule_id\": str(row[\"id\"]),\n                    \"task_name\": row[\"task_name\"],\n                    \"labels\": schedule[\"labels\"],\n                    \"args\": schedule[\"args\"],\n                    \"kwargs\": schedule[\"kwargs\"],\n                    \"cron\": schedule[\"cron\"],\n                    \"cron_offset\": schedule[\"cron_offset\"],\n                    \"time\": schedule[\"time\"],\n                    \"interval\": schedule[\"interval\"],\n                },\n            ),\n        )\n    return schedules\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgScheduleSource.add_schedule","title":"add_schedule  <code>async</code>","text":"<pre><code>add_schedule(schedule)\n</code></pre> <p>Add a new schedule.</p> <p>Parameters:</p> <ul> <li> <code>schedule</code>               (<code>ScheduledTask</code>)           \u2013            <p>schedule to add.</p> </li> </ul> Source code in <code>src/taskiq_pg/asyncpg/schedule_source.py</code> <pre><code>async def add_schedule(self, schedule: \"ScheduledTask\") -&gt; None:\n    \"\"\"\n    Add a new schedule.\n\n    Args:\n        schedule: schedule to add.\n    \"\"\"\n    await self._database_pool.execute(\n        INSERT_SCHEDULE_QUERY.format(self._table_name),\n        str(schedule.schedule_id),\n        schedule.task_name,\n        schedule.model_dump_json(\n            exclude={\"schedule_id\", \"task_name\"},\n        ),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgScheduleSource.delete_schedule","title":"delete_schedule  <code>async</code>","text":"<pre><code>delete_schedule(schedule_id)\n</code></pre> <p>Method to delete schedule by id.</p> <p>This is useful for schedule cancelation.</p> <p>Parameters:</p> <ul> <li> <code>schedule_id</code>               (<code>str</code>)           \u2013            <p>id of schedule to delete.</p> </li> </ul> Source code in <code>src/taskiq_pg/asyncpg/schedule_source.py</code> <pre><code>async def delete_schedule(self, schedule_id: str) -&gt; None:\n    \"\"\"\n    Method to delete schedule by id.\n\n    This is useful for schedule cancelation.\n\n    Args:\n        schedule_id: id of schedule to delete.\n    \"\"\"\n    await self._database_pool.execute(\n        DELETE_SCHEDULE_QUERY.format(self._table_name),\n        schedule_id,\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.AsyncpgScheduleSource.post_send","title":"post_send  <code>async</code>","text":"<pre><code>post_send(task)\n</code></pre> <p>Delete a task after it's completed.</p> Source code in <code>src/taskiq_pg/asyncpg/schedule_source.py</code> <pre><code>async def post_send(self, task: ScheduledTask) -&gt; None:\n    \"\"\"Delete a task after it's completed.\"\"\"\n    if task.time is not None:\n        await self.delete_schedule(task.schedule_id)\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.broker","title":"broker","text":""},{"location":"reference/#taskiq_pg.asyncpg.broker.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger('taskiq.asyncpg_broker')\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.broker.AsyncpgBroker","title":"AsyncpgBroker","text":"<pre><code>AsyncpgBroker(\n    dsn=\"postgresql://postgres:postgres@localhost:5432/postgres\",\n    result_backend=None,\n    task_id_generator=None,\n    channel_name=\"taskiq\",\n    table_name=\"taskiq_messages\",\n    max_retry_attempts=5,\n    read_kwargs=None,\n    write_kwargs=None,\n)\n</code></pre> <p>               Bases: <code>BasePostgresBroker</code></p> <p>Broker that uses asyncpg as driver and PostgreSQL with LISTEN/NOTIFY mechanism.</p> <p>Construct a new broker.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>str | Callable[[], str]</code>, default:                   <code>'postgresql://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>connection string to PostgreSQL, or callable returning one.</p> </li> <li> <code>result_backend</code>               (<code>AsyncResultBackend[_T] | None</code>, default:                   <code>None</code> )           \u2013            <p>Custom result backend.</p> </li> <li> <code>task_id_generator</code>               (<code>Callable[[], str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Custom task_id generator.</p> </li> <li> <code>channel_name</code>               (<code>str</code>, default:                   <code>'taskiq'</code> )           \u2013            <p>Name of the channel to listen on.</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_messages'</code> )           \u2013            <p>Name of the table to store messages.</p> </li> <li> <code>max_retry_attempts</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>Maximum number of message processing attempts.</p> </li> <li> <code>read_kwargs</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional arguments for read connection creation.</p> </li> <li> <code>write_kwargs</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional arguments for write pool creation.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/broker.py</code> <pre><code>def __init__(  # noqa: PLR0913\n    self,\n    dsn: str | tp.Callable[[], str] = \"postgresql://postgres:postgres@localhost:5432/postgres\",\n    result_backend: AsyncResultBackend[_T] | None = None,\n    task_id_generator: tp.Callable[[], str] | None = None,\n    channel_name: str = \"taskiq\",\n    table_name: str = \"taskiq_messages\",\n    max_retry_attempts: int = 5,\n    read_kwargs: dict[str, tp.Any] | None = None,\n    write_kwargs: dict[str, tp.Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Construct a new broker.\n\n    Args:\n        dsn: connection string to PostgreSQL, or callable returning one.\n        result_backend: Custom result backend.\n        task_id_generator: Custom task_id generator.\n        channel_name: Name of the channel to listen on.\n        table_name: Name of the table to store messages.\n        max_retry_attempts: Maximum number of message processing attempts.\n        read_kwargs: Additional arguments for read connection creation.\n        write_kwargs: Additional arguments for write pool creation.\n\n    \"\"\"\n    super().__init__(\n        result_backend=result_backend,\n        task_id_generator=task_id_generator,\n    )\n    self._dsn: str | tp.Callable[[], str] = dsn\n    self.channel_name: str = channel_name\n    self.table_name: str = table_name\n    self.read_kwargs: dict[str, tp.Any] = read_kwargs or {}\n    self.write_kwargs: dict[str, tp.Any] = write_kwargs or {}\n    self.max_retry_attempts: int = max_retry_attempts\n    self._queue: asyncio.Queue[str] | None = None\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.broker.AsyncpgBroker.channel_name","title":"channel_name  <code>instance-attribute</code>","text":"<pre><code>channel_name = channel_name\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.broker.AsyncpgBroker.table_name","title":"table_name  <code>instance-attribute</code>","text":"<pre><code>table_name = table_name\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.broker.AsyncpgBroker.read_kwargs","title":"read_kwargs  <code>instance-attribute</code>","text":"<pre><code>read_kwargs = read_kwargs or {}\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.broker.AsyncpgBroker.write_kwargs","title":"write_kwargs  <code>instance-attribute</code>","text":"<pre><code>write_kwargs = write_kwargs or {}\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.broker.AsyncpgBroker.max_retry_attempts","title":"max_retry_attempts  <code>instance-attribute</code>","text":"<pre><code>max_retry_attempts = max_retry_attempts\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.broker.AsyncpgBroker.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>A string with dsn or None if dsn isn't set yet.</p> </li> </ul>"},{"location":"reference/#taskiq_pg.asyncpg.broker.AsyncpgBroker.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the broker.</p> Source code in <code>src/taskiq_pg/asyncpg/broker.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"Initialize the broker.\"\"\"\n    await super().startup()\n\n    self._read_conn = await asyncpg.connect(self.dsn, **self.read_kwargs)\n    self._write_pool = await asyncpg.create_pool(self.dsn, **self.write_kwargs)\n\n    if self._read_conn is None:\n        msg = \"_read_conn not initialized\"\n        raise RuntimeError(msg)\n\n    async with self._write_pool.acquire() as conn:\n        await conn.execute(CREATE_MESSAGE_TABLE_QUERY.format(self.table_name))\n\n    await self._read_conn.add_listener(self.channel_name, self._notification_handler)\n    self._queue = asyncio.Queue()\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.broker.AsyncpgBroker.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close all connections on shutdown.</p> Source code in <code>src/taskiq_pg/asyncpg/broker.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close all connections on shutdown.\"\"\"\n    await super().shutdown()\n    if self._read_conn is not None:\n        await self._read_conn.remove_listener(self.channel_name, self._notification_handler)\n        await self._read_conn.close()\n    if self._write_pool is not None:\n        await self._write_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.broker.AsyncpgBroker.kick","title":"kick  <code>async</code>","text":"<pre><code>kick(message)\n</code></pre> <p>Send message to the channel.</p> <p>Inserts the message into the database and sends a NOTIFY.</p> <p>:param message: Message to send.</p> Source code in <code>src/taskiq_pg/asyncpg/broker.py</code> <pre><code>async def kick(self, message: BrokerMessage) -&gt; None:\n    \"\"\"\n    Send message to the channel.\n\n    Inserts the message into the database and sends a NOTIFY.\n\n    :param message: Message to send.\n    \"\"\"\n    if self._write_pool is None:\n        msg = \"Please run startup before kicking.\"\n        raise ValueError(msg)\n\n    async with self._write_pool.acquire() as conn:\n        # Insert the message into the database\n        message_inserted_id = tp.cast(\n            \"int\",\n            await conn.fetchval(\n                INSERT_MESSAGE_QUERY.format(self.table_name),\n                message.task_id,\n                message.task_name,\n                message.message.decode(),\n                json.dumps(message.labels),\n            ),\n        )\n\n        delay_value = message.labels.get(\"delay\")\n        if delay_value is not None:\n            delay_seconds = int(delay_value)\n            _ = asyncio.create_task(  # noqa: RUF006\n                self._schedule_notification(message_inserted_id, delay_seconds),\n            )\n        else:\n            # Send a NOTIFY with the message ID as payload\n            _ = await conn.execute(\n                f\"NOTIFY {self.channel_name}, '{message_inserted_id}'\",\n            )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.broker.AsyncpgBroker.listen","title":"listen  <code>async</code>","text":"<pre><code>listen()\n</code></pre> <p>Listen to the channel.</p> <p>Yields messages as they are received.</p> <p>:yields: AckableMessage instances.</p> Source code in <code>src/taskiq_pg/asyncpg/broker.py</code> <pre><code>async def listen(self) -&gt; AsyncGenerator[AckableMessage, None]:\n    \"\"\"\n    Listen to the channel.\n\n    Yields messages as they are received.\n\n    :yields: AckableMessage instances.\n    \"\"\"\n    if self._write_pool is None:\n        msg = \"Call startup before starting listening.\"\n        raise ValueError(msg)\n    if self._queue is None:\n        msg = \"Startup did not initialize the queue.\"\n        raise ValueError(msg)\n\n    while True:\n        try:\n            payload = await self._queue.get()\n            message_id = int(payload)\n            async with self._write_pool.acquire() as conn:\n                claimed = await conn.fetchrow(\n                    CLAIM_MESSAGE_QUERY.format(self.table_name),\n                    message_id,\n                )\n            if claimed is None:\n                continue\n            message_str = claimed[\"message\"]\n            if not isinstance(message_str, str):\n                msg = \"message is not a string\"\n                raise TypeError(msg)\n            message_data = message_str.encode()\n\n            async def ack(*, _message_id: int = message_id) -&gt; None:\n                if self._write_pool is None:\n                    msg = \"Call startup before starting listening.\"\n                    raise ValueError(msg)\n\n                async with self._write_pool.acquire() as conn:\n                    _ = await conn.execute(\n                        DELETE_MESSAGE_QUERY.format(self.table_name),\n                        _message_id,\n                    )\n\n            yield AckableMessage(data=message_data, ack=ack)\n        except Exception:\n            logger.exception(\"Error processing message\")\n            continue\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries","title":"queries","text":""},{"location":"reference/#taskiq_pg.asyncpg.queries.CREATE_TABLE_QUERY","title":"CREATE_TABLE_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_TABLE_QUERY = \"\\nCREATE TABLE IF NOT EXISTS {} (\\n    task_id {} UNIQUE,\\n    result BYTEA,\\n    progress BYTEA\\n)\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.ADD_PROGRESS_COLUMN_QUERY","title":"ADD_PROGRESS_COLUMN_QUERY  <code>module-attribute</code>","text":"<pre><code>ADD_PROGRESS_COLUMN_QUERY = \"\\nALTER TABLE {} ADD COLUMN IF NOT EXISTS progress BYTEA;\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.CREATE_INDEX_QUERY","title":"CREATE_INDEX_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_INDEX_QUERY = \"\\nCREATE INDEX IF NOT EXISTS {}_task_id_idx ON {} USING HASH (task_id)\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.INSERT_RESULT_QUERY","title":"INSERT_RESULT_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_RESULT_QUERY = \"\\nINSERT INTO {} VALUES ($1, $2, NULL)\\nON CONFLICT (task_id)\\nDO UPDATE\\nSET result = $2\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.INSERT_PROGRESS_QUERY","title":"INSERT_PROGRESS_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_PROGRESS_QUERY = \"\\nINSERT INTO {} VALUES ($1, NULL, $2)\\nON CONFLICT (task_id)\\nDO UPDATE\\nSET progress = $2\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.SELECT_PROGRESS_QUERY","title":"SELECT_PROGRESS_QUERY  <code>module-attribute</code>","text":"<pre><code>SELECT_PROGRESS_QUERY = (\n    \"\\nSELECT progress FROM {} WHERE task_id = $1\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.IS_RESULT_EXISTS_QUERY","title":"IS_RESULT_EXISTS_QUERY  <code>module-attribute</code>","text":"<pre><code>IS_RESULT_EXISTS_QUERY = \"\\nSELECT EXISTS(\\n    SELECT 1 FROM {} WHERE task_id = $1 and result IS NOT NULL\\n)\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.SELECT_RESULT_QUERY","title":"SELECT_RESULT_QUERY  <code>module-attribute</code>","text":"<pre><code>SELECT_RESULT_QUERY = (\n    \"\\nSELECT result FROM {} WHERE task_id = $1\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.DELETE_RESULT_QUERY","title":"DELETE_RESULT_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_RESULT_QUERY = (\n    \"\\nDELETE FROM {} WHERE task_id = $1\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.CREATE_MESSAGE_TABLE_QUERY","title":"CREATE_MESSAGE_TABLE_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_MESSAGE_TABLE_QUERY = \"\\nCREATE TABLE IF NOT EXISTS {} (\\n    id SERIAL PRIMARY KEY,\\n    task_id VARCHAR NOT NULL,\\n    task_name VARCHAR NOT NULL,\\n    message TEXT NOT NULL,\\n    labels JSONB NOT NULL,\\n    status TEXT NOT NULL DEFAULT 'pending',\\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\\n);\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.INSERT_MESSAGE_QUERY","title":"INSERT_MESSAGE_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_MESSAGE_QUERY = \"\\nINSERT INTO {} (task_id, task_name, message, labels)\\nVALUES ($1, $2, $3, $4)\\nRETURNING id\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.CLAIM_MESSAGE_QUERY","title":"CLAIM_MESSAGE_QUERY  <code>module-attribute</code>","text":"<pre><code>CLAIM_MESSAGE_QUERY = \"UPDATE {} SET status = 'processing' WHERE id = $1 AND status = 'pending' RETURNING id, message\"\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.DELETE_MESSAGE_QUERY","title":"DELETE_MESSAGE_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_MESSAGE_QUERY = 'DELETE FROM {} WHERE id = $1'\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.CREATE_SCHEDULES_TABLE_QUERY","title":"CREATE_SCHEDULES_TABLE_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_SCHEDULES_TABLE_QUERY = \"\\nCREATE TABLE IF NOT EXISTS {} (\\n    id UUID PRIMARY KEY,\\n    task_name VARCHAR(100) NOT NULL,\\n    schedule JSONB NOT NULL,\\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\\n);\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.INSERT_SCHEDULE_QUERY","title":"INSERT_SCHEDULE_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_SCHEDULE_QUERY = \"\\nINSERT INTO {} (id, task_name, schedule)\\nVALUES ($1, $2, $3)\\nON CONFLICT (id) DO UPDATE\\nSET task_name = EXCLUDED.task_name,\\n    schedule = EXCLUDED.schedule,\\n    updated_at = NOW();\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.SELECT_SCHEDULES_QUERY","title":"SELECT_SCHEDULES_QUERY  <code>module-attribute</code>","text":"<pre><code>SELECT_SCHEDULES_QUERY = (\n    \"\\nSELECT id, task_name, schedule\\nFROM {};\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.DELETE_ALL_SCHEDULES_QUERY","title":"DELETE_ALL_SCHEDULES_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_ALL_SCHEDULES_QUERY = '\\nDELETE FROM {};\\n'\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.queries.DELETE_SCHEDULE_QUERY","title":"DELETE_SCHEDULE_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_SCHEDULE_QUERY = '\\nDELETE FROM {} WHERE id = $1;\\n'\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.result_backend","title":"result_backend","text":""},{"location":"reference/#taskiq_pg.asyncpg.result_backend.AsyncpgResultBackend","title":"AsyncpgResultBackend","text":"<pre><code>AsyncpgResultBackend(\n    dsn=\"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results=True,\n    table_name=\"taskiq_results\",\n    field_for_task_id=\"VarChar\",\n    serializer=None,\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresResultBackend</code></p> <p>Result backend for TaskIQ based on asyncpg.</p> <p>Construct new result backend.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>Callable[[], str] | str | None</code>, default:                   <code>'postgres://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>connection string to PostgreSQL, or callable returning one.</p> </li> <li> <code>keep_results</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>flag to not remove results from the database after reading.</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_results'</code> )           \u2013            <p>name of the table to store results.</p> </li> <li> <code>field_for_task_id</code>               (<code>Literal['VarChar', 'Text', 'Uuid']</code>, default:                   <code>'VarChar'</code> )           \u2013            <p>type of the field to store task_id.</p> </li> <li> <code>serializer</code>               (<code>TaskiqSerializer | None</code>, default:                   <code>None</code> )           \u2013            <p>serializer class to serialize/deserialize result from task.</p> </li> <li> <code>connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>additional arguments for creating connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/result_backend.py</code> <pre><code>def __init__(\n    self,\n    dsn: tp.Callable[[], str] | str | None = \"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results: bool = True,\n    table_name: str = \"taskiq_results\",\n    field_for_task_id: tp.Literal[\"VarChar\", \"Text\", \"Uuid\"] = \"VarChar\",\n    serializer: TaskiqSerializer | None = None,\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Construct new result backend.\n\n    Args:\n        dsn: connection string to PostgreSQL, or callable returning one.\n        keep_results: flag to not remove results from the database after reading.\n        table_name: name of the table to store results.\n        field_for_task_id: type of the field to store task_id.\n        serializer: serializer class to serialize/deserialize result from task.\n        connect_kwargs: additional arguments for creating connection pool.\n\n    \"\"\"\n    self._dsn: tp.Final = dsn\n    self.keep_results: tp.Final = keep_results\n    self.table_name: tp.Final = table_name\n    self.field_for_task_id: tp.Final = field_for_task_id\n    self.connect_kwargs: tp.Final = connect_kwargs\n    self.serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.result_backend.AsyncpgResultBackend.keep_results","title":"keep_results  <code>instance-attribute</code>","text":"<pre><code>keep_results = keep_results\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.result_backend.AsyncpgResultBackend.table_name","title":"table_name  <code>instance-attribute</code>","text":"<pre><code>table_name = table_name\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.result_backend.AsyncpgResultBackend.field_for_task_id","title":"field_for_task_id  <code>instance-attribute</code>","text":"<pre><code>field_for_task_id = field_for_task_id\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.result_backend.AsyncpgResultBackend.connect_kwargs","title":"connect_kwargs  <code>instance-attribute</code>","text":"<pre><code>connect_kwargs = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.result_backend.AsyncpgResultBackend.serializer","title":"serializer  <code>instance-attribute</code>","text":"<pre><code>serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.result_backend.AsyncpgResultBackend.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.asyncpg.result_backend.AsyncpgResultBackend.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the result backend.</p> <p>Construct new connection pool and create new table for results if not exists.</p> Source code in <code>src/taskiq_pg/asyncpg/result_backend.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the result backend.\n\n    Construct new connection pool and create new table for results if not exists.\n    \"\"\"\n    _database_pool = await asyncpg.create_pool(\n        dsn=self.dsn,\n        **self.connect_kwargs,\n    )\n    self._database_pool = _database_pool\n\n    await self._database_pool.execute(\n        queries.CREATE_TABLE_QUERY.format(\n            self.table_name,\n            self.field_for_task_id,\n        ),\n    )\n    await self._database_pool.execute(\n        queries.ADD_PROGRESS_COLUMN_QUERY.format(\n            self.table_name,\n        ),\n    )\n    await self._database_pool.execute(\n        queries.CREATE_INDEX_QUERY.format(\n            self.table_name,\n            self.table_name,\n        ),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.result_backend.AsyncpgResultBackend.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/asyncpg/result_backend.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        await self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.result_backend.AsyncpgResultBackend.set_result","title":"set_result  <code>async</code>","text":"<pre><code>set_result(task_id, result)\n</code></pre> <p>Set result to the PostgreSQL table.</p> <p>:param task_id: ID of the task. :param result: result of the task.</p> Source code in <code>src/taskiq_pg/asyncpg/result_backend.py</code> <pre><code>async def set_result(\n    self,\n    task_id: str,\n    result: TaskiqResult[ReturnType],\n) -&gt; None:\n    \"\"\"\n    Set result to the PostgreSQL table.\n\n    :param task_id: ID of the task.\n    :param result: result of the task.\n    \"\"\"\n    _ = await self._database_pool.execute(\n        queries.INSERT_RESULT_QUERY.format(\n            self.table_name,\n        ),\n        task_id,\n        self.serializer.dumpb(model_dump(result)),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.result_backend.AsyncpgResultBackend.is_result_ready","title":"is_result_ready  <code>async</code>","text":"<pre><code>is_result_ready(task_id)\n</code></pre> <p>Returns whether the result is ready.</p> <p>:param task_id: ID of the task. :returns: True if the result is ready else False.</p> Source code in <code>src/taskiq_pg/asyncpg/result_backend.py</code> <pre><code>async def is_result_ready(self, task_id: str) -&gt; bool:\n    \"\"\"\n    Returns whether the result is ready.\n\n    :param task_id: ID of the task.\n    :returns: True if the result is ready else False.\n    \"\"\"\n    return tp.cast(\n        \"bool\",\n        await self._database_pool.fetchval(\n            queries.IS_RESULT_EXISTS_QUERY.format(\n                self.table_name,\n            ),\n            task_id,\n        ),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.result_backend.AsyncpgResultBackend.get_result","title":"get_result  <code>async</code>","text":"<pre><code>get_result(task_id, with_logs=False)\n</code></pre> <p>Retrieve result from the task.</p> <p>:param task_id: task's id. :param with_logs: if True it will download task's logs. (deprecated in taskiq) :raises ResultIsMissingError: if there is no result when trying to get it. :return: TaskiqResult.</p> Source code in <code>src/taskiq_pg/asyncpg/result_backend.py</code> <pre><code>async def get_result(\n    self,\n    task_id: str,\n    with_logs: bool = False,\n) -&gt; TaskiqResult[ReturnType]:\n    \"\"\"\n    Retrieve result from the task.\n\n    :param task_id: task's id.\n    :param with_logs: if True it will download task's logs. (deprecated in taskiq)\n    :raises ResultIsMissingError: if there is no result when trying to get it.\n    :return: TaskiqResult.\n    \"\"\"\n    result_in_bytes = tp.cast(\n        \"bytes\",\n        await self._database_pool.fetchval(\n            queries.SELECT_RESULT_QUERY.format(\n                self.table_name,\n            ),\n            task_id,\n        ),\n    )\n    if not self.keep_results:\n        await self._database_pool.execute(\n            queries.DELETE_RESULT_QUERY.format(\n                self.table_name,\n            ),\n            task_id,\n        )\n    taskiq_result: tp.Final = model_validate(\n        TaskiqResult[ReturnType],\n        self.serializer.loadb(result_in_bytes),\n    )\n    if not with_logs:\n        taskiq_result.log = None\n    return taskiq_result\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.result_backend.AsyncpgResultBackend.set_progress","title":"set_progress  <code>async</code>","text":"<pre><code>set_progress(task_id, progress)\n</code></pre> <p>Saves progress.</p> <p>:param task_id: task's id. :param progress: progress of execution.</p> Source code in <code>src/taskiq_pg/asyncpg/result_backend.py</code> <pre><code>async def set_progress(\n    self,\n    task_id: str,\n    progress: TaskProgress[tp.Any],\n) -&gt; None:\n    \"\"\"\n    Saves progress.\n\n    :param task_id: task's id.\n    :param progress: progress of execution.\n    \"\"\"\n    await self._database_pool.execute(\n        queries.INSERT_PROGRESS_QUERY.format(\n            self.table_name,\n        ),\n        task_id,\n        self.serializer.dumpb(model_dump(progress)),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.result_backend.AsyncpgResultBackend.get_progress","title":"get_progress  <code>async</code>","text":"<pre><code>get_progress(task_id)\n</code></pre> <p>Gets progress.</p> <p>:param task_id: task's id.</p> Source code in <code>src/taskiq_pg/asyncpg/result_backend.py</code> <pre><code>async def get_progress(\n    self,\n    task_id: str,\n) -&gt; TaskProgress[tp.Any] | None:\n    \"\"\"\n    Gets progress.\n\n    :param task_id: task's id.\n    \"\"\"\n    progress_in_bytes = await self._database_pool.fetchval(\n        queries.SELECT_PROGRESS_QUERY.format(\n            self.table_name,\n        ),\n        task_id,\n    )\n    if progress_in_bytes is None:\n        return None\n    return model_validate(\n        TaskProgress[tp.Any],\n        self.serializer.loadb(progress_in_bytes),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.schedule_source","title":"schedule_source","text":""},{"location":"reference/#taskiq_pg.asyncpg.schedule_source.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger('taskiq_pg.asyncpg_schedule_source')\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.schedule_source.AsyncpgScheduleSource","title":"AsyncpgScheduleSource","text":"<pre><code>AsyncpgScheduleSource(\n    broker,\n    dsn=\"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name=\"taskiq_schedules\",\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresScheduleSource</code></p> <p>Schedule source that uses asyncpg to store schedules in PostgreSQL.</p> <p>Initialize the PostgreSQL scheduler source.</p> <p>Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database. This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks across application restarts.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>str | Callable[[], str]</code>, default:                   <code>'postgresql://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>PostgreSQL connection string</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_schedules'</code> )           \u2013            <p>Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.</p> </li> <li> <code>broker</code>               (<code>AsyncBroker</code>)           \u2013            <p>The TaskIQ broker instance to use for finding and managing tasks. Required if startup_schedule is provided.</p> </li> <li> <code>**connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional keyword arguments passed to the database connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def __init__(\n    self,\n    broker: AsyncBroker,\n    dsn: str | tp.Callable[[], str] = \"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name: str = \"taskiq_schedules\",\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Initialize the PostgreSQL scheduler source.\n\n    Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database.\n    This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks\n    across application restarts.\n\n    Args:\n        dsn: PostgreSQL connection string\n        table_name: Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.\n        broker: The TaskIQ broker instance to use for finding and managing tasks.\n            Required if startup_schedule is provided.\n        **connect_kwargs: Additional keyword arguments passed to the database connection pool.\n\n    \"\"\"\n    self._broker: tp.Final = broker\n    self._dsn: tp.Final = dsn\n    self._table_name: tp.Final = table_name\n    self._connect_kwargs: tp.Final = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.schedule_source.AsyncpgScheduleSource.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.asyncpg.schedule_source.AsyncpgScheduleSource.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the schedule source.</p> <p>Construct new connection pool, create new table for schedules if not exists and fill table with schedules from task labels.</p> Source code in <code>src/taskiq_pg/asyncpg/schedule_source.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the schedule source.\n\n    Construct new connection pool, create new table for schedules if not exists\n    and fill table with schedules from task labels.\n    \"\"\"\n    self._database_pool = await asyncpg.create_pool(\n        dsn=self.dsn,\n        **self._connect_kwargs,\n    )\n    await self._database_pool.execute(\n        CREATE_SCHEDULES_TABLE_QUERY.format(\n            self._table_name,\n        ),\n    )\n    scheduled_tasks_for_creation = self.extract_scheduled_tasks_from_broker()\n    await self._update_schedules_on_startup(scheduled_tasks_for_creation)\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.schedule_source.AsyncpgScheduleSource.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/asyncpg/schedule_source.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        await self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.schedule_source.AsyncpgScheduleSource.get_schedules","title":"get_schedules  <code>async</code>","text":"<pre><code>get_schedules()\n</code></pre> <p>Fetch schedules from the database.</p> Source code in <code>src/taskiq_pg/asyncpg/schedule_source.py</code> <pre><code>async def get_schedules(self) -&gt; list[\"ScheduledTask\"]:\n    \"\"\"Fetch schedules from the database.\"\"\"\n    async with self._database_pool.acquire() as conn:\n        rows_with_schedules = await conn.fetch(\n            SELECT_SCHEDULES_QUERY.format(self._table_name),\n        )\n    schedules = []\n    for row in rows_with_schedules:\n        schedule = json.loads(row[\"schedule\"])\n        schedules.append(\n            ScheduledTask.model_validate(\n                {\n                    \"schedule_id\": str(row[\"id\"]),\n                    \"task_name\": row[\"task_name\"],\n                    \"labels\": schedule[\"labels\"],\n                    \"args\": schedule[\"args\"],\n                    \"kwargs\": schedule[\"kwargs\"],\n                    \"cron\": schedule[\"cron\"],\n                    \"cron_offset\": schedule[\"cron_offset\"],\n                    \"time\": schedule[\"time\"],\n                    \"interval\": schedule[\"interval\"],\n                },\n            ),\n        )\n    return schedules\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.schedule_source.AsyncpgScheduleSource.add_schedule","title":"add_schedule  <code>async</code>","text":"<pre><code>add_schedule(schedule)\n</code></pre> <p>Add a new schedule.</p> <p>Parameters:</p> <ul> <li> <code>schedule</code>               (<code>ScheduledTask</code>)           \u2013            <p>schedule to add.</p> </li> </ul> Source code in <code>src/taskiq_pg/asyncpg/schedule_source.py</code> <pre><code>async def add_schedule(self, schedule: \"ScheduledTask\") -&gt; None:\n    \"\"\"\n    Add a new schedule.\n\n    Args:\n        schedule: schedule to add.\n    \"\"\"\n    await self._database_pool.execute(\n        INSERT_SCHEDULE_QUERY.format(self._table_name),\n        str(schedule.schedule_id),\n        schedule.task_name,\n        schedule.model_dump_json(\n            exclude={\"schedule_id\", \"task_name\"},\n        ),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.schedule_source.AsyncpgScheduleSource.delete_schedule","title":"delete_schedule  <code>async</code>","text":"<pre><code>delete_schedule(schedule_id)\n</code></pre> <p>Method to delete schedule by id.</p> <p>This is useful for schedule cancelation.</p> <p>Parameters:</p> <ul> <li> <code>schedule_id</code>               (<code>str</code>)           \u2013            <p>id of schedule to delete.</p> </li> </ul> Source code in <code>src/taskiq_pg/asyncpg/schedule_source.py</code> <pre><code>async def delete_schedule(self, schedule_id: str) -&gt; None:\n    \"\"\"\n    Method to delete schedule by id.\n\n    This is useful for schedule cancelation.\n\n    Args:\n        schedule_id: id of schedule to delete.\n    \"\"\"\n    await self._database_pool.execute(\n        DELETE_SCHEDULE_QUERY.format(self._table_name),\n        schedule_id,\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.schedule_source.AsyncpgScheduleSource.post_send","title":"post_send  <code>async</code>","text":"<pre><code>post_send(task)\n</code></pre> <p>Delete a task after it's completed.</p> Source code in <code>src/taskiq_pg/asyncpg/schedule_source.py</code> <pre><code>async def post_send(self, task: ScheduledTask) -&gt; None:\n    \"\"\"Delete a task after it's completed.\"\"\"\n    if task.time is not None:\n        await self.delete_schedule(task.schedule_id)\n</code></pre>"},{"location":"reference/#taskiq_pg.asyncpg.schedule_source.AsyncpgScheduleSource.extract_scheduled_tasks_from_broker","title":"extract_scheduled_tasks_from_broker","text":"<pre><code>extract_scheduled_tasks_from_broker()\n</code></pre> <p>Extract schedules from tasks that were registered in broker.</p> <p>Returns:</p> <ul> <li> <code>list[ScheduledTask]</code>           \u2013            <p>A list of ScheduledTask instances extracted from the task's labels.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def extract_scheduled_tasks_from_broker(self) -&gt; list[ScheduledTask]:\n    \"\"\"\n    Extract schedules from tasks that were registered in broker.\n\n    Returns:\n        A list of ScheduledTask instances extracted from the task's labels.\n    \"\"\"\n    scheduled_tasks_for_creation: list[ScheduledTask] = []\n    for task_name, task in self._broker.get_all_tasks().items():\n        if \"schedule\" not in task.labels:\n            logger.debug(\"Task %s has no schedule, skipping\", task_name)\n            continue\n        if not isinstance(task.labels[\"schedule\"], list):\n            logger.warning(\n                \"Schedule for task %s is not a list, skipping\",\n                task_name,\n            )\n            continue\n        for schedule in task.labels[\"schedule\"]:\n            try:\n                new_schedule = ScheduledTask.model_validate(\n                    {\n                        \"task_name\": task_name,\n                        \"labels\": schedule.get(\"labels\", {}),\n                        \"args\": schedule.get(\"args\", []),\n                        \"kwargs\": schedule.get(\"kwargs\", {}),\n                        \"schedule_id\": str(uuid.uuid4()),\n                        \"cron\": schedule.get(\"cron\", None),\n                        \"cron_offset\": schedule.get(\"cron_offset\", None),\n                        \"interval\": schedule.get(\"interval\", None),\n                        \"time\": schedule.get(\"time\", None),\n                    },\n                )\n                scheduled_tasks_for_creation.append(new_schedule)\n            except ValidationError:  # noqa: PERF203\n                logger.exception(\n                    \"Schedule for task %s is not valid, skipping\",\n                    task_name,\n                )\n                continue\n    return scheduled_tasks_for_creation\n</code></pre>"},{"location":"reference/#taskiq_pg.exceptions","title":"exceptions","text":""},{"location":"reference/#taskiq_pg.exceptions.BaseTaskiqPgError","title":"BaseTaskiqPgError","text":"<p>               Bases: <code>Exception</code></p> <p>Base error for all possible exception in the lib.</p>"},{"location":"reference/#taskiq_pg.exceptions.DatabaseConnectionError","title":"DatabaseConnectionError","text":"<p>               Bases: <code>BaseTaskiqPgError</code></p> <p>Error if cannot connect to PostgreSQL.</p>"},{"location":"reference/#taskiq_pg.exceptions.ResultIsMissingError","title":"ResultIsMissingError","text":"<p>               Bases: <code>BaseTaskiqPgError</code></p> <p>Error if cannot retrieve result from PostgreSQL.</p>"},{"location":"reference/#taskiq_pg.psqlpy","title":"psqlpy","text":""},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyBroker","title":"PSQLPyBroker","text":"<pre><code>PSQLPyBroker(\n    dsn=\"postgresql://postgres:postgres@localhost:5432/postgres\",\n    result_backend=None,\n    task_id_generator=None,\n    channel_name=\"taskiq\",\n    table_name=\"taskiq_messages\",\n    max_retry_attempts=5,\n    read_kwargs=None,\n    write_kwargs=None,\n)\n</code></pre> <p>               Bases: <code>BasePostgresBroker</code></p> <p>Broker that uses PostgreSQL and PSQLPy with LISTEN/NOTIFY.</p> <p>Construct a new broker.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>str | Callable[[], str]</code>, default:                   <code>'postgresql://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>connection string to PostgreSQL, or callable returning one.</p> </li> <li> <code>result_backend</code>               (<code>AsyncResultBackend[_T] | None</code>, default:                   <code>None</code> )           \u2013            <p>Custom result backend.</p> </li> <li> <code>task_id_generator</code>               (<code>Callable[[], str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Custom task_id generator.</p> </li> <li> <code>channel_name</code>               (<code>str</code>, default:                   <code>'taskiq'</code> )           \u2013            <p>Name of the channel to listen on.</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_messages'</code> )           \u2013            <p>Name of the table to store messages.</p> </li> <li> <code>max_retry_attempts</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>Maximum number of message processing attempts.</p> </li> <li> <code>read_kwargs</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional arguments for read connection creation.</p> </li> <li> <code>write_kwargs</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional arguments for write pool creation.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/broker.py</code> <pre><code>def __init__(  # noqa: PLR0913\n    self,\n    dsn: str | tp.Callable[[], str] = \"postgresql://postgres:postgres@localhost:5432/postgres\",\n    result_backend: AsyncResultBackend[_T] | None = None,\n    task_id_generator: tp.Callable[[], str] | None = None,\n    channel_name: str = \"taskiq\",\n    table_name: str = \"taskiq_messages\",\n    max_retry_attempts: int = 5,\n    read_kwargs: dict[str, tp.Any] | None = None,\n    write_kwargs: dict[str, tp.Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Construct a new broker.\n\n    Args:\n        dsn: connection string to PostgreSQL, or callable returning one.\n        result_backend: Custom result backend.\n        task_id_generator: Custom task_id generator.\n        channel_name: Name of the channel to listen on.\n        table_name: Name of the table to store messages.\n        max_retry_attempts: Maximum number of message processing attempts.\n        read_kwargs: Additional arguments for read connection creation.\n        write_kwargs: Additional arguments for write pool creation.\n\n    \"\"\"\n    super().__init__(\n        result_backend=result_backend,\n        task_id_generator=task_id_generator,\n    )\n    self._dsn: str | tp.Callable[[], str] = dsn\n    self.channel_name: str = channel_name\n    self.table_name: str = table_name\n    self.read_kwargs: dict[str, tp.Any] = read_kwargs or {}\n    self.write_kwargs: dict[str, tp.Any] = write_kwargs or {}\n    self.max_retry_attempts: int = max_retry_attempts\n    self._queue: asyncio.Queue[str] | None = None\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyBroker.channel_name","title":"channel_name  <code>instance-attribute</code>","text":"<pre><code>channel_name = channel_name\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyBroker.table_name","title":"table_name  <code>instance-attribute</code>","text":"<pre><code>table_name = table_name\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyBroker.read_kwargs","title":"read_kwargs  <code>instance-attribute</code>","text":"<pre><code>read_kwargs = read_kwargs or {}\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyBroker.write_kwargs","title":"write_kwargs  <code>instance-attribute</code>","text":"<pre><code>write_kwargs = write_kwargs or {}\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyBroker.max_retry_attempts","title":"max_retry_attempts  <code>instance-attribute</code>","text":"<pre><code>max_retry_attempts = max_retry_attempts\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyBroker.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>A string with dsn or None if dsn isn't set yet.</p> </li> </ul>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyBroker.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the broker.</p> Source code in <code>src/taskiq_pg/psqlpy/broker.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"Initialize the broker.\"\"\"\n    await super().startup()\n    self._read_conn = await psqlpy.connect(\n        dsn=self.dsn,\n        **self.read_kwargs,\n    )\n    self._write_pool = psqlpy.ConnectionPool(\n        dsn=self.dsn,\n        **self.write_kwargs,\n    )\n\n    # create messages table if it doesn't exist\n    async with self._write_pool.acquire() as conn:\n        await conn.execute(CREATE_MESSAGE_TABLE_QUERY.format(self.table_name))\n\n    # listen to notification channel\n    self._listener = self._write_pool.listener()\n    await self._listener.add_callback(self.channel_name, self._notification_handler)\n    await self._listener.startup()\n    self._listener.listen()\n\n    self._queue = asyncio.Queue()\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyBroker.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close all connections on shutdown.</p> Source code in <code>src/taskiq_pg/psqlpy/broker.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close all connections on shutdown.\"\"\"\n    await super().shutdown()\n    if self._read_conn is not None:\n        self._read_conn.close()\n    if self._write_pool is not None:\n        self._write_pool.close()\n    if self._listener is not None:\n        self._listener.abort_listen()\n        await self._listener.shutdown()\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyBroker.kick","title":"kick  <code>async</code>","text":"<pre><code>kick(message)\n</code></pre> <p>Send message to the channel.</p> <p>Inserts the message into the database and sends a NOTIFY.</p> <p>:param message: Message to send.</p> Source code in <code>src/taskiq_pg/psqlpy/broker.py</code> <pre><code>async def kick(self, message: BrokerMessage) -&gt; None:\n    \"\"\"\n    Send message to the channel.\n\n    Inserts the message into the database and sends a NOTIFY.\n\n    :param message: Message to send.\n    \"\"\"\n    async with self._write_pool.acquire() as conn:\n        # insert message into db table\n        message_inserted_id = tp.cast(\n            \"int\",\n            await conn.fetch_val(\n                INSERT_MESSAGE_QUERY.format(self.table_name),\n                [\n                    message.task_id,\n                    message.task_name,\n                    message.message.decode(),\n                    JSONB(message.labels),\n                ],\n            ),\n        )\n\n        delay_value = tp.cast(\"str | None\", message.labels.get(\"delay\"))\n        if delay_value is not None:\n            delay_seconds = int(delay_value)\n            asyncio.create_task(  # noqa: RUF006\n                self._schedule_notification(message_inserted_id, delay_seconds),\n            )\n        else:\n            # Send NOTIFY with message ID as payload\n            _ = await conn.execute(\n                f\"NOTIFY {self.channel_name}, '{message_inserted_id}'\",\n            )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyBroker.listen","title":"listen  <code>async</code>","text":"<pre><code>listen()\n</code></pre> <p>Listen to the channel.</p> <p>Yields messages as they are received.</p> <p>:yields: AckableMessage instances.</p> Source code in <code>src/taskiq_pg/psqlpy/broker.py</code> <pre><code>async def listen(self) -&gt; AsyncGenerator[AckableMessage, None]:\n    \"\"\"\n    Listen to the channel.\n\n    Yields messages as they are received.\n\n    :yields: AckableMessage instances.\n    \"\"\"\n    while True:\n        try:\n            payload = await self._queue.get()\n            message_id = int(payload)  # payload is the message id\n            try:\n                async with self._write_pool.acquire() as conn:\n                    claimed_message = await conn.fetch_row(\n                        CLAIM_MESSAGE_QUERY.format(self.table_name),\n                        [message_id],\n                    )\n            except ConnectionExecuteError:  # message was claimed by another worker\n                continue\n            message_row_result = tp.cast(\n                \"MessageRow\",\n                tp.cast(\"object\", claimed_message.as_class(MessageRow)),\n            )\n            message_data = message_row_result.message.encode()\n\n            async def ack(*, _message_id: int = message_id) -&gt; None:\n                async with self._write_pool.acquire() as conn:\n                    _ = await conn.execute(\n                        DELETE_MESSAGE_QUERY.format(self.table_name),\n                        [_message_id],\n                    )\n\n            yield AckableMessage(data=message_data, ack=ack)\n        except Exception:\n            logger.exception(\"Error processing message\")\n            continue\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyResultBackend","title":"PSQLPyResultBackend","text":"<pre><code>PSQLPyResultBackend(\n    dsn=\"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results=True,\n    table_name=\"taskiq_results\",\n    field_for_task_id=\"VarChar\",\n    serializer=None,\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresResultBackend</code></p> <p>Result backend for TaskIQ based on PSQLPy.</p> <p>Construct new result backend.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>Callable[[], str] | str | None</code>, default:                   <code>'postgres://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>connection string to PostgreSQL, or callable returning one.</p> </li> <li> <code>keep_results</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>flag to not remove results from the database after reading.</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_results'</code> )           \u2013            <p>name of the table to store results.</p> </li> <li> <code>field_for_task_id</code>               (<code>Literal['VarChar', 'Text', 'Uuid']</code>, default:                   <code>'VarChar'</code> )           \u2013            <p>type of the field to store task_id.</p> </li> <li> <code>serializer</code>               (<code>TaskiqSerializer | None</code>, default:                   <code>None</code> )           \u2013            <p>serializer class to serialize/deserialize result from task.</p> </li> <li> <code>connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>additional arguments for creating connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/result_backend.py</code> <pre><code>def __init__(\n    self,\n    dsn: tp.Callable[[], str] | str | None = \"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results: bool = True,\n    table_name: str = \"taskiq_results\",\n    field_for_task_id: tp.Literal[\"VarChar\", \"Text\", \"Uuid\"] = \"VarChar\",\n    serializer: TaskiqSerializer | None = None,\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Construct new result backend.\n\n    Args:\n        dsn: connection string to PostgreSQL, or callable returning one.\n        keep_results: flag to not remove results from the database after reading.\n        table_name: name of the table to store results.\n        field_for_task_id: type of the field to store task_id.\n        serializer: serializer class to serialize/deserialize result from task.\n        connect_kwargs: additional arguments for creating connection pool.\n\n    \"\"\"\n    self._dsn: tp.Final = dsn\n    self.keep_results: tp.Final = keep_results\n    self.table_name: tp.Final = table_name\n    self.field_for_task_id: tp.Final = field_for_task_id\n    self.connect_kwargs: tp.Final = connect_kwargs\n    self.serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyResultBackend.keep_results","title":"keep_results  <code>instance-attribute</code>","text":"<pre><code>keep_results = keep_results\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyResultBackend.table_name","title":"table_name  <code>instance-attribute</code>","text":"<pre><code>table_name = table_name\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyResultBackend.field_for_task_id","title":"field_for_task_id  <code>instance-attribute</code>","text":"<pre><code>field_for_task_id = field_for_task_id\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyResultBackend.connect_kwargs","title":"connect_kwargs  <code>instance-attribute</code>","text":"<pre><code>connect_kwargs = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyResultBackend.serializer","title":"serializer  <code>instance-attribute</code>","text":"<pre><code>serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyResultBackend.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyResultBackend.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the result backend.</p> <p>Construct new connection pool and create new table for results if not exists.</p> Source code in <code>src/taskiq_pg/psqlpy/result_backend.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the result backend.\n\n    Construct new connection pool\n    and create new table for results if not exists.\n    \"\"\"\n    self._database_pool = ConnectionPool(\n        dsn=self.dsn,\n        **self.connect_kwargs,\n    )\n    connection = await self._database_pool.connection()\n    await connection.execute(\n        querystring=queries.CREATE_TABLE_QUERY.format(\n            self.table_name,\n            self.field_for_task_id,\n        ),\n    )\n    await connection.execute(\n        querystring=queries.ADD_PROGRESS_COLUMN_QUERY.format(\n            self.table_name,\n        ),\n    )\n    await connection.execute(\n        querystring=queries.CREATE_INDEX_QUERY.format(\n            self.table_name,\n            self.table_name,\n        ),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyResultBackend.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/psqlpy/result_backend.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyResultBackend.set_result","title":"set_result  <code>async</code>","text":"<pre><code>set_result(task_id, result)\n</code></pre> <p>Set result to the PostgreSQL table.</p> <p>:param task_id: ID of the task. :param result: result of the task.</p> Source code in <code>src/taskiq_pg/psqlpy/result_backend.py</code> <pre><code>async def set_result(\n    self,\n    task_id: str,\n    result: TaskiqResult[ReturnType],\n) -&gt; None:\n    \"\"\"\n    Set result to the PostgreSQL table.\n\n    :param task_id: ID of the task.\n    :param result: result of the task.\n    \"\"\"\n    connection = await self._database_pool.connection()\n    await connection.execute(\n        querystring=queries.INSERT_RESULT_QUERY.format(\n            self.table_name,\n        ),\n        parameters=[\n            task_id,\n            self.serializer.dumpb(model_dump(result)),\n        ],\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyResultBackend.is_result_ready","title":"is_result_ready  <code>async</code>","text":"<pre><code>is_result_ready(task_id)\n</code></pre> <p>Returns whether the result is ready.</p> <p>:param task_id: ID of the task.</p> <p>:returns: True if the result is ready else False.</p> Source code in <code>src/taskiq_pg/psqlpy/result_backend.py</code> <pre><code>async def is_result_ready(self, task_id: str) -&gt; bool:\n    \"\"\"\n    Returns whether the result is ready.\n\n    :param task_id: ID of the task.\n\n    :returns: True if the result is ready else False.\n    \"\"\"\n    connection: tp.Final = await self._database_pool.connection()\n    return tp.cast(\n        \"bool\",\n        await connection.fetch_val(\n            querystring=queries.IS_RESULT_EXISTS_QUERY.format(\n                self.table_name,\n            ),\n            parameters=[task_id],\n        ),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyResultBackend.get_result","title":"get_result  <code>async</code>","text":"<pre><code>get_result(task_id, with_logs=False)\n</code></pre> <p>Retrieve result from the task.</p> <p>:param task_id: task's id. :param with_logs: if True it will download task's logs. :raises ResultIsMissingError: if there is no result when trying to get it. :return: TaskiqResult.</p> Source code in <code>src/taskiq_pg/psqlpy/result_backend.py</code> <pre><code>async def get_result(\n    self,\n    task_id: str,\n    with_logs: bool = False,\n) -&gt; TaskiqResult[ReturnType]:\n    \"\"\"\n    Retrieve result from the task.\n\n    :param task_id: task's id.\n    :param with_logs: if True it will download task's logs.\n    :raises ResultIsMissingError: if there is no result when trying to get it.\n    :return: TaskiqResult.\n    \"\"\"\n    connection: tp.Final = await self._database_pool.connection()\n    try:\n        result_in_bytes: tp.Final[bytes] = await connection.fetch_val(\n            querystring=queries.SELECT_RESULT_QUERY.format(\n                self.table_name,\n            ),\n            parameters=[task_id],\n        )\n    except BaseConnectionError as exc:\n        msg = f\"Cannot find record with task_id = {task_id} in PostgreSQL\"\n        raise ResultIsMissingError(msg) from exc\n\n    if not self.keep_results:\n        await connection.execute(\n            querystring=queries.DELETE_RESULT_QUERY.format(\n                self.table_name,\n            ),\n            parameters=[task_id],\n        )\n\n    taskiq_result: tp.Final = model_validate(\n        TaskiqResult[ReturnType],\n        self.serializer.loadb(result_in_bytes),\n    )\n\n    if not with_logs:\n        taskiq_result.log = None\n\n    return taskiq_result\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyResultBackend.set_progress","title":"set_progress  <code>async</code>","text":"<pre><code>set_progress(task_id, progress)\n</code></pre> <p>Saves progress.</p> <p>:param task_id: task's id. :param progress: progress of execution.</p> Source code in <code>src/taskiq_pg/psqlpy/result_backend.py</code> <pre><code>async def set_progress(\n    self,\n    task_id: str,\n    progress: TaskProgress[tp.Any],\n) -&gt; None:\n    \"\"\"\n    Saves progress.\n\n    :param task_id: task's id.\n    :param progress: progress of execution.\n    \"\"\"\n    connection = await self._database_pool.connection()\n    await connection.execute(\n        querystring=queries.INSERT_PROGRESS_QUERY.format(\n            self.table_name,\n        ),\n        parameters=[\n            task_id,\n            self.serializer.dumpb(model_dump(progress)),\n        ],\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyResultBackend.get_progress","title":"get_progress  <code>async</code>","text":"<pre><code>get_progress(task_id)\n</code></pre> <p>Gets progress.</p> <p>:param task_id: task's id.</p> Source code in <code>src/taskiq_pg/psqlpy/result_backend.py</code> <pre><code>async def get_progress(\n    self,\n    task_id: str,\n) -&gt; TaskProgress[tp.Any] | None:\n    \"\"\"\n    Gets progress.\n\n    :param task_id: task's id.\n    \"\"\"\n    connection: tp.Final = await self._database_pool.connection()\n    try:\n        progress_in_bytes = await connection.fetch_val(\n            querystring=queries.SELECT_PROGRESS_QUERY.format(\n                self.table_name,\n            ),\n            parameters=[task_id],\n        )\n    except BaseConnectionError as exc:\n        msg = f\"Cannot find record with task_id = {task_id} in PostgreSQL\"\n        raise ResultIsMissingError(msg) from exc\n    if progress_in_bytes is None:\n        return None\n    return model_validate(\n        TaskProgress[tp.Any],\n        self.serializer.loadb(progress_in_bytes),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyScheduleSource","title":"PSQLPyScheduleSource","text":"<pre><code>PSQLPyScheduleSource(\n    broker,\n    dsn=\"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name=\"taskiq_schedules\",\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresScheduleSource</code></p> <p>Schedule source that uses psqlpy to store schedules in PostgreSQL.</p> <p>Initialize the PostgreSQL scheduler source.</p> <p>Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database. This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks across application restarts.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>str | Callable[[], str]</code>, default:                   <code>'postgresql://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>PostgreSQL connection string</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_schedules'</code> )           \u2013            <p>Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.</p> </li> <li> <code>broker</code>               (<code>AsyncBroker</code>)           \u2013            <p>The TaskIQ broker instance to use for finding and managing tasks. Required if startup_schedule is provided.</p> </li> <li> <code>**connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional keyword arguments passed to the database connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def __init__(\n    self,\n    broker: AsyncBroker,\n    dsn: str | tp.Callable[[], str] = \"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name: str = \"taskiq_schedules\",\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Initialize the PostgreSQL scheduler source.\n\n    Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database.\n    This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks\n    across application restarts.\n\n    Args:\n        dsn: PostgreSQL connection string\n        table_name: Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.\n        broker: The TaskIQ broker instance to use for finding and managing tasks.\n            Required if startup_schedule is provided.\n        **connect_kwargs: Additional keyword arguments passed to the database connection pool.\n\n    \"\"\"\n    self._broker: tp.Final = broker\n    self._dsn: tp.Final = dsn\n    self._table_name: tp.Final = table_name\n    self._connect_kwargs: tp.Final = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyScheduleSource.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyScheduleSource.extract_scheduled_tasks_from_broker","title":"extract_scheduled_tasks_from_broker","text":"<pre><code>extract_scheduled_tasks_from_broker()\n</code></pre> <p>Extract schedules from tasks that were registered in broker.</p> <p>Returns:</p> <ul> <li> <code>list[ScheduledTask]</code>           \u2013            <p>A list of ScheduledTask instances extracted from the task's labels.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def extract_scheduled_tasks_from_broker(self) -&gt; list[ScheduledTask]:\n    \"\"\"\n    Extract schedules from tasks that were registered in broker.\n\n    Returns:\n        A list of ScheduledTask instances extracted from the task's labels.\n    \"\"\"\n    scheduled_tasks_for_creation: list[ScheduledTask] = []\n    for task_name, task in self._broker.get_all_tasks().items():\n        if \"schedule\" not in task.labels:\n            logger.debug(\"Task %s has no schedule, skipping\", task_name)\n            continue\n        if not isinstance(task.labels[\"schedule\"], list):\n            logger.warning(\n                \"Schedule for task %s is not a list, skipping\",\n                task_name,\n            )\n            continue\n        for schedule in task.labels[\"schedule\"]:\n            try:\n                new_schedule = ScheduledTask.model_validate(\n                    {\n                        \"task_name\": task_name,\n                        \"labels\": schedule.get(\"labels\", {}),\n                        \"args\": schedule.get(\"args\", []),\n                        \"kwargs\": schedule.get(\"kwargs\", {}),\n                        \"schedule_id\": str(uuid.uuid4()),\n                        \"cron\": schedule.get(\"cron\", None),\n                        \"cron_offset\": schedule.get(\"cron_offset\", None),\n                        \"interval\": schedule.get(\"interval\", None),\n                        \"time\": schedule.get(\"time\", None),\n                    },\n                )\n                scheduled_tasks_for_creation.append(new_schedule)\n            except ValidationError:  # noqa: PERF203\n                logger.exception(\n                    \"Schedule for task %s is not valid, skipping\",\n                    task_name,\n                )\n                continue\n    return scheduled_tasks_for_creation\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyScheduleSource.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the schedule source.</p> <p>Construct new connection pool, create new table for schedules if not exists and fill table with schedules from task labels.</p> Source code in <code>src/taskiq_pg/psqlpy/schedule_source.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the schedule source.\n\n    Construct new connection pool, create new table for schedules if not exists\n    and fill table with schedules from task labels.\n    \"\"\"\n    self._database_pool = ConnectionPool(\n        dsn=self.dsn,\n        **self._connect_kwargs,\n    )\n    async with self._database_pool.acquire() as connection:\n        await connection.execute(\n            CREATE_SCHEDULES_TABLE_QUERY.format(\n                self._table_name,\n            ),\n        )\n    scheduled_tasks_for_creation = self.extract_scheduled_tasks_from_broker()\n    await self._update_schedules_on_startup(scheduled_tasks_for_creation)\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyScheduleSource.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/psqlpy/schedule_source.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyScheduleSource.get_schedules","title":"get_schedules  <code>async</code>","text":"<pre><code>get_schedules()\n</code></pre> <p>Fetch schedules from the database.</p> Source code in <code>src/taskiq_pg/psqlpy/schedule_source.py</code> <pre><code>async def get_schedules(self) -&gt; list[\"ScheduledTask\"]:\n    \"\"\"Fetch schedules from the database.\"\"\"\n    async with self._database_pool.acquire() as connection:\n        rows_with_schedules = await connection.fetch(\n            SELECT_SCHEDULES_QUERY.format(self._table_name),\n        )\n    schedules = []\n    for row in rows_with_schedules.result():\n        schedule = row[\"schedule\"]\n        schedules.append(\n            ScheduledTask.model_validate(\n                {\n                    \"schedule_id\": str(row[\"id\"]),\n                    \"task_name\": row[\"task_name\"],\n                    \"labels\": schedule[\"labels\"],\n                    \"args\": schedule[\"args\"],\n                    \"kwargs\": schedule[\"kwargs\"],\n                    \"cron\": schedule[\"cron\"],\n                    \"cron_offset\": schedule[\"cron_offset\"],\n                    \"time\": schedule[\"time\"],\n                    \"interval\": schedule[\"interval\"],\n                },\n            ),\n        )\n    return schedules\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyScheduleSource.add_schedule","title":"add_schedule  <code>async</code>","text":"<pre><code>add_schedule(schedule)\n</code></pre> <p>Add a new schedule.</p> <p>Parameters:</p> <ul> <li> <code>schedule</code>               (<code>ScheduledTask</code>)           \u2013            <p>schedule to add.</p> </li> </ul> Source code in <code>src/taskiq_pg/psqlpy/schedule_source.py</code> <pre><code>async def add_schedule(self, schedule: \"ScheduledTask\") -&gt; None:\n    \"\"\"\n    Add a new schedule.\n\n    Args:\n        schedule: schedule to add.\n    \"\"\"\n    async with self._database_pool.acquire() as connection:\n        schedule_dict = schedule.model_dump(\n            mode=\"json\",\n            exclude={\"schedule_id\", \"task_name\"},\n        )\n        await connection.execute(\n            INSERT_SCHEDULE_QUERY.format(self._table_name),\n            [\n                uuid.UUID(schedule.schedule_id),\n                schedule.task_name,\n                JSONB(schedule_dict),\n            ]\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyScheduleSource.delete_schedule","title":"delete_schedule  <code>async</code>","text":"<pre><code>delete_schedule(schedule_id)\n</code></pre> <p>Method to delete schedule by id.</p> <p>This is useful for schedule cancelation.</p> <p>Parameters:</p> <ul> <li> <code>schedule_id</code>               (<code>str</code>)           \u2013            <p>id of schedule to delete.</p> </li> </ul> Source code in <code>src/taskiq_pg/psqlpy/schedule_source.py</code> <pre><code>async def delete_schedule(self, schedule_id: str) -&gt; None:\n    \"\"\"\n    Method to delete schedule by id.\n\n    This is useful for schedule cancelation.\n\n    Args:\n        schedule_id: id of schedule to delete.\n    \"\"\"\n    async with self._database_pool.acquire() as connection:\n        await connection.execute(\n            DELETE_SCHEDULE_QUERY.format(self._table_name),\n            [uuid.UUID(schedule_id)],\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.PSQLPyScheduleSource.post_send","title":"post_send  <code>async</code>","text":"<pre><code>post_send(task)\n</code></pre> <p>Delete a task after it's completed.</p> Source code in <code>src/taskiq_pg/psqlpy/schedule_source.py</code> <pre><code>async def post_send(self, task: ScheduledTask) -&gt; None:\n    \"\"\"Delete a task after it's completed.\"\"\"\n    if task.time is not None:\n        await self.delete_schedule(task.schedule_id)\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker","title":"broker","text":""},{"location":"reference/#taskiq_pg.psqlpy.broker.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger('taskiq.psqlpy_broker')\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.MessageRow","title":"MessageRow  <code>dataclass</code>","text":"<pre><code>MessageRow(\n    id,\n    task_id,\n    task_name,\n    message,\n    labels,\n    status,\n    created_at,\n)\n</code></pre> <p>Message in db table.</p>"},{"location":"reference/#taskiq_pg.psqlpy.broker.MessageRow.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.MessageRow.task_id","title":"task_id  <code>instance-attribute</code>","text":"<pre><code>task_id\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.MessageRow.task_name","title":"task_name  <code>instance-attribute</code>","text":"<pre><code>task_name\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.MessageRow.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.MessageRow.labels","title":"labels  <code>instance-attribute</code>","text":"<pre><code>labels\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.MessageRow.status","title":"status  <code>instance-attribute</code>","text":"<pre><code>status\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.MessageRow.created_at","title":"created_at  <code>instance-attribute</code>","text":"<pre><code>created_at\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.PSQLPyBroker","title":"PSQLPyBroker","text":"<pre><code>PSQLPyBroker(\n    dsn=\"postgresql://postgres:postgres@localhost:5432/postgres\",\n    result_backend=None,\n    task_id_generator=None,\n    channel_name=\"taskiq\",\n    table_name=\"taskiq_messages\",\n    max_retry_attempts=5,\n    read_kwargs=None,\n    write_kwargs=None,\n)\n</code></pre> <p>               Bases: <code>BasePostgresBroker</code></p> <p>Broker that uses PostgreSQL and PSQLPy with LISTEN/NOTIFY.</p> <p>Construct a new broker.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>str | Callable[[], str]</code>, default:                   <code>'postgresql://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>connection string to PostgreSQL, or callable returning one.</p> </li> <li> <code>result_backend</code>               (<code>AsyncResultBackend[_T] | None</code>, default:                   <code>None</code> )           \u2013            <p>Custom result backend.</p> </li> <li> <code>task_id_generator</code>               (<code>Callable[[], str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Custom task_id generator.</p> </li> <li> <code>channel_name</code>               (<code>str</code>, default:                   <code>'taskiq'</code> )           \u2013            <p>Name of the channel to listen on.</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_messages'</code> )           \u2013            <p>Name of the table to store messages.</p> </li> <li> <code>max_retry_attempts</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>Maximum number of message processing attempts.</p> </li> <li> <code>read_kwargs</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional arguments for read connection creation.</p> </li> <li> <code>write_kwargs</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional arguments for write pool creation.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/broker.py</code> <pre><code>def __init__(  # noqa: PLR0913\n    self,\n    dsn: str | tp.Callable[[], str] = \"postgresql://postgres:postgres@localhost:5432/postgres\",\n    result_backend: AsyncResultBackend[_T] | None = None,\n    task_id_generator: tp.Callable[[], str] | None = None,\n    channel_name: str = \"taskiq\",\n    table_name: str = \"taskiq_messages\",\n    max_retry_attempts: int = 5,\n    read_kwargs: dict[str, tp.Any] | None = None,\n    write_kwargs: dict[str, tp.Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Construct a new broker.\n\n    Args:\n        dsn: connection string to PostgreSQL, or callable returning one.\n        result_backend: Custom result backend.\n        task_id_generator: Custom task_id generator.\n        channel_name: Name of the channel to listen on.\n        table_name: Name of the table to store messages.\n        max_retry_attempts: Maximum number of message processing attempts.\n        read_kwargs: Additional arguments for read connection creation.\n        write_kwargs: Additional arguments for write pool creation.\n\n    \"\"\"\n    super().__init__(\n        result_backend=result_backend,\n        task_id_generator=task_id_generator,\n    )\n    self._dsn: str | tp.Callable[[], str] = dsn\n    self.channel_name: str = channel_name\n    self.table_name: str = table_name\n    self.read_kwargs: dict[str, tp.Any] = read_kwargs or {}\n    self.write_kwargs: dict[str, tp.Any] = write_kwargs or {}\n    self.max_retry_attempts: int = max_retry_attempts\n    self._queue: asyncio.Queue[str] | None = None\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.PSQLPyBroker.channel_name","title":"channel_name  <code>instance-attribute</code>","text":"<pre><code>channel_name = channel_name\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.PSQLPyBroker.table_name","title":"table_name  <code>instance-attribute</code>","text":"<pre><code>table_name = table_name\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.PSQLPyBroker.read_kwargs","title":"read_kwargs  <code>instance-attribute</code>","text":"<pre><code>read_kwargs = read_kwargs or {}\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.PSQLPyBroker.write_kwargs","title":"write_kwargs  <code>instance-attribute</code>","text":"<pre><code>write_kwargs = write_kwargs or {}\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.PSQLPyBroker.max_retry_attempts","title":"max_retry_attempts  <code>instance-attribute</code>","text":"<pre><code>max_retry_attempts = max_retry_attempts\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.PSQLPyBroker.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>A string with dsn or None if dsn isn't set yet.</p> </li> </ul>"},{"location":"reference/#taskiq_pg.psqlpy.broker.PSQLPyBroker.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the broker.</p> Source code in <code>src/taskiq_pg/psqlpy/broker.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"Initialize the broker.\"\"\"\n    await super().startup()\n    self._read_conn = await psqlpy.connect(\n        dsn=self.dsn,\n        **self.read_kwargs,\n    )\n    self._write_pool = psqlpy.ConnectionPool(\n        dsn=self.dsn,\n        **self.write_kwargs,\n    )\n\n    # create messages table if it doesn't exist\n    async with self._write_pool.acquire() as conn:\n        await conn.execute(CREATE_MESSAGE_TABLE_QUERY.format(self.table_name))\n\n    # listen to notification channel\n    self._listener = self._write_pool.listener()\n    await self._listener.add_callback(self.channel_name, self._notification_handler)\n    await self._listener.startup()\n    self._listener.listen()\n\n    self._queue = asyncio.Queue()\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.PSQLPyBroker.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close all connections on shutdown.</p> Source code in <code>src/taskiq_pg/psqlpy/broker.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close all connections on shutdown.\"\"\"\n    await super().shutdown()\n    if self._read_conn is not None:\n        self._read_conn.close()\n    if self._write_pool is not None:\n        self._write_pool.close()\n    if self._listener is not None:\n        self._listener.abort_listen()\n        await self._listener.shutdown()\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.PSQLPyBroker.kick","title":"kick  <code>async</code>","text":"<pre><code>kick(message)\n</code></pre> <p>Send message to the channel.</p> <p>Inserts the message into the database and sends a NOTIFY.</p> <p>:param message: Message to send.</p> Source code in <code>src/taskiq_pg/psqlpy/broker.py</code> <pre><code>async def kick(self, message: BrokerMessage) -&gt; None:\n    \"\"\"\n    Send message to the channel.\n\n    Inserts the message into the database and sends a NOTIFY.\n\n    :param message: Message to send.\n    \"\"\"\n    async with self._write_pool.acquire() as conn:\n        # insert message into db table\n        message_inserted_id = tp.cast(\n            \"int\",\n            await conn.fetch_val(\n                INSERT_MESSAGE_QUERY.format(self.table_name),\n                [\n                    message.task_id,\n                    message.task_name,\n                    message.message.decode(),\n                    JSONB(message.labels),\n                ],\n            ),\n        )\n\n        delay_value = tp.cast(\"str | None\", message.labels.get(\"delay\"))\n        if delay_value is not None:\n            delay_seconds = int(delay_value)\n            asyncio.create_task(  # noqa: RUF006\n                self._schedule_notification(message_inserted_id, delay_seconds),\n            )\n        else:\n            # Send NOTIFY with message ID as payload\n            _ = await conn.execute(\n                f\"NOTIFY {self.channel_name}, '{message_inserted_id}'\",\n            )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.broker.PSQLPyBroker.listen","title":"listen  <code>async</code>","text":"<pre><code>listen()\n</code></pre> <p>Listen to the channel.</p> <p>Yields messages as they are received.</p> <p>:yields: AckableMessage instances.</p> Source code in <code>src/taskiq_pg/psqlpy/broker.py</code> <pre><code>async def listen(self) -&gt; AsyncGenerator[AckableMessage, None]:\n    \"\"\"\n    Listen to the channel.\n\n    Yields messages as they are received.\n\n    :yields: AckableMessage instances.\n    \"\"\"\n    while True:\n        try:\n            payload = await self._queue.get()\n            message_id = int(payload)  # payload is the message id\n            try:\n                async with self._write_pool.acquire() as conn:\n                    claimed_message = await conn.fetch_row(\n                        CLAIM_MESSAGE_QUERY.format(self.table_name),\n                        [message_id],\n                    )\n            except ConnectionExecuteError:  # message was claimed by another worker\n                continue\n            message_row_result = tp.cast(\n                \"MessageRow\",\n                tp.cast(\"object\", claimed_message.as_class(MessageRow)),\n            )\n            message_data = message_row_result.message.encode()\n\n            async def ack(*, _message_id: int = message_id) -&gt; None:\n                async with self._write_pool.acquire() as conn:\n                    _ = await conn.execute(\n                        DELETE_MESSAGE_QUERY.format(self.table_name),\n                        [_message_id],\n                    )\n\n            yield AckableMessage(data=message_data, ack=ack)\n        except Exception:\n            logger.exception(\"Error processing message\")\n            continue\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries","title":"queries","text":""},{"location":"reference/#taskiq_pg.psqlpy.queries.CREATE_TABLE_QUERY","title":"CREATE_TABLE_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_TABLE_QUERY = \"\\nCREATE TABLE IF NOT EXISTS {} (\\n    task_id {} UNIQUE,\\n    result BYTEA,\\n    progress BYTEA\\n)\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.ADD_PROGRESS_COLUMN_QUERY","title":"ADD_PROGRESS_COLUMN_QUERY  <code>module-attribute</code>","text":"<pre><code>ADD_PROGRESS_COLUMN_QUERY = \"\\nALTER TABLE {} ADD COLUMN IF NOT EXISTS progress BYTEA;\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.CREATE_INDEX_QUERY","title":"CREATE_INDEX_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_INDEX_QUERY = \"\\nCREATE INDEX IF NOT EXISTS {}_task_id_idx ON {} USING HASH (task_id)\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.INSERT_RESULT_QUERY","title":"INSERT_RESULT_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_RESULT_QUERY = \"\\nINSERT INTO {} VALUES ($1, $2, NULL)\\nON CONFLICT (task_id)\\nDO UPDATE\\nSET result = $2\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.INSERT_PROGRESS_QUERY","title":"INSERT_PROGRESS_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_PROGRESS_QUERY = \"\\nINSERT INTO {} VALUES ($1, NULL, $2)\\nON CONFLICT (task_id)\\nDO UPDATE\\nSET progress = $2\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.SELECT_PROGRESS_QUERY","title":"SELECT_PROGRESS_QUERY  <code>module-attribute</code>","text":"<pre><code>SELECT_PROGRESS_QUERY = (\n    \"\\nSELECT progress FROM {} WHERE task_id = $1\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.IS_RESULT_EXISTS_QUERY","title":"IS_RESULT_EXISTS_QUERY  <code>module-attribute</code>","text":"<pre><code>IS_RESULT_EXISTS_QUERY = \"\\nSELECT EXISTS(\\n    SELECT 1 FROM {} WHERE task_id = $1 and result IS NOT NULL\\n)\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.SELECT_RESULT_QUERY","title":"SELECT_RESULT_QUERY  <code>module-attribute</code>","text":"<pre><code>SELECT_RESULT_QUERY = (\n    \"\\nSELECT result FROM {} WHERE task_id = $1\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.DELETE_RESULT_QUERY","title":"DELETE_RESULT_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_RESULT_QUERY = (\n    \"\\nDELETE FROM {} WHERE task_id = $1\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.CREATE_MESSAGE_TABLE_QUERY","title":"CREATE_MESSAGE_TABLE_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_MESSAGE_TABLE_QUERY = \"\\nCREATE TABLE IF NOT EXISTS {} (\\n    id SERIAL PRIMARY KEY,\\n    task_id VARCHAR NOT NULL,\\n    task_name VARCHAR NOT NULL,\\n    message TEXT NOT NULL,\\n    labels JSONB NOT NULL,\\n    status TEXT NOT NULL DEFAULT 'pending',\\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\\n);\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.INSERT_MESSAGE_QUERY","title":"INSERT_MESSAGE_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_MESSAGE_QUERY = \"\\nINSERT INTO {} (task_id, task_name, message, labels)\\nVALUES ($1, $2, $3, $4)\\nRETURNING id\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.CLAIM_MESSAGE_QUERY","title":"CLAIM_MESSAGE_QUERY  <code>module-attribute</code>","text":"<pre><code>CLAIM_MESSAGE_QUERY = \"UPDATE {} SET status = 'processing' WHERE id = $1 AND status = 'pending' RETURNING *\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.DELETE_MESSAGE_QUERY","title":"DELETE_MESSAGE_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_MESSAGE_QUERY = 'DELETE FROM {} WHERE id = $1'\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.CREATE_SCHEDULES_TABLE_QUERY","title":"CREATE_SCHEDULES_TABLE_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_SCHEDULES_TABLE_QUERY = \"\\nCREATE TABLE IF NOT EXISTS {} (\\n    id UUID PRIMARY KEY,\\n    task_name VARCHAR(100) NOT NULL,\\n    schedule JSONB NOT NULL,\\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\\n);\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.INSERT_SCHEDULE_QUERY","title":"INSERT_SCHEDULE_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_SCHEDULE_QUERY = \"\\nINSERT INTO {} (id, task_name, schedule)\\nVALUES ($1, $2, $3)\\nON CONFLICT (id) DO UPDATE\\nSET task_name = EXCLUDED.task_name,\\n    schedule = EXCLUDED.schedule,\\n    updated_at = NOW();\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.SELECT_SCHEDULES_QUERY","title":"SELECT_SCHEDULES_QUERY  <code>module-attribute</code>","text":"<pre><code>SELECT_SCHEDULES_QUERY = (\n    \"\\nSELECT id, task_name, schedule\\nFROM {};\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.DELETE_ALL_SCHEDULES_QUERY","title":"DELETE_ALL_SCHEDULES_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_ALL_SCHEDULES_QUERY = '\\nDELETE FROM {};\\n'\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.queries.DELETE_SCHEDULE_QUERY","title":"DELETE_SCHEDULE_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_SCHEDULE_QUERY = '\\nDELETE FROM {} WHERE id = $1;\\n'\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.result_backend","title":"result_backend","text":""},{"location":"reference/#taskiq_pg.psqlpy.result_backend.PSQLPyResultBackend","title":"PSQLPyResultBackend","text":"<pre><code>PSQLPyResultBackend(\n    dsn=\"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results=True,\n    table_name=\"taskiq_results\",\n    field_for_task_id=\"VarChar\",\n    serializer=None,\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresResultBackend</code></p> <p>Result backend for TaskIQ based on PSQLPy.</p> <p>Construct new result backend.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>Callable[[], str] | str | None</code>, default:                   <code>'postgres://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>connection string to PostgreSQL, or callable returning one.</p> </li> <li> <code>keep_results</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>flag to not remove results from the database after reading.</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_results'</code> )           \u2013            <p>name of the table to store results.</p> </li> <li> <code>field_for_task_id</code>               (<code>Literal['VarChar', 'Text', 'Uuid']</code>, default:                   <code>'VarChar'</code> )           \u2013            <p>type of the field to store task_id.</p> </li> <li> <code>serializer</code>               (<code>TaskiqSerializer | None</code>, default:                   <code>None</code> )           \u2013            <p>serializer class to serialize/deserialize result from task.</p> </li> <li> <code>connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>additional arguments for creating connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/result_backend.py</code> <pre><code>def __init__(\n    self,\n    dsn: tp.Callable[[], str] | str | None = \"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results: bool = True,\n    table_name: str = \"taskiq_results\",\n    field_for_task_id: tp.Literal[\"VarChar\", \"Text\", \"Uuid\"] = \"VarChar\",\n    serializer: TaskiqSerializer | None = None,\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Construct new result backend.\n\n    Args:\n        dsn: connection string to PostgreSQL, or callable returning one.\n        keep_results: flag to not remove results from the database after reading.\n        table_name: name of the table to store results.\n        field_for_task_id: type of the field to store task_id.\n        serializer: serializer class to serialize/deserialize result from task.\n        connect_kwargs: additional arguments for creating connection pool.\n\n    \"\"\"\n    self._dsn: tp.Final = dsn\n    self.keep_results: tp.Final = keep_results\n    self.table_name: tp.Final = table_name\n    self.field_for_task_id: tp.Final = field_for_task_id\n    self.connect_kwargs: tp.Final = connect_kwargs\n    self.serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.result_backend.PSQLPyResultBackend.keep_results","title":"keep_results  <code>instance-attribute</code>","text":"<pre><code>keep_results = keep_results\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.result_backend.PSQLPyResultBackend.table_name","title":"table_name  <code>instance-attribute</code>","text":"<pre><code>table_name = table_name\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.result_backend.PSQLPyResultBackend.field_for_task_id","title":"field_for_task_id  <code>instance-attribute</code>","text":"<pre><code>field_for_task_id = field_for_task_id\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.result_backend.PSQLPyResultBackend.connect_kwargs","title":"connect_kwargs  <code>instance-attribute</code>","text":"<pre><code>connect_kwargs = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.result_backend.PSQLPyResultBackend.serializer","title":"serializer  <code>instance-attribute</code>","text":"<pre><code>serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.result_backend.PSQLPyResultBackend.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.psqlpy.result_backend.PSQLPyResultBackend.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the result backend.</p> <p>Construct new connection pool and create new table for results if not exists.</p> Source code in <code>src/taskiq_pg/psqlpy/result_backend.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the result backend.\n\n    Construct new connection pool\n    and create new table for results if not exists.\n    \"\"\"\n    self._database_pool = ConnectionPool(\n        dsn=self.dsn,\n        **self.connect_kwargs,\n    )\n    connection = await self._database_pool.connection()\n    await connection.execute(\n        querystring=queries.CREATE_TABLE_QUERY.format(\n            self.table_name,\n            self.field_for_task_id,\n        ),\n    )\n    await connection.execute(\n        querystring=queries.ADD_PROGRESS_COLUMN_QUERY.format(\n            self.table_name,\n        ),\n    )\n    await connection.execute(\n        querystring=queries.CREATE_INDEX_QUERY.format(\n            self.table_name,\n            self.table_name,\n        ),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.result_backend.PSQLPyResultBackend.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/psqlpy/result_backend.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.result_backend.PSQLPyResultBackend.set_result","title":"set_result  <code>async</code>","text":"<pre><code>set_result(task_id, result)\n</code></pre> <p>Set result to the PostgreSQL table.</p> <p>:param task_id: ID of the task. :param result: result of the task.</p> Source code in <code>src/taskiq_pg/psqlpy/result_backend.py</code> <pre><code>async def set_result(\n    self,\n    task_id: str,\n    result: TaskiqResult[ReturnType],\n) -&gt; None:\n    \"\"\"\n    Set result to the PostgreSQL table.\n\n    :param task_id: ID of the task.\n    :param result: result of the task.\n    \"\"\"\n    connection = await self._database_pool.connection()\n    await connection.execute(\n        querystring=queries.INSERT_RESULT_QUERY.format(\n            self.table_name,\n        ),\n        parameters=[\n            task_id,\n            self.serializer.dumpb(model_dump(result)),\n        ],\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.result_backend.PSQLPyResultBackend.is_result_ready","title":"is_result_ready  <code>async</code>","text":"<pre><code>is_result_ready(task_id)\n</code></pre> <p>Returns whether the result is ready.</p> <p>:param task_id: ID of the task.</p> <p>:returns: True if the result is ready else False.</p> Source code in <code>src/taskiq_pg/psqlpy/result_backend.py</code> <pre><code>async def is_result_ready(self, task_id: str) -&gt; bool:\n    \"\"\"\n    Returns whether the result is ready.\n\n    :param task_id: ID of the task.\n\n    :returns: True if the result is ready else False.\n    \"\"\"\n    connection: tp.Final = await self._database_pool.connection()\n    return tp.cast(\n        \"bool\",\n        await connection.fetch_val(\n            querystring=queries.IS_RESULT_EXISTS_QUERY.format(\n                self.table_name,\n            ),\n            parameters=[task_id],\n        ),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.result_backend.PSQLPyResultBackend.get_result","title":"get_result  <code>async</code>","text":"<pre><code>get_result(task_id, with_logs=False)\n</code></pre> <p>Retrieve result from the task.</p> <p>:param task_id: task's id. :param with_logs: if True it will download task's logs. :raises ResultIsMissingError: if there is no result when trying to get it. :return: TaskiqResult.</p> Source code in <code>src/taskiq_pg/psqlpy/result_backend.py</code> <pre><code>async def get_result(\n    self,\n    task_id: str,\n    with_logs: bool = False,\n) -&gt; TaskiqResult[ReturnType]:\n    \"\"\"\n    Retrieve result from the task.\n\n    :param task_id: task's id.\n    :param with_logs: if True it will download task's logs.\n    :raises ResultIsMissingError: if there is no result when trying to get it.\n    :return: TaskiqResult.\n    \"\"\"\n    connection: tp.Final = await self._database_pool.connection()\n    try:\n        result_in_bytes: tp.Final[bytes] = await connection.fetch_val(\n            querystring=queries.SELECT_RESULT_QUERY.format(\n                self.table_name,\n            ),\n            parameters=[task_id],\n        )\n    except BaseConnectionError as exc:\n        msg = f\"Cannot find record with task_id = {task_id} in PostgreSQL\"\n        raise ResultIsMissingError(msg) from exc\n\n    if not self.keep_results:\n        await connection.execute(\n            querystring=queries.DELETE_RESULT_QUERY.format(\n                self.table_name,\n            ),\n            parameters=[task_id],\n        )\n\n    taskiq_result: tp.Final = model_validate(\n        TaskiqResult[ReturnType],\n        self.serializer.loadb(result_in_bytes),\n    )\n\n    if not with_logs:\n        taskiq_result.log = None\n\n    return taskiq_result\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.result_backend.PSQLPyResultBackend.set_progress","title":"set_progress  <code>async</code>","text":"<pre><code>set_progress(task_id, progress)\n</code></pre> <p>Saves progress.</p> <p>:param task_id: task's id. :param progress: progress of execution.</p> Source code in <code>src/taskiq_pg/psqlpy/result_backend.py</code> <pre><code>async def set_progress(\n    self,\n    task_id: str,\n    progress: TaskProgress[tp.Any],\n) -&gt; None:\n    \"\"\"\n    Saves progress.\n\n    :param task_id: task's id.\n    :param progress: progress of execution.\n    \"\"\"\n    connection = await self._database_pool.connection()\n    await connection.execute(\n        querystring=queries.INSERT_PROGRESS_QUERY.format(\n            self.table_name,\n        ),\n        parameters=[\n            task_id,\n            self.serializer.dumpb(model_dump(progress)),\n        ],\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.result_backend.PSQLPyResultBackend.get_progress","title":"get_progress  <code>async</code>","text":"<pre><code>get_progress(task_id)\n</code></pre> <p>Gets progress.</p> <p>:param task_id: task's id.</p> Source code in <code>src/taskiq_pg/psqlpy/result_backend.py</code> <pre><code>async def get_progress(\n    self,\n    task_id: str,\n) -&gt; TaskProgress[tp.Any] | None:\n    \"\"\"\n    Gets progress.\n\n    :param task_id: task's id.\n    \"\"\"\n    connection: tp.Final = await self._database_pool.connection()\n    try:\n        progress_in_bytes = await connection.fetch_val(\n            querystring=queries.SELECT_PROGRESS_QUERY.format(\n                self.table_name,\n            ),\n            parameters=[task_id],\n        )\n    except BaseConnectionError as exc:\n        msg = f\"Cannot find record with task_id = {task_id} in PostgreSQL\"\n        raise ResultIsMissingError(msg) from exc\n    if progress_in_bytes is None:\n        return None\n    return model_validate(\n        TaskProgress[tp.Any],\n        self.serializer.loadb(progress_in_bytes),\n    )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.schedule_source","title":"schedule_source","text":""},{"location":"reference/#taskiq_pg.psqlpy.schedule_source.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger('taskiq_pg.psqlpy_schedule_source')\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.schedule_source.PSQLPyScheduleSource","title":"PSQLPyScheduleSource","text":"<pre><code>PSQLPyScheduleSource(\n    broker,\n    dsn=\"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name=\"taskiq_schedules\",\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresScheduleSource</code></p> <p>Schedule source that uses psqlpy to store schedules in PostgreSQL.</p> <p>Initialize the PostgreSQL scheduler source.</p> <p>Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database. This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks across application restarts.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>str | Callable[[], str]</code>, default:                   <code>'postgresql://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>PostgreSQL connection string</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_schedules'</code> )           \u2013            <p>Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.</p> </li> <li> <code>broker</code>               (<code>AsyncBroker</code>)           \u2013            <p>The TaskIQ broker instance to use for finding and managing tasks. Required if startup_schedule is provided.</p> </li> <li> <code>**connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional keyword arguments passed to the database connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def __init__(\n    self,\n    broker: AsyncBroker,\n    dsn: str | tp.Callable[[], str] = \"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name: str = \"taskiq_schedules\",\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Initialize the PostgreSQL scheduler source.\n\n    Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database.\n    This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks\n    across application restarts.\n\n    Args:\n        dsn: PostgreSQL connection string\n        table_name: Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.\n        broker: The TaskIQ broker instance to use for finding and managing tasks.\n            Required if startup_schedule is provided.\n        **connect_kwargs: Additional keyword arguments passed to the database connection pool.\n\n    \"\"\"\n    self._broker: tp.Final = broker\n    self._dsn: tp.Final = dsn\n    self._table_name: tp.Final = table_name\n    self._connect_kwargs: tp.Final = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.schedule_source.PSQLPyScheduleSource.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.psqlpy.schedule_source.PSQLPyScheduleSource.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the schedule source.</p> <p>Construct new connection pool, create new table for schedules if not exists and fill table with schedules from task labels.</p> Source code in <code>src/taskiq_pg/psqlpy/schedule_source.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the schedule source.\n\n    Construct new connection pool, create new table for schedules if not exists\n    and fill table with schedules from task labels.\n    \"\"\"\n    self._database_pool = ConnectionPool(\n        dsn=self.dsn,\n        **self._connect_kwargs,\n    )\n    async with self._database_pool.acquire() as connection:\n        await connection.execute(\n            CREATE_SCHEDULES_TABLE_QUERY.format(\n                self._table_name,\n            ),\n        )\n    scheduled_tasks_for_creation = self.extract_scheduled_tasks_from_broker()\n    await self._update_schedules_on_startup(scheduled_tasks_for_creation)\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.schedule_source.PSQLPyScheduleSource.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/psqlpy/schedule_source.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.schedule_source.PSQLPyScheduleSource.get_schedules","title":"get_schedules  <code>async</code>","text":"<pre><code>get_schedules()\n</code></pre> <p>Fetch schedules from the database.</p> Source code in <code>src/taskiq_pg/psqlpy/schedule_source.py</code> <pre><code>async def get_schedules(self) -&gt; list[\"ScheduledTask\"]:\n    \"\"\"Fetch schedules from the database.\"\"\"\n    async with self._database_pool.acquire() as connection:\n        rows_with_schedules = await connection.fetch(\n            SELECT_SCHEDULES_QUERY.format(self._table_name),\n        )\n    schedules = []\n    for row in rows_with_schedules.result():\n        schedule = row[\"schedule\"]\n        schedules.append(\n            ScheduledTask.model_validate(\n                {\n                    \"schedule_id\": str(row[\"id\"]),\n                    \"task_name\": row[\"task_name\"],\n                    \"labels\": schedule[\"labels\"],\n                    \"args\": schedule[\"args\"],\n                    \"kwargs\": schedule[\"kwargs\"],\n                    \"cron\": schedule[\"cron\"],\n                    \"cron_offset\": schedule[\"cron_offset\"],\n                    \"time\": schedule[\"time\"],\n                    \"interval\": schedule[\"interval\"],\n                },\n            ),\n        )\n    return schedules\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.schedule_source.PSQLPyScheduleSource.add_schedule","title":"add_schedule  <code>async</code>","text":"<pre><code>add_schedule(schedule)\n</code></pre> <p>Add a new schedule.</p> <p>Parameters:</p> <ul> <li> <code>schedule</code>               (<code>ScheduledTask</code>)           \u2013            <p>schedule to add.</p> </li> </ul> Source code in <code>src/taskiq_pg/psqlpy/schedule_source.py</code> <pre><code>async def add_schedule(self, schedule: \"ScheduledTask\") -&gt; None:\n    \"\"\"\n    Add a new schedule.\n\n    Args:\n        schedule: schedule to add.\n    \"\"\"\n    async with self._database_pool.acquire() as connection:\n        schedule_dict = schedule.model_dump(\n            mode=\"json\",\n            exclude={\"schedule_id\", \"task_name\"},\n        )\n        await connection.execute(\n            INSERT_SCHEDULE_QUERY.format(self._table_name),\n            [\n                uuid.UUID(schedule.schedule_id),\n                schedule.task_name,\n                JSONB(schedule_dict),\n            ]\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.schedule_source.PSQLPyScheduleSource.delete_schedule","title":"delete_schedule  <code>async</code>","text":"<pre><code>delete_schedule(schedule_id)\n</code></pre> <p>Method to delete schedule by id.</p> <p>This is useful for schedule cancelation.</p> <p>Parameters:</p> <ul> <li> <code>schedule_id</code>               (<code>str</code>)           \u2013            <p>id of schedule to delete.</p> </li> </ul> Source code in <code>src/taskiq_pg/psqlpy/schedule_source.py</code> <pre><code>async def delete_schedule(self, schedule_id: str) -&gt; None:\n    \"\"\"\n    Method to delete schedule by id.\n\n    This is useful for schedule cancelation.\n\n    Args:\n        schedule_id: id of schedule to delete.\n    \"\"\"\n    async with self._database_pool.acquire() as connection:\n        await connection.execute(\n            DELETE_SCHEDULE_QUERY.format(self._table_name),\n            [uuid.UUID(schedule_id)],\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.schedule_source.PSQLPyScheduleSource.post_send","title":"post_send  <code>async</code>","text":"<pre><code>post_send(task)\n</code></pre> <p>Delete a task after it's completed.</p> Source code in <code>src/taskiq_pg/psqlpy/schedule_source.py</code> <pre><code>async def post_send(self, task: ScheduledTask) -&gt; None:\n    \"\"\"Delete a task after it's completed.\"\"\"\n    if task.time is not None:\n        await self.delete_schedule(task.schedule_id)\n</code></pre>"},{"location":"reference/#taskiq_pg.psqlpy.schedule_source.PSQLPyScheduleSource.extract_scheduled_tasks_from_broker","title":"extract_scheduled_tasks_from_broker","text":"<pre><code>extract_scheduled_tasks_from_broker()\n</code></pre> <p>Extract schedules from tasks that were registered in broker.</p> <p>Returns:</p> <ul> <li> <code>list[ScheduledTask]</code>           \u2013            <p>A list of ScheduledTask instances extracted from the task's labels.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def extract_scheduled_tasks_from_broker(self) -&gt; list[ScheduledTask]:\n    \"\"\"\n    Extract schedules from tasks that were registered in broker.\n\n    Returns:\n        A list of ScheduledTask instances extracted from the task's labels.\n    \"\"\"\n    scheduled_tasks_for_creation: list[ScheduledTask] = []\n    for task_name, task in self._broker.get_all_tasks().items():\n        if \"schedule\" not in task.labels:\n            logger.debug(\"Task %s has no schedule, skipping\", task_name)\n            continue\n        if not isinstance(task.labels[\"schedule\"], list):\n            logger.warning(\n                \"Schedule for task %s is not a list, skipping\",\n                task_name,\n            )\n            continue\n        for schedule in task.labels[\"schedule\"]:\n            try:\n                new_schedule = ScheduledTask.model_validate(\n                    {\n                        \"task_name\": task_name,\n                        \"labels\": schedule.get(\"labels\", {}),\n                        \"args\": schedule.get(\"args\", []),\n                        \"kwargs\": schedule.get(\"kwargs\", {}),\n                        \"schedule_id\": str(uuid.uuid4()),\n                        \"cron\": schedule.get(\"cron\", None),\n                        \"cron_offset\": schedule.get(\"cron_offset\", None),\n                        \"interval\": schedule.get(\"interval\", None),\n                        \"time\": schedule.get(\"time\", None),\n                    },\n                )\n                scheduled_tasks_for_creation.append(new_schedule)\n            except ValidationError:  # noqa: PERF203\n                logger.exception(\n                    \"Schedule for task %s is not valid, skipping\",\n                    task_name,\n                )\n                continue\n    return scheduled_tasks_for_creation\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg","title":"psycopg","text":""},{"location":"reference/#taskiq_pg.psycopg.PsycopgBroker","title":"PsycopgBroker","text":"<pre><code>PsycopgBroker(\n    dsn=\"postgresql://postgres:postgres@localhost:5432/postgres\",\n    result_backend=None,\n    task_id_generator=None,\n    channel_name=\"taskiq\",\n    table_name=\"taskiq_messages\",\n    max_retry_attempts=5,\n    read_kwargs=None,\n    write_kwargs=None,\n)\n</code></pre> <p>               Bases: <code>BasePostgresBroker</code></p> <p>Broker that uses PostgreSQL and psycopg with LISTEN/NOTIFY.</p> <p>Construct a new broker.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>str | Callable[[], str]</code>, default:                   <code>'postgresql://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>connection string to PostgreSQL, or callable returning one.</p> </li> <li> <code>result_backend</code>               (<code>AsyncResultBackend[_T] | None</code>, default:                   <code>None</code> )           \u2013            <p>Custom result backend.</p> </li> <li> <code>task_id_generator</code>               (<code>Callable[[], str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Custom task_id generator.</p> </li> <li> <code>channel_name</code>               (<code>str</code>, default:                   <code>'taskiq'</code> )           \u2013            <p>Name of the channel to listen on.</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_messages'</code> )           \u2013            <p>Name of the table to store messages.</p> </li> <li> <code>max_retry_attempts</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>Maximum number of message processing attempts.</p> </li> <li> <code>read_kwargs</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional arguments for read connection creation.</p> </li> <li> <code>write_kwargs</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional arguments for write pool creation.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/broker.py</code> <pre><code>def __init__(  # noqa: PLR0913\n    self,\n    dsn: str | tp.Callable[[], str] = \"postgresql://postgres:postgres@localhost:5432/postgres\",\n    result_backend: AsyncResultBackend[_T] | None = None,\n    task_id_generator: tp.Callable[[], str] | None = None,\n    channel_name: str = \"taskiq\",\n    table_name: str = \"taskiq_messages\",\n    max_retry_attempts: int = 5,\n    read_kwargs: dict[str, tp.Any] | None = None,\n    write_kwargs: dict[str, tp.Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Construct a new broker.\n\n    Args:\n        dsn: connection string to PostgreSQL, or callable returning one.\n        result_backend: Custom result backend.\n        task_id_generator: Custom task_id generator.\n        channel_name: Name of the channel to listen on.\n        table_name: Name of the table to store messages.\n        max_retry_attempts: Maximum number of message processing attempts.\n        read_kwargs: Additional arguments for read connection creation.\n        write_kwargs: Additional arguments for write pool creation.\n\n    \"\"\"\n    super().__init__(\n        result_backend=result_backend,\n        task_id_generator=task_id_generator,\n    )\n    self._dsn: str | tp.Callable[[], str] = dsn\n    self.channel_name: str = channel_name\n    self.table_name: str = table_name\n    self.read_kwargs: dict[str, tp.Any] = read_kwargs or {}\n    self.write_kwargs: dict[str, tp.Any] = write_kwargs or {}\n    self.max_retry_attempts: int = max_retry_attempts\n    self._queue: asyncio.Queue[str] | None = None\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgBroker.channel_name","title":"channel_name  <code>instance-attribute</code>","text":"<pre><code>channel_name = channel_name\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgBroker.table_name","title":"table_name  <code>instance-attribute</code>","text":"<pre><code>table_name = table_name\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgBroker.read_kwargs","title":"read_kwargs  <code>instance-attribute</code>","text":"<pre><code>read_kwargs = read_kwargs or {}\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgBroker.write_kwargs","title":"write_kwargs  <code>instance-attribute</code>","text":"<pre><code>write_kwargs = write_kwargs or {}\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgBroker.max_retry_attempts","title":"max_retry_attempts  <code>instance-attribute</code>","text":"<pre><code>max_retry_attempts = max_retry_attempts\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgBroker.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>A string with dsn or None if dsn isn't set yet.</p> </li> </ul>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgBroker.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the broker.</p> Source code in <code>src/taskiq_pg/psycopg/broker.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"Initialize the broker.\"\"\"\n    await super().startup()\n    self._read_conn = await AsyncConnection.connect(\n        conninfo=self.dsn,\n        **self.read_kwargs,\n        autocommit=True,\n        cursor_factory=AsyncRawCursor,\n    )\n    self._write_pool = AsyncConnectionPool(\n        conninfo=self.dsn if self.dsn is not None else \"\",\n        open=False,\n        **self.write_kwargs,\n    )\n    await self._write_pool.open()\n\n    async with self._write_pool.connection() as connection, connection.cursor() as cursor:\n        await cursor.execute(sql.SQL(CREATE_MESSAGE_TABLE_QUERY).format(sql.Identifier(self.table_name)))\n\n    await self._read_conn.execute(sql.SQL(\"LISTEN {}\").format(sql.Identifier(self.channel_name)))\n    self._notifies_iter = self._read_conn.notifies()\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgBroker.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close all connections on shutdown.</p> Source code in <code>src/taskiq_pg/psycopg/broker.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close all connections on shutdown.\"\"\"\n    await super().shutdown()\n    if self._notifies_iter is not None:\n        with suppress(RuntimeError):  # RuntimeError: aclose(): asynchronous generator is already running\n            await self._notifies_iter.aclose()  # type: ignore[attr-defined]\n    if self._read_conn is not None:\n        await self._read_conn.notifies().aclose()\n        await self._read_conn.close()\n    if self._write_pool is not None:\n        await self._write_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgBroker.kick","title":"kick  <code>async</code>","text":"<pre><code>kick(message)\n</code></pre> <p>Send message to the channel.</p> <p>Inserts the message into the database and sends a NOTIFY.</p> <p>:param message: Message to send.</p> Source code in <code>src/taskiq_pg/psycopg/broker.py</code> <pre><code>async def kick(self, message: BrokerMessage) -&gt; None:\n    \"\"\"\n    Send message to the channel.\n\n    Inserts the message into the database and sends a NOTIFY.\n\n    :param message: Message to send.\n    \"\"\"\n    async with self._write_pool.connection() as connection, connection.cursor() as cursor:\n        # insert message into db table\n        await cursor.execute(\n            sql.SQL(INSERT_MESSAGE_QUERY).format(sql.Identifier(self.table_name)),\n            [\n                message.task_id,\n                message.task_name,\n                message.message.decode(),\n                json.dumps(message.labels),\n            ],\n        )\n        row = await cursor.fetchone()\n        if row is None:\n            msg = \"failed to insert message\"\n            raise RuntimeError(msg)\n        message_inserted_id = int(row[0])\n\n        delay_value = tp.cast(\"str | None\", message.labels.get(\"delay\"))\n        if delay_value is not None:\n            delay_seconds = int(delay_value)\n            await self._schedule_notification(message_inserted_id, delay_seconds)\n        else:\n            # Send NOTIFY with message ID as payload\n            await cursor.execute(\n                sql.SQL(\"NOTIFY {}, {}\").format(\n                    sql.Identifier(self.channel_name),\n                    sql.Literal(str(message_inserted_id)),\n                ),\n            )\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgBroker.listen","title":"listen  <code>async</code>","text":"<pre><code>listen()\n</code></pre> <p>Listen to the channel.</p> <p>Yields messages as they are received.</p> <p>:yields: AckableMessage instances.</p> Source code in <code>src/taskiq_pg/psycopg/broker.py</code> <pre><code>async def listen(self) -&gt; AsyncGenerator[AckableMessage, None]:\n    \"\"\"\n    Listen to the channel.\n\n    Yields messages as they are received.\n\n    :yields: AckableMessage instances.\n    \"\"\"\n    while True:\n        async for message_id_str in self._listen_context():\n            message_id = int(message_id_str)  # payload is the message id\n            try:\n                async with self._write_pool.connection() as connection, connection.cursor() as cursor:\n                    await cursor.execute(\n                        sql.SQL(CLAIM_MESSAGE_QUERY).format(sql.Identifier(self.table_name)),\n                        [message_id],\n                    )\n                    claimed_message = await cursor.fetchone()\n                    if claimed_message is None:\n                        continue\n            except psycopg.OperationalError:  # message was claimed by another worker\n                continue\n            message_str = claimed_message[3]\n            if not isinstance(message_str, str):\n                msg = \"Message is not a string\"\n                raise TypeError(msg)\n            message_data = message_str.encode()\n\n            async def ack(*, _message_id: int = message_id) -&gt; None:\n                async with self._write_pool.connection() as connection, connection.cursor() as cursor:\n                    await cursor.execute(\n                        sql.SQL(DELETE_MESSAGE_QUERY).format(sql.Identifier(self.table_name)),\n                        [_message_id],\n                    )\n\n            yield AckableMessage(data=message_data, ack=ack)\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgResultBackend","title":"PsycopgResultBackend","text":"<pre><code>PsycopgResultBackend(\n    dsn=\"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results=True,\n    table_name=\"taskiq_results\",\n    field_for_task_id=\"VarChar\",\n    serializer=None,\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresResultBackend</code></p> <p>Result backend for TaskIQ based on psycopg.</p> <p>Construct new result backend.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>Callable[[], str] | str | None</code>, default:                   <code>'postgres://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>connection string to PostgreSQL, or callable returning one.</p> </li> <li> <code>keep_results</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>flag to not remove results from the database after reading.</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_results'</code> )           \u2013            <p>name of the table to store results.</p> </li> <li> <code>field_for_task_id</code>               (<code>Literal['VarChar', 'Text', 'Uuid']</code>, default:                   <code>'VarChar'</code> )           \u2013            <p>type of the field to store task_id.</p> </li> <li> <code>serializer</code>               (<code>TaskiqSerializer | None</code>, default:                   <code>None</code> )           \u2013            <p>serializer class to serialize/deserialize result from task.</p> </li> <li> <code>connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>additional arguments for creating connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/result_backend.py</code> <pre><code>def __init__(\n    self,\n    dsn: tp.Callable[[], str] | str | None = \"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results: bool = True,\n    table_name: str = \"taskiq_results\",\n    field_for_task_id: tp.Literal[\"VarChar\", \"Text\", \"Uuid\"] = \"VarChar\",\n    serializer: TaskiqSerializer | None = None,\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Construct new result backend.\n\n    Args:\n        dsn: connection string to PostgreSQL, or callable returning one.\n        keep_results: flag to not remove results from the database after reading.\n        table_name: name of the table to store results.\n        field_for_task_id: type of the field to store task_id.\n        serializer: serializer class to serialize/deserialize result from task.\n        connect_kwargs: additional arguments for creating connection pool.\n\n    \"\"\"\n    self._dsn: tp.Final = dsn\n    self.keep_results: tp.Final = keep_results\n    self.table_name: tp.Final = table_name\n    self.field_for_task_id: tp.Final = field_for_task_id\n    self.connect_kwargs: tp.Final = connect_kwargs\n    self.serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgResultBackend.keep_results","title":"keep_results  <code>instance-attribute</code>","text":"<pre><code>keep_results = keep_results\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgResultBackend.table_name","title":"table_name  <code>instance-attribute</code>","text":"<pre><code>table_name = table_name\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgResultBackend.field_for_task_id","title":"field_for_task_id  <code>instance-attribute</code>","text":"<pre><code>field_for_task_id = field_for_task_id\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgResultBackend.connect_kwargs","title":"connect_kwargs  <code>instance-attribute</code>","text":"<pre><code>connect_kwargs = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgResultBackend.serializer","title":"serializer  <code>instance-attribute</code>","text":"<pre><code>serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgResultBackend.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgResultBackend.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the result backend.</p> <p>Construct new connection pool and create new table for results if not exists.</p> Source code in <code>src/taskiq_pg/psycopg/result_backend.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the result backend.\n\n    Construct new connection pool\n    and create new table for results if not exists.\n    \"\"\"\n    self._database_pool = AsyncConnectionPool(\n        conninfo=self.dsn if self.dsn is not None else \"\",\n        open=False,\n        **self.connect_kwargs,\n    )\n    await self._database_pool.open()\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            query=sql.SQL(queries.CREATE_TABLE_QUERY).format(\n                sql.Identifier(self.table_name),\n                sql.SQL(self.field_for_task_id),\n            ),\n        )\n        await cursor.execute(\n            query=sql.SQL(queries.ADD_PROGRESS_COLUMN_QUERY).format(\n                sql.Identifier(self.table_name),\n            ),\n        )\n        await cursor.execute(\n            query=sql.SQL(queries.CREATE_INDEX_QUERY).format(\n                sql.Identifier(self.table_name + \"_task_id_idx\"),\n                sql.Identifier(self.table_name),\n            ),\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgResultBackend.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/psycopg/result_backend.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        await self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgResultBackend.set_result","title":"set_result  <code>async</code>","text":"<pre><code>set_result(task_id, result)\n</code></pre> <p>Set result to the PostgreSQL table.</p> <p>:param task_id: ID of the task. :param result: result of the task.</p> Source code in <code>src/taskiq_pg/psycopg/result_backend.py</code> <pre><code>async def set_result(\n    self,\n    task_id: str,\n    result: TaskiqResult[ReturnType],\n) -&gt; None:\n    \"\"\"\n    Set result to the PostgreSQL table.\n\n    :param task_id: ID of the task.\n    :param result: result of the task.\n    \"\"\"\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            query=sql.SQL(queries.INSERT_RESULT_QUERY).format(\n                sql.Identifier(self.table_name),\n            ),\n            params=[\n                task_id,\n                self.serializer.dumpb(model_dump(result)),\n            ],\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgResultBackend.is_result_ready","title":"is_result_ready  <code>async</code>","text":"<pre><code>is_result_ready(task_id)\n</code></pre> <p>Returns whether the result is ready.</p> <p>:param task_id: ID of the task.</p> <p>:returns: True if the result is ready else False.</p> Source code in <code>src/taskiq_pg/psycopg/result_backend.py</code> <pre><code>async def is_result_ready(self, task_id: str) -&gt; bool:\n    \"\"\"\n    Returns whether the result is ready.\n\n    :param task_id: ID of the task.\n\n    :returns: True if the result is ready else False.\n    \"\"\"\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        execute_result = await cursor.execute(\n            query=sql.SQL(queries.IS_RESULT_EXISTS_QUERY).format(\n                sql.Identifier(self.table_name),\n            ),\n            params=[task_id],\n        )\n        row = await execute_result.fetchone()\n        return bool(row and row[0])\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgResultBackend.get_result","title":"get_result  <code>async</code>","text":"<pre><code>get_result(task_id, with_logs=False)\n</code></pre> <p>Retrieve result from the task.</p> <p>:param task_id: task's id. :param with_logs: if True it will download task's logs. :raises ResultIsMissingError: if there is no result when trying to get it. :return: TaskiqResult.</p> Source code in <code>src/taskiq_pg/psycopg/result_backend.py</code> <pre><code>async def get_result(\n    self,\n    task_id: str,\n    with_logs: bool = False,\n) -&gt; TaskiqResult[ReturnType]:\n    \"\"\"\n    Retrieve result from the task.\n\n    :param task_id: task's id.\n    :param with_logs: if True it will download task's logs.\n    :raises ResultIsMissingError: if there is no result when trying to get it.\n    :return: TaskiqResult.\n    \"\"\"\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        execute_result = await cursor.execute(\n            query=sql.SQL(queries.SELECT_RESULT_QUERY).format(\n                sql.Identifier(self.table_name),\n            ),\n            params=[task_id],\n        )\n        result = await execute_result.fetchone()\n        if result is None:\n            msg = f\"Cannot find record with task_id = {task_id} in PostgreSQL\"\n            raise ResultIsMissingError(msg)\n        result_in_bytes: tp.Final = result[0]\n\n        if not self.keep_results:\n            await cursor.execute(\n                query=sql.SQL(queries.DELETE_RESULT_QUERY).format(\n                    sql.Identifier(self.table_name),\n                ),\n                params=[task_id],\n            )\n\n        taskiq_result: tp.Final = model_validate(\n            TaskiqResult[ReturnType],\n            self.serializer.loadb(result_in_bytes),\n        )\n\n        if not with_logs:\n            taskiq_result.log = None\n\n        return taskiq_result\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgResultBackend.set_progress","title":"set_progress  <code>async</code>","text":"<pre><code>set_progress(task_id, progress)\n</code></pre> <p>Saves progress.</p> <p>:param task_id: task's id. :param progress: progress of execution.</p> Source code in <code>src/taskiq_pg/psycopg/result_backend.py</code> <pre><code>async def set_progress(\n    self,\n    task_id: str,\n    progress: TaskProgress[tp.Any],\n) -&gt; None:\n    \"\"\"\n    Saves progress.\n\n    :param task_id: task's id.\n    :param progress: progress of execution.\n    \"\"\"\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            query=sql.SQL(queries.INSERT_PROGRESS_QUERY).format(\n                sql.Identifier(self.table_name),\n            ),\n            params=[\n                task_id,\n                self.serializer.dumpb(model_dump(progress)),\n                self.serializer.dumpb(model_dump(progress)),\n            ],\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgResultBackend.get_progress","title":"get_progress  <code>async</code>","text":"<pre><code>get_progress(task_id)\n</code></pre> <p>Gets progress.</p> <p>:param task_id: task's id.</p> Source code in <code>src/taskiq_pg/psycopg/result_backend.py</code> <pre><code>async def get_progress(\n    self,\n    task_id: str,\n) -&gt; TaskProgress[tp.Any] | None:\n    \"\"\"\n    Gets progress.\n\n    :param task_id: task's id.\n    \"\"\"\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        execute_result = await cursor.execute(\n            query=sql.SQL(queries.SELECT_PROGRESS_QUERY).format(\n                sql.Identifier(self.table_name),\n            ),\n            params=[task_id],\n        )\n        progress_in_bytes = await execute_result.fetchone()\n        if progress_in_bytes is None or progress_in_bytes[0] is None:\n            return None\n        return model_validate(\n            TaskProgress[tp.Any],\n            self.serializer.loadb(progress_in_bytes[0]),\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgScheduleSource","title":"PsycopgScheduleSource","text":"<pre><code>PsycopgScheduleSource(\n    broker,\n    dsn=\"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name=\"taskiq_schedules\",\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresScheduleSource</code></p> <p>Schedule source that uses psycopg to store schedules in PostgreSQL.</p> <p>Initialize the PostgreSQL scheduler source.</p> <p>Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database. This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks across application restarts.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>str | Callable[[], str]</code>, default:                   <code>'postgresql://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>PostgreSQL connection string</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_schedules'</code> )           \u2013            <p>Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.</p> </li> <li> <code>broker</code>               (<code>AsyncBroker</code>)           \u2013            <p>The TaskIQ broker instance to use for finding and managing tasks. Required if startup_schedule is provided.</p> </li> <li> <code>**connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional keyword arguments passed to the database connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def __init__(\n    self,\n    broker: AsyncBroker,\n    dsn: str | tp.Callable[[], str] = \"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name: str = \"taskiq_schedules\",\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Initialize the PostgreSQL scheduler source.\n\n    Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database.\n    This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks\n    across application restarts.\n\n    Args:\n        dsn: PostgreSQL connection string\n        table_name: Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.\n        broker: The TaskIQ broker instance to use for finding and managing tasks.\n            Required if startup_schedule is provided.\n        **connect_kwargs: Additional keyword arguments passed to the database connection pool.\n\n    \"\"\"\n    self._broker: tp.Final = broker\n    self._dsn: tp.Final = dsn\n    self._table_name: tp.Final = table_name\n    self._connect_kwargs: tp.Final = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgScheduleSource.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgScheduleSource.extract_scheduled_tasks_from_broker","title":"extract_scheduled_tasks_from_broker","text":"<pre><code>extract_scheduled_tasks_from_broker()\n</code></pre> <p>Extract schedules from tasks that were registered in broker.</p> <p>Returns:</p> <ul> <li> <code>list[ScheduledTask]</code>           \u2013            <p>A list of ScheduledTask instances extracted from the task's labels.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def extract_scheduled_tasks_from_broker(self) -&gt; list[ScheduledTask]:\n    \"\"\"\n    Extract schedules from tasks that were registered in broker.\n\n    Returns:\n        A list of ScheduledTask instances extracted from the task's labels.\n    \"\"\"\n    scheduled_tasks_for_creation: list[ScheduledTask] = []\n    for task_name, task in self._broker.get_all_tasks().items():\n        if \"schedule\" not in task.labels:\n            logger.debug(\"Task %s has no schedule, skipping\", task_name)\n            continue\n        if not isinstance(task.labels[\"schedule\"], list):\n            logger.warning(\n                \"Schedule for task %s is not a list, skipping\",\n                task_name,\n            )\n            continue\n        for schedule in task.labels[\"schedule\"]:\n            try:\n                new_schedule = ScheduledTask.model_validate(\n                    {\n                        \"task_name\": task_name,\n                        \"labels\": schedule.get(\"labels\", {}),\n                        \"args\": schedule.get(\"args\", []),\n                        \"kwargs\": schedule.get(\"kwargs\", {}),\n                        \"schedule_id\": str(uuid.uuid4()),\n                        \"cron\": schedule.get(\"cron\", None),\n                        \"cron_offset\": schedule.get(\"cron_offset\", None),\n                        \"interval\": schedule.get(\"interval\", None),\n                        \"time\": schedule.get(\"time\", None),\n                    },\n                )\n                scheduled_tasks_for_creation.append(new_schedule)\n            except ValidationError:  # noqa: PERF203\n                logger.exception(\n                    \"Schedule for task %s is not valid, skipping\",\n                    task_name,\n                )\n                continue\n    return scheduled_tasks_for_creation\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgScheduleSource.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the schedule source.</p> <p>Construct new connection pool, create new table for schedules if not exists and fill table with schedules from task labels.</p> Source code in <code>src/taskiq_pg/psycopg/schedule_source.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the schedule source.\n\n    Construct new connection pool, create new table for schedules if not exists\n    and fill table with schedules from task labels.\n    \"\"\"\n    self._database_pool = AsyncConnectionPool(\n        conninfo=self.dsn if self.dsn is not None else \"\",\n        open=False,\n        **self._connect_kwargs,\n    )\n    await self._database_pool.open()\n\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            sql.SQL(CREATE_SCHEDULES_TABLE_QUERY).format(sql.Identifier(self._table_name)),\n        )\n    scheduled_tasks_for_creation = self.extract_scheduled_tasks_from_broker()\n    await self._update_schedules_on_startup(scheduled_tasks_for_creation)\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgScheduleSource.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/psycopg/schedule_source.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        await self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgScheduleSource.get_schedules","title":"get_schedules  <code>async</code>","text":"<pre><code>get_schedules()\n</code></pre> <p>Fetch schedules from the database.</p> Source code in <code>src/taskiq_pg/psycopg/schedule_source.py</code> <pre><code>async def get_schedules(self) -&gt; list[\"ScheduledTask\"]:\n    \"\"\"Fetch schedules from the database.\"\"\"\n    schedules = []\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        rows_with_schedules = await cursor.execute(\n            sql.SQL(SELECT_SCHEDULES_QUERY).format(sql.Identifier(self._table_name)),\n        )\n        rows = await rows_with_schedules.fetchall()\n        for schedule_id, task_name, schedule in rows:\n            schedules.append(\n                ScheduledTask.model_validate(\n                    {\n                        \"schedule_id\": str(schedule_id),\n                        \"task_name\": task_name,\n                        \"labels\": schedule[\"labels\"],\n                        \"args\": schedule[\"args\"],\n                        \"kwargs\": schedule[\"kwargs\"],\n                        \"cron\": schedule[\"cron\"],\n                        \"cron_offset\": schedule[\"cron_offset\"],\n                        \"time\": schedule[\"time\"],\n                        \"interval\": schedule[\"interval\"],\n                    },\n                ),\n            )\n    return schedules\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgScheduleSource.add_schedule","title":"add_schedule  <code>async</code>","text":"<pre><code>add_schedule(schedule)\n</code></pre> <p>Add a new schedule.</p> <p>Parameters:</p> <ul> <li> <code>schedule</code>               (<code>ScheduledTask</code>)           \u2013            <p>schedule to add.</p> </li> </ul> Source code in <code>src/taskiq_pg/psycopg/schedule_source.py</code> <pre><code>async def add_schedule(self, schedule: \"ScheduledTask\") -&gt; None:\n    \"\"\"\n    Add a new schedule.\n\n    Args:\n        schedule: schedule to add.\n    \"\"\"\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            sql.SQL(INSERT_SCHEDULE_QUERY).format(sql.Identifier(self._table_name)),\n            [\n                uuid.UUID(schedule.schedule_id),\n                schedule.task_name,\n                schedule.model_dump_json(\n                    exclude={\"schedule_id\", \"task_name\"},\n                ),\n            ]\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgScheduleSource.delete_schedule","title":"delete_schedule  <code>async</code>","text":"<pre><code>delete_schedule(schedule_id)\n</code></pre> <p>Method to delete schedule by id.</p> <p>This is useful for schedule cancelation.</p> <p>Parameters:</p> <ul> <li> <code>schedule_id</code>               (<code>str</code>)           \u2013            <p>id of schedule to delete.</p> </li> </ul> Source code in <code>src/taskiq_pg/psycopg/schedule_source.py</code> <pre><code>async def delete_schedule(self, schedule_id: str) -&gt; None:\n    \"\"\"\n    Method to delete schedule by id.\n\n    This is useful for schedule cancelation.\n\n    Args:\n        schedule_id: id of schedule to delete.\n    \"\"\"\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            sql.SQL(DELETE_SCHEDULE_QUERY).format(sql.Identifier(self._table_name)),\n            [schedule_id],\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.PsycopgScheduleSource.post_send","title":"post_send  <code>async</code>","text":"<pre><code>post_send(task)\n</code></pre> <p>Delete a task after it's completed.</p> Source code in <code>src/taskiq_pg/psycopg/schedule_source.py</code> <pre><code>async def post_send(self, task: ScheduledTask) -&gt; None:\n    \"\"\"Delete a task after it's completed.\"\"\"\n    if task.time is not None:\n        await self.delete_schedule(task.schedule_id)\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.broker","title":"broker","text":""},{"location":"reference/#taskiq_pg.psycopg.broker.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger('taskiq.psycopg_broker')\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.broker.PsycopgBroker","title":"PsycopgBroker","text":"<pre><code>PsycopgBroker(\n    dsn=\"postgresql://postgres:postgres@localhost:5432/postgres\",\n    result_backend=None,\n    task_id_generator=None,\n    channel_name=\"taskiq\",\n    table_name=\"taskiq_messages\",\n    max_retry_attempts=5,\n    read_kwargs=None,\n    write_kwargs=None,\n)\n</code></pre> <p>               Bases: <code>BasePostgresBroker</code></p> <p>Broker that uses PostgreSQL and psycopg with LISTEN/NOTIFY.</p> <p>Construct a new broker.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>str | Callable[[], str]</code>, default:                   <code>'postgresql://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>connection string to PostgreSQL, or callable returning one.</p> </li> <li> <code>result_backend</code>               (<code>AsyncResultBackend[_T] | None</code>, default:                   <code>None</code> )           \u2013            <p>Custom result backend.</p> </li> <li> <code>task_id_generator</code>               (<code>Callable[[], str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Custom task_id generator.</p> </li> <li> <code>channel_name</code>               (<code>str</code>, default:                   <code>'taskiq'</code> )           \u2013            <p>Name of the channel to listen on.</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_messages'</code> )           \u2013            <p>Name of the table to store messages.</p> </li> <li> <code>max_retry_attempts</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>Maximum number of message processing attempts.</p> </li> <li> <code>read_kwargs</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional arguments for read connection creation.</p> </li> <li> <code>write_kwargs</code>               (<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional arguments for write pool creation.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/broker.py</code> <pre><code>def __init__(  # noqa: PLR0913\n    self,\n    dsn: str | tp.Callable[[], str] = \"postgresql://postgres:postgres@localhost:5432/postgres\",\n    result_backend: AsyncResultBackend[_T] | None = None,\n    task_id_generator: tp.Callable[[], str] | None = None,\n    channel_name: str = \"taskiq\",\n    table_name: str = \"taskiq_messages\",\n    max_retry_attempts: int = 5,\n    read_kwargs: dict[str, tp.Any] | None = None,\n    write_kwargs: dict[str, tp.Any] | None = None,\n) -&gt; None:\n    \"\"\"\n    Construct a new broker.\n\n    Args:\n        dsn: connection string to PostgreSQL, or callable returning one.\n        result_backend: Custom result backend.\n        task_id_generator: Custom task_id generator.\n        channel_name: Name of the channel to listen on.\n        table_name: Name of the table to store messages.\n        max_retry_attempts: Maximum number of message processing attempts.\n        read_kwargs: Additional arguments for read connection creation.\n        write_kwargs: Additional arguments for write pool creation.\n\n    \"\"\"\n    super().__init__(\n        result_backend=result_backend,\n        task_id_generator=task_id_generator,\n    )\n    self._dsn: str | tp.Callable[[], str] = dsn\n    self.channel_name: str = channel_name\n    self.table_name: str = table_name\n    self.read_kwargs: dict[str, tp.Any] = read_kwargs or {}\n    self.write_kwargs: dict[str, tp.Any] = write_kwargs or {}\n    self.max_retry_attempts: int = max_retry_attempts\n    self._queue: asyncio.Queue[str] | None = None\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.broker.PsycopgBroker.channel_name","title":"channel_name  <code>instance-attribute</code>","text":"<pre><code>channel_name = channel_name\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.broker.PsycopgBroker.table_name","title":"table_name  <code>instance-attribute</code>","text":"<pre><code>table_name = table_name\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.broker.PsycopgBroker.read_kwargs","title":"read_kwargs  <code>instance-attribute</code>","text":"<pre><code>read_kwargs = read_kwargs or {}\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.broker.PsycopgBroker.write_kwargs","title":"write_kwargs  <code>instance-attribute</code>","text":"<pre><code>write_kwargs = write_kwargs or {}\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.broker.PsycopgBroker.max_retry_attempts","title":"max_retry_attempts  <code>instance-attribute</code>","text":"<pre><code>max_retry_attempts = max_retry_attempts\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.broker.PsycopgBroker.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>A string with dsn or None if dsn isn't set yet.</p> </li> </ul>"},{"location":"reference/#taskiq_pg.psycopg.broker.PsycopgBroker.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the broker.</p> Source code in <code>src/taskiq_pg/psycopg/broker.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"Initialize the broker.\"\"\"\n    await super().startup()\n    self._read_conn = await AsyncConnection.connect(\n        conninfo=self.dsn,\n        **self.read_kwargs,\n        autocommit=True,\n        cursor_factory=AsyncRawCursor,\n    )\n    self._write_pool = AsyncConnectionPool(\n        conninfo=self.dsn if self.dsn is not None else \"\",\n        open=False,\n        **self.write_kwargs,\n    )\n    await self._write_pool.open()\n\n    async with self._write_pool.connection() as connection, connection.cursor() as cursor:\n        await cursor.execute(sql.SQL(CREATE_MESSAGE_TABLE_QUERY).format(sql.Identifier(self.table_name)))\n\n    await self._read_conn.execute(sql.SQL(\"LISTEN {}\").format(sql.Identifier(self.channel_name)))\n    self._notifies_iter = self._read_conn.notifies()\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.broker.PsycopgBroker.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close all connections on shutdown.</p> Source code in <code>src/taskiq_pg/psycopg/broker.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close all connections on shutdown.\"\"\"\n    await super().shutdown()\n    if self._notifies_iter is not None:\n        with suppress(RuntimeError):  # RuntimeError: aclose(): asynchronous generator is already running\n            await self._notifies_iter.aclose()  # type: ignore[attr-defined]\n    if self._read_conn is not None:\n        await self._read_conn.notifies().aclose()\n        await self._read_conn.close()\n    if self._write_pool is not None:\n        await self._write_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.broker.PsycopgBroker.kick","title":"kick  <code>async</code>","text":"<pre><code>kick(message)\n</code></pre> <p>Send message to the channel.</p> <p>Inserts the message into the database and sends a NOTIFY.</p> <p>:param message: Message to send.</p> Source code in <code>src/taskiq_pg/psycopg/broker.py</code> <pre><code>async def kick(self, message: BrokerMessage) -&gt; None:\n    \"\"\"\n    Send message to the channel.\n\n    Inserts the message into the database and sends a NOTIFY.\n\n    :param message: Message to send.\n    \"\"\"\n    async with self._write_pool.connection() as connection, connection.cursor() as cursor:\n        # insert message into db table\n        await cursor.execute(\n            sql.SQL(INSERT_MESSAGE_QUERY).format(sql.Identifier(self.table_name)),\n            [\n                message.task_id,\n                message.task_name,\n                message.message.decode(),\n                json.dumps(message.labels),\n            ],\n        )\n        row = await cursor.fetchone()\n        if row is None:\n            msg = \"failed to insert message\"\n            raise RuntimeError(msg)\n        message_inserted_id = int(row[0])\n\n        delay_value = tp.cast(\"str | None\", message.labels.get(\"delay\"))\n        if delay_value is not None:\n            delay_seconds = int(delay_value)\n            await self._schedule_notification(message_inserted_id, delay_seconds)\n        else:\n            # Send NOTIFY with message ID as payload\n            await cursor.execute(\n                sql.SQL(\"NOTIFY {}, {}\").format(\n                    sql.Identifier(self.channel_name),\n                    sql.Literal(str(message_inserted_id)),\n                ),\n            )\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.broker.PsycopgBroker.listen","title":"listen  <code>async</code>","text":"<pre><code>listen()\n</code></pre> <p>Listen to the channel.</p> <p>Yields messages as they are received.</p> <p>:yields: AckableMessage instances.</p> Source code in <code>src/taskiq_pg/psycopg/broker.py</code> <pre><code>async def listen(self) -&gt; AsyncGenerator[AckableMessage, None]:\n    \"\"\"\n    Listen to the channel.\n\n    Yields messages as they are received.\n\n    :yields: AckableMessage instances.\n    \"\"\"\n    while True:\n        async for message_id_str in self._listen_context():\n            message_id = int(message_id_str)  # payload is the message id\n            try:\n                async with self._write_pool.connection() as connection, connection.cursor() as cursor:\n                    await cursor.execute(\n                        sql.SQL(CLAIM_MESSAGE_QUERY).format(sql.Identifier(self.table_name)),\n                        [message_id],\n                    )\n                    claimed_message = await cursor.fetchone()\n                    if claimed_message is None:\n                        continue\n            except psycopg.OperationalError:  # message was claimed by another worker\n                continue\n            message_str = claimed_message[3]\n            if not isinstance(message_str, str):\n                msg = \"Message is not a string\"\n                raise TypeError(msg)\n            message_data = message_str.encode()\n\n            async def ack(*, _message_id: int = message_id) -&gt; None:\n                async with self._write_pool.connection() as connection, connection.cursor() as cursor:\n                    await cursor.execute(\n                        sql.SQL(DELETE_MESSAGE_QUERY).format(sql.Identifier(self.table_name)),\n                        [_message_id],\n                    )\n\n            yield AckableMessage(data=message_data, ack=ack)\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries","title":"queries","text":""},{"location":"reference/#taskiq_pg.psycopg.queries.CREATE_TABLE_QUERY","title":"CREATE_TABLE_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_TABLE_QUERY = \"\\nCREATE TABLE IF NOT EXISTS {} (\\n    task_id {} UNIQUE,\\n    result BYTEA,\\n    progress BYTEA\\n)\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.ADD_PROGRESS_COLUMN_QUERY","title":"ADD_PROGRESS_COLUMN_QUERY  <code>module-attribute</code>","text":"<pre><code>ADD_PROGRESS_COLUMN_QUERY = \"\\nALTER TABLE {} ADD COLUMN IF NOT EXISTS progress BYTEA;\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.CREATE_INDEX_QUERY","title":"CREATE_INDEX_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_INDEX_QUERY = \"\\nCREATE INDEX IF NOT EXISTS {} ON {} USING HASH (task_id)\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.INSERT_RESULT_QUERY","title":"INSERT_RESULT_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_RESULT_QUERY = \"\\nINSERT INTO {} VALUES (%s, %s)\\nON CONFLICT (task_id)\\nDO UPDATE\\nSET result = EXCLUDED.result;\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.INSERT_PROGRESS_QUERY","title":"INSERT_PROGRESS_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_PROGRESS_QUERY = \"\\nINSERT INTO {} VALUES (%s, NULL, %s)\\nON CONFLICT (task_id)\\nDO UPDATE\\nSET progress = %s\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.SELECT_PROGRESS_QUERY","title":"SELECT_PROGRESS_QUERY  <code>module-attribute</code>","text":"<pre><code>SELECT_PROGRESS_QUERY = (\n    \"\\nSELECT progress FROM {} WHERE task_id = %s\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.IS_RESULT_EXISTS_QUERY","title":"IS_RESULT_EXISTS_QUERY  <code>module-attribute</code>","text":"<pre><code>IS_RESULT_EXISTS_QUERY = \"\\nSELECT EXISTS(\\n    SELECT 1 FROM {} WHERE task_id = %s and result IS NOT NULL\\n);\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.SELECT_RESULT_QUERY","title":"SELECT_RESULT_QUERY  <code>module-attribute</code>","text":"<pre><code>SELECT_RESULT_QUERY = (\n    \"\\nSELECT result FROM {} WHERE task_id = %s;\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.DELETE_RESULT_QUERY","title":"DELETE_RESULT_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_RESULT_QUERY = (\n    \"\\nDELETE FROM {} WHERE task_id = %s;\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.CREATE_MESSAGE_TABLE_QUERY","title":"CREATE_MESSAGE_TABLE_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_MESSAGE_TABLE_QUERY = \"\\nCREATE TABLE IF NOT EXISTS {} (\\n    id SERIAL PRIMARY KEY,\\n    task_id VARCHAR NOT NULL,\\n    task_name VARCHAR NOT NULL,\\n    message TEXT NOT NULL,\\n    labels JSONB NOT NULL,\\n    status TEXT NOT NULL DEFAULT 'pending',\\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\\n);\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.INSERT_MESSAGE_QUERY","title":"INSERT_MESSAGE_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_MESSAGE_QUERY = \"\\nINSERT INTO {} (task_id, task_name, message, labels)\\nVALUES (%s, %s, %s, %s)\\nRETURNING id\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.CLAIM_MESSAGE_QUERY","title":"CLAIM_MESSAGE_QUERY  <code>module-attribute</code>","text":"<pre><code>CLAIM_MESSAGE_QUERY = \"UPDATE {} SET status = 'processing' WHERE id = %s AND status = 'pending' RETURNING *\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.DELETE_MESSAGE_QUERY","title":"DELETE_MESSAGE_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_MESSAGE_QUERY = 'DELETE FROM {} WHERE id = %s'\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.CREATE_SCHEDULES_TABLE_QUERY","title":"CREATE_SCHEDULES_TABLE_QUERY  <code>module-attribute</code>","text":"<pre><code>CREATE_SCHEDULES_TABLE_QUERY = \"\\nCREATE TABLE IF NOT EXISTS {} (\\n    id UUID PRIMARY KEY,\\n    task_name VARCHAR(100) NOT NULL,\\n    schedule JSONB NOT NULL,\\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\\n);\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.INSERT_SCHEDULE_QUERY","title":"INSERT_SCHEDULE_QUERY  <code>module-attribute</code>","text":"<pre><code>INSERT_SCHEDULE_QUERY = \"\\nINSERT INTO {} (id, task_name, schedule)\\nVALUES (%s, %s, %s)\\nON CONFLICT (id) DO UPDATE\\nSET task_name = EXCLUDED.task_name,\\n    schedule = EXCLUDED.schedule,\\n    updated_at = NOW();\\n\"\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.SELECT_SCHEDULES_QUERY","title":"SELECT_SCHEDULES_QUERY  <code>module-attribute</code>","text":"<pre><code>SELECT_SCHEDULES_QUERY = (\n    \"\\nSELECT id, task_name, schedule\\nFROM {};\\n\"\n)\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.DELETE_ALL_SCHEDULES_QUERY","title":"DELETE_ALL_SCHEDULES_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_ALL_SCHEDULES_QUERY = '\\nDELETE FROM {};\\n'\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.queries.DELETE_SCHEDULE_QUERY","title":"DELETE_SCHEDULE_QUERY  <code>module-attribute</code>","text":"<pre><code>DELETE_SCHEDULE_QUERY = '\\nDELETE FROM {} WHERE id = %s;\\n'\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.result_backend","title":"result_backend","text":""},{"location":"reference/#taskiq_pg.psycopg.result_backend.PsycopgResultBackend","title":"PsycopgResultBackend","text":"<pre><code>PsycopgResultBackend(\n    dsn=\"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results=True,\n    table_name=\"taskiq_results\",\n    field_for_task_id=\"VarChar\",\n    serializer=None,\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresResultBackend</code></p> <p>Result backend for TaskIQ based on psycopg.</p> <p>Construct new result backend.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>Callable[[], str] | str | None</code>, default:                   <code>'postgres://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>connection string to PostgreSQL, or callable returning one.</p> </li> <li> <code>keep_results</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>flag to not remove results from the database after reading.</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_results'</code> )           \u2013            <p>name of the table to store results.</p> </li> <li> <code>field_for_task_id</code>               (<code>Literal['VarChar', 'Text', 'Uuid']</code>, default:                   <code>'VarChar'</code> )           \u2013            <p>type of the field to store task_id.</p> </li> <li> <code>serializer</code>               (<code>TaskiqSerializer | None</code>, default:                   <code>None</code> )           \u2013            <p>serializer class to serialize/deserialize result from task.</p> </li> <li> <code>connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>additional arguments for creating connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/result_backend.py</code> <pre><code>def __init__(\n    self,\n    dsn: tp.Callable[[], str] | str | None = \"postgres://postgres:postgres@localhost:5432/postgres\",\n    keep_results: bool = True,\n    table_name: str = \"taskiq_results\",\n    field_for_task_id: tp.Literal[\"VarChar\", \"Text\", \"Uuid\"] = \"VarChar\",\n    serializer: TaskiqSerializer | None = None,\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Construct new result backend.\n\n    Args:\n        dsn: connection string to PostgreSQL, or callable returning one.\n        keep_results: flag to not remove results from the database after reading.\n        table_name: name of the table to store results.\n        field_for_task_id: type of the field to store task_id.\n        serializer: serializer class to serialize/deserialize result from task.\n        connect_kwargs: additional arguments for creating connection pool.\n\n    \"\"\"\n    self._dsn: tp.Final = dsn\n    self.keep_results: tp.Final = keep_results\n    self.table_name: tp.Final = table_name\n    self.field_for_task_id: tp.Final = field_for_task_id\n    self.connect_kwargs: tp.Final = connect_kwargs\n    self.serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.result_backend.PsycopgResultBackend.keep_results","title":"keep_results  <code>instance-attribute</code>","text":"<pre><code>keep_results = keep_results\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.result_backend.PsycopgResultBackend.table_name","title":"table_name  <code>instance-attribute</code>","text":"<pre><code>table_name = table_name\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.result_backend.PsycopgResultBackend.field_for_task_id","title":"field_for_task_id  <code>instance-attribute</code>","text":"<pre><code>field_for_task_id = field_for_task_id\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.result_backend.PsycopgResultBackend.connect_kwargs","title":"connect_kwargs  <code>instance-attribute</code>","text":"<pre><code>connect_kwargs = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.result_backend.PsycopgResultBackend.serializer","title":"serializer  <code>instance-attribute</code>","text":"<pre><code>serializer = serializer or PickleSerializer()\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.result_backend.PsycopgResultBackend.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.psycopg.result_backend.PsycopgResultBackend.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the result backend.</p> <p>Construct new connection pool and create new table for results if not exists.</p> Source code in <code>src/taskiq_pg/psycopg/result_backend.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the result backend.\n\n    Construct new connection pool\n    and create new table for results if not exists.\n    \"\"\"\n    self._database_pool = AsyncConnectionPool(\n        conninfo=self.dsn if self.dsn is not None else \"\",\n        open=False,\n        **self.connect_kwargs,\n    )\n    await self._database_pool.open()\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            query=sql.SQL(queries.CREATE_TABLE_QUERY).format(\n                sql.Identifier(self.table_name),\n                sql.SQL(self.field_for_task_id),\n            ),\n        )\n        await cursor.execute(\n            query=sql.SQL(queries.ADD_PROGRESS_COLUMN_QUERY).format(\n                sql.Identifier(self.table_name),\n            ),\n        )\n        await cursor.execute(\n            query=sql.SQL(queries.CREATE_INDEX_QUERY).format(\n                sql.Identifier(self.table_name + \"_task_id_idx\"),\n                sql.Identifier(self.table_name),\n            ),\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.result_backend.PsycopgResultBackend.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/psycopg/result_backend.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        await self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.result_backend.PsycopgResultBackend.set_result","title":"set_result  <code>async</code>","text":"<pre><code>set_result(task_id, result)\n</code></pre> <p>Set result to the PostgreSQL table.</p> <p>:param task_id: ID of the task. :param result: result of the task.</p> Source code in <code>src/taskiq_pg/psycopg/result_backend.py</code> <pre><code>async def set_result(\n    self,\n    task_id: str,\n    result: TaskiqResult[ReturnType],\n) -&gt; None:\n    \"\"\"\n    Set result to the PostgreSQL table.\n\n    :param task_id: ID of the task.\n    :param result: result of the task.\n    \"\"\"\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            query=sql.SQL(queries.INSERT_RESULT_QUERY).format(\n                sql.Identifier(self.table_name),\n            ),\n            params=[\n                task_id,\n                self.serializer.dumpb(model_dump(result)),\n            ],\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.result_backend.PsycopgResultBackend.is_result_ready","title":"is_result_ready  <code>async</code>","text":"<pre><code>is_result_ready(task_id)\n</code></pre> <p>Returns whether the result is ready.</p> <p>:param task_id: ID of the task.</p> <p>:returns: True if the result is ready else False.</p> Source code in <code>src/taskiq_pg/psycopg/result_backend.py</code> <pre><code>async def is_result_ready(self, task_id: str) -&gt; bool:\n    \"\"\"\n    Returns whether the result is ready.\n\n    :param task_id: ID of the task.\n\n    :returns: True if the result is ready else False.\n    \"\"\"\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        execute_result = await cursor.execute(\n            query=sql.SQL(queries.IS_RESULT_EXISTS_QUERY).format(\n                sql.Identifier(self.table_name),\n            ),\n            params=[task_id],\n        )\n        row = await execute_result.fetchone()\n        return bool(row and row[0])\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.result_backend.PsycopgResultBackend.get_result","title":"get_result  <code>async</code>","text":"<pre><code>get_result(task_id, with_logs=False)\n</code></pre> <p>Retrieve result from the task.</p> <p>:param task_id: task's id. :param with_logs: if True it will download task's logs. :raises ResultIsMissingError: if there is no result when trying to get it. :return: TaskiqResult.</p> Source code in <code>src/taskiq_pg/psycopg/result_backend.py</code> <pre><code>async def get_result(\n    self,\n    task_id: str,\n    with_logs: bool = False,\n) -&gt; TaskiqResult[ReturnType]:\n    \"\"\"\n    Retrieve result from the task.\n\n    :param task_id: task's id.\n    :param with_logs: if True it will download task's logs.\n    :raises ResultIsMissingError: if there is no result when trying to get it.\n    :return: TaskiqResult.\n    \"\"\"\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        execute_result = await cursor.execute(\n            query=sql.SQL(queries.SELECT_RESULT_QUERY).format(\n                sql.Identifier(self.table_name),\n            ),\n            params=[task_id],\n        )\n        result = await execute_result.fetchone()\n        if result is None:\n            msg = f\"Cannot find record with task_id = {task_id} in PostgreSQL\"\n            raise ResultIsMissingError(msg)\n        result_in_bytes: tp.Final = result[0]\n\n        if not self.keep_results:\n            await cursor.execute(\n                query=sql.SQL(queries.DELETE_RESULT_QUERY).format(\n                    sql.Identifier(self.table_name),\n                ),\n                params=[task_id],\n            )\n\n        taskiq_result: tp.Final = model_validate(\n            TaskiqResult[ReturnType],\n            self.serializer.loadb(result_in_bytes),\n        )\n\n        if not with_logs:\n            taskiq_result.log = None\n\n        return taskiq_result\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.result_backend.PsycopgResultBackend.set_progress","title":"set_progress  <code>async</code>","text":"<pre><code>set_progress(task_id, progress)\n</code></pre> <p>Saves progress.</p> <p>:param task_id: task's id. :param progress: progress of execution.</p> Source code in <code>src/taskiq_pg/psycopg/result_backend.py</code> <pre><code>async def set_progress(\n    self,\n    task_id: str,\n    progress: TaskProgress[tp.Any],\n) -&gt; None:\n    \"\"\"\n    Saves progress.\n\n    :param task_id: task's id.\n    :param progress: progress of execution.\n    \"\"\"\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            query=sql.SQL(queries.INSERT_PROGRESS_QUERY).format(\n                sql.Identifier(self.table_name),\n            ),\n            params=[\n                task_id,\n                self.serializer.dumpb(model_dump(progress)),\n                self.serializer.dumpb(model_dump(progress)),\n            ],\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.result_backend.PsycopgResultBackend.get_progress","title":"get_progress  <code>async</code>","text":"<pre><code>get_progress(task_id)\n</code></pre> <p>Gets progress.</p> <p>:param task_id: task's id.</p> Source code in <code>src/taskiq_pg/psycopg/result_backend.py</code> <pre><code>async def get_progress(\n    self,\n    task_id: str,\n) -&gt; TaskProgress[tp.Any] | None:\n    \"\"\"\n    Gets progress.\n\n    :param task_id: task's id.\n    \"\"\"\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        execute_result = await cursor.execute(\n            query=sql.SQL(queries.SELECT_PROGRESS_QUERY).format(\n                sql.Identifier(self.table_name),\n            ),\n            params=[task_id],\n        )\n        progress_in_bytes = await execute_result.fetchone()\n        if progress_in_bytes is None or progress_in_bytes[0] is None:\n            return None\n        return model_validate(\n            TaskProgress[tp.Any],\n            self.serializer.loadb(progress_in_bytes[0]),\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.schedule_source","title":"schedule_source","text":""},{"location":"reference/#taskiq_pg.psycopg.schedule_source.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger('taskiq_pg.psycopg_schedule_source')\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.schedule_source.PsycopgScheduleSource","title":"PsycopgScheduleSource","text":"<pre><code>PsycopgScheduleSource(\n    broker,\n    dsn=\"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name=\"taskiq_schedules\",\n    **connect_kwargs,\n)\n</code></pre> <p>               Bases: <code>BasePostgresScheduleSource</code></p> <p>Schedule source that uses psycopg to store schedules in PostgreSQL.</p> <p>Initialize the PostgreSQL scheduler source.</p> <p>Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database. This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks across application restarts.</p> <p>Parameters:</p> <ul> <li> <code>dsn</code>               (<code>str | Callable[[], str]</code>, default:                   <code>'postgresql://postgres:postgres@localhost:5432/postgres'</code> )           \u2013            <p>PostgreSQL connection string</p> </li> <li> <code>table_name</code>               (<code>str</code>, default:                   <code>'taskiq_schedules'</code> )           \u2013            <p>Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.</p> </li> <li> <code>broker</code>               (<code>AsyncBroker</code>)           \u2013            <p>The TaskIQ broker instance to use for finding and managing tasks. Required if startup_schedule is provided.</p> </li> <li> <code>**connect_kwargs</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional keyword arguments passed to the database connection pool.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def __init__(\n    self,\n    broker: AsyncBroker,\n    dsn: str | tp.Callable[[], str] = \"postgresql://postgres:postgres@localhost:5432/postgres\",\n    table_name: str = \"taskiq_schedules\",\n    **connect_kwargs: tp.Any,\n) -&gt; None:\n    \"\"\"\n    Initialize the PostgreSQL scheduler source.\n\n    Sets up a scheduler source that stores scheduled tasks in a PostgreSQL database.\n    This scheduler source manages task schedules, allowing for persistent storage and retrieval of scheduled tasks\n    across application restarts.\n\n    Args:\n        dsn: PostgreSQL connection string\n        table_name: Name of the table to store scheduled tasks. Will be created automatically if it doesn't exist.\n        broker: The TaskIQ broker instance to use for finding and managing tasks.\n            Required if startup_schedule is provided.\n        **connect_kwargs: Additional keyword arguments passed to the database connection pool.\n\n    \"\"\"\n    self._broker: tp.Final = broker\n    self._dsn: tp.Final = dsn\n    self._table_name: tp.Final = table_name\n    self._connect_kwargs: tp.Final = connect_kwargs\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.schedule_source.PsycopgScheduleSource.dsn","title":"dsn  <code>property</code>","text":"<pre><code>dsn\n</code></pre> <p>Get the DSN string.</p> <p>Returns the DSN string or None if not set.</p>"},{"location":"reference/#taskiq_pg.psycopg.schedule_source.PsycopgScheduleSource.startup","title":"startup  <code>async</code>","text":"<pre><code>startup()\n</code></pre> <p>Initialize the schedule source.</p> <p>Construct new connection pool, create new table for schedules if not exists and fill table with schedules from task labels.</p> Source code in <code>src/taskiq_pg/psycopg/schedule_source.py</code> <pre><code>async def startup(self) -&gt; None:\n    \"\"\"\n    Initialize the schedule source.\n\n    Construct new connection pool, create new table for schedules if not exists\n    and fill table with schedules from task labels.\n    \"\"\"\n    self._database_pool = AsyncConnectionPool(\n        conninfo=self.dsn if self.dsn is not None else \"\",\n        open=False,\n        **self._connect_kwargs,\n    )\n    await self._database_pool.open()\n\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            sql.SQL(CREATE_SCHEDULES_TABLE_QUERY).format(sql.Identifier(self._table_name)),\n        )\n    scheduled_tasks_for_creation = self.extract_scheduled_tasks_from_broker()\n    await self._update_schedules_on_startup(scheduled_tasks_for_creation)\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.schedule_source.PsycopgScheduleSource.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown()\n</code></pre> <p>Close the connection pool.</p> Source code in <code>src/taskiq_pg/psycopg/schedule_source.py</code> <pre><code>async def shutdown(self) -&gt; None:\n    \"\"\"Close the connection pool.\"\"\"\n    if getattr(self, \"_database_pool\", None) is not None:\n        await self._database_pool.close()\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.schedule_source.PsycopgScheduleSource.get_schedules","title":"get_schedules  <code>async</code>","text":"<pre><code>get_schedules()\n</code></pre> <p>Fetch schedules from the database.</p> Source code in <code>src/taskiq_pg/psycopg/schedule_source.py</code> <pre><code>async def get_schedules(self) -&gt; list[\"ScheduledTask\"]:\n    \"\"\"Fetch schedules from the database.\"\"\"\n    schedules = []\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        rows_with_schedules = await cursor.execute(\n            sql.SQL(SELECT_SCHEDULES_QUERY).format(sql.Identifier(self._table_name)),\n        )\n        rows = await rows_with_schedules.fetchall()\n        for schedule_id, task_name, schedule in rows:\n            schedules.append(\n                ScheduledTask.model_validate(\n                    {\n                        \"schedule_id\": str(schedule_id),\n                        \"task_name\": task_name,\n                        \"labels\": schedule[\"labels\"],\n                        \"args\": schedule[\"args\"],\n                        \"kwargs\": schedule[\"kwargs\"],\n                        \"cron\": schedule[\"cron\"],\n                        \"cron_offset\": schedule[\"cron_offset\"],\n                        \"time\": schedule[\"time\"],\n                        \"interval\": schedule[\"interval\"],\n                    },\n                ),\n            )\n    return schedules\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.schedule_source.PsycopgScheduleSource.add_schedule","title":"add_schedule  <code>async</code>","text":"<pre><code>add_schedule(schedule)\n</code></pre> <p>Add a new schedule.</p> <p>Parameters:</p> <ul> <li> <code>schedule</code>               (<code>ScheduledTask</code>)           \u2013            <p>schedule to add.</p> </li> </ul> Source code in <code>src/taskiq_pg/psycopg/schedule_source.py</code> <pre><code>async def add_schedule(self, schedule: \"ScheduledTask\") -&gt; None:\n    \"\"\"\n    Add a new schedule.\n\n    Args:\n        schedule: schedule to add.\n    \"\"\"\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            sql.SQL(INSERT_SCHEDULE_QUERY).format(sql.Identifier(self._table_name)),\n            [\n                uuid.UUID(schedule.schedule_id),\n                schedule.task_name,\n                schedule.model_dump_json(\n                    exclude={\"schedule_id\", \"task_name\"},\n                ),\n            ]\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.schedule_source.PsycopgScheduleSource.delete_schedule","title":"delete_schedule  <code>async</code>","text":"<pre><code>delete_schedule(schedule_id)\n</code></pre> <p>Method to delete schedule by id.</p> <p>This is useful for schedule cancelation.</p> <p>Parameters:</p> <ul> <li> <code>schedule_id</code>               (<code>str</code>)           \u2013            <p>id of schedule to delete.</p> </li> </ul> Source code in <code>src/taskiq_pg/psycopg/schedule_source.py</code> <pre><code>async def delete_schedule(self, schedule_id: str) -&gt; None:\n    \"\"\"\n    Method to delete schedule by id.\n\n    This is useful for schedule cancelation.\n\n    Args:\n        schedule_id: id of schedule to delete.\n    \"\"\"\n    async with self._database_pool.connection() as connection, connection.cursor() as cursor:\n        await cursor.execute(\n            sql.SQL(DELETE_SCHEDULE_QUERY).format(sql.Identifier(self._table_name)),\n            [schedule_id],\n        )\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.schedule_source.PsycopgScheduleSource.post_send","title":"post_send  <code>async</code>","text":"<pre><code>post_send(task)\n</code></pre> <p>Delete a task after it's completed.</p> Source code in <code>src/taskiq_pg/psycopg/schedule_source.py</code> <pre><code>async def post_send(self, task: ScheduledTask) -&gt; None:\n    \"\"\"Delete a task after it's completed.\"\"\"\n    if task.time is not None:\n        await self.delete_schedule(task.schedule_id)\n</code></pre>"},{"location":"reference/#taskiq_pg.psycopg.schedule_source.PsycopgScheduleSource.extract_scheduled_tasks_from_broker","title":"extract_scheduled_tasks_from_broker","text":"<pre><code>extract_scheduled_tasks_from_broker()\n</code></pre> <p>Extract schedules from tasks that were registered in broker.</p> <p>Returns:</p> <ul> <li> <code>list[ScheduledTask]</code>           \u2013            <p>A list of ScheduledTask instances extracted from the task's labels.</p> </li> </ul> Source code in <code>src/taskiq_pg/_internal/schedule_source.py</code> <pre><code>def extract_scheduled_tasks_from_broker(self) -&gt; list[ScheduledTask]:\n    \"\"\"\n    Extract schedules from tasks that were registered in broker.\n\n    Returns:\n        A list of ScheduledTask instances extracted from the task's labels.\n    \"\"\"\n    scheduled_tasks_for_creation: list[ScheduledTask] = []\n    for task_name, task in self._broker.get_all_tasks().items():\n        if \"schedule\" not in task.labels:\n            logger.debug(\"Task %s has no schedule, skipping\", task_name)\n            continue\n        if not isinstance(task.labels[\"schedule\"], list):\n            logger.warning(\n                \"Schedule for task %s is not a list, skipping\",\n                task_name,\n            )\n            continue\n        for schedule in task.labels[\"schedule\"]:\n            try:\n                new_schedule = ScheduledTask.model_validate(\n                    {\n                        \"task_name\": task_name,\n                        \"labels\": schedule.get(\"labels\", {}),\n                        \"args\": schedule.get(\"args\", []),\n                        \"kwargs\": schedule.get(\"kwargs\", {}),\n                        \"schedule_id\": str(uuid.uuid4()),\n                        \"cron\": schedule.get(\"cron\", None),\n                        \"cron_offset\": schedule.get(\"cron_offset\", None),\n                        \"interval\": schedule.get(\"interval\", None),\n                        \"time\": schedule.get(\"time\", None),\n                    },\n                )\n                scheduled_tasks_for_creation.append(new_schedule)\n            except ValidationError:  # noqa: PERF203\n                logger.exception(\n                    \"Schedule for task %s is not valid, skipping\",\n                    task_name,\n                )\n                continue\n    return scheduled_tasks_for_creation\n</code></pre>"},{"location":"tutorial/common_issues/","title":"Common Issues","text":""},{"location":"tutorial/common_issues/#connection-errors","title":"Connection Errors","text":"<p>Ensure your connection string is correct:</p> <pre><code>dsn = \"postgresql://postgres:postgres@localhost:5432/postgres\"\n</code></pre> <p>Check PostgreSQL is running and accessible:</p> <pre><code>import asyncpg\n\ndsn = '...'\nconn = await asyncpg.connect(dsn)\nawait conn.close()\n</code></pre>"},{"location":"tutorial/common_issues/#table-creation-issues","title":"Table Creation Issues","text":"<p>Ensure user has <code>CREATE TABLE</code> permissions or manually create tables using provided schemas:</p> <pre><code>-- for broker\nCREATE TABLE taskiq_queue (\n    id SERIAL PRIMARY KEY,\n    task_id UUID NOT NULL,\n    task_name VARCHAR NOT NULL,\n    message BYTEA NOT NULL,\n    labels JSONB,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\n-- for result backend\nCREATE TABLE taskiq_results (\n    task_id UUID PRIMARY KEY,\n    result BYTEA,\n    is_err BOOLEAN DEFAULT FALSE,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\n-- for schedule source\nCREATE TABLE taskiq_schedules (\n    id UUID PRIMARY KEY,\n    task_name VARCHAR(100) NOT NULL,\n    schedule JSONB NOT NULL,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n</code></pre> <p>This is default schemas. So if you changed table names or other parameters, adjust accordingly.</p>"},{"location":"tutorial/common_issues/#driver-import-errors","title":"Driver Import Errors","text":"<p>Install the appropriate driver extra, for example:</p> <pre><code># for asyncpg\npip install taskiq-postgres[asyncpg]\n</code></pre>"},{"location":"tutorial/result_backend/","title":"Result Backend","text":""},{"location":"tutorial/result_backend/#basic-usage","title":"Basic usage","text":"<p>You can store task results in Postgres using one of result backend classes from this package.</p> <p>You can define your broker with result backend like this:</p> <pre><code>import asyncio\nfrom taskiq import TaskiqBroker\n# 1. Import AsyncpgBroker and AsyncpgResultBackend (or other result backend you want to use)\nfrom taskiq_pg.asyncpg import AsyncpgBroker, AsyncpgResultBackend\n\n# 2. Define your broker with result backend\ndsn = \"postgres://taskiq_postgres:look_in_vault@localhost:5432/taskiq_postgres\"\nbroker = AsyncpgBroker(dsn).with_result_backend(AsyncpgResultBackend(dsn=dsn)\n\n# 3. Register task\n@broker.task(task_name=\"answer_for_everything\")\nasync def answer_for_everything() -&gt; None:\n    await asyncio.sleep(2)\n    return 42\n\nasync def main():\n    # 4. Start broker, call task and wait for result\n    await broker.startup()\n    task = await best_task_ever.kiq()\n    print(await task.wait_result())\n    await broker.shutdown()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>After running this code, you should see <code>42</code> printed in the console. Plus the result will be stored in the Postgres database in <code>taskiq_results</code> (by default).</p>"},{"location":"tutorial/result_backend/#customization","title":"Customization","text":"<p>You can customize the result backend by providing additional parameters to the constructor.</p> <ul> <li><code>keep_results</code> - whatever to keep results after they are fetched. Default is <code>True</code>. Suitable if you don't want to store results forever.</li> <li><code>table_name</code> - name of the table to store results in. Default is <code>taskiq_results</code>.</li> <li><code>field_for_task_id</code> - type of the field to store task IDs. Default is <code>VarChar</code>. But you can pick <code>Uuid</code> or <code>Text</code> if you want.</li> <li><code>serializer</code> - serializer to use for serializing results. Default is <code>PickleSerializer</code>. But if you want human readable results you can use <code>JsonSerializer</code> from <code>taskiq.serializers</code> for example.</li> </ul>"},{"location":"tutorial/result_backend/#task-progress","title":"Task progress","text":"<p>You can also store task progress using result backend. To do this, you need to use <code>set_progress</code> method from <code>ProgressTracker</code>:</p> <pre><code>import asyncio\nfrom taskiq import TaskiqBroker\n# 1. Import AsyncpgBroker and AsyncpgResultBackend (or other result backend you want to use)\nfrom taskiq_pg.asyncpg import AsyncpgBroker, AsyncpgResultBackend\n\n# 2. Define your broker with result backend\ndsn = \"postgres://taskiq_postgres:look_in_vault@localhost:5432/taskiq_postgres\"\nbroker = AsyncpgBroker(dsn).with_result_backend(AsyncpgResultBackend(dsn=dsn)\n\n# 3. Register task\n@broker.task(\"solve_all_problems\")\nasync def best_task_ever(\n    progress_tracker: ProgressTracker[Any] = TaskiqDepends(),  # noqa: B008\n) -&gt; int:\n    # 4. Set progress with state\n    state_dict = {\"start_message\": \"Starting to solve problems\"}\n    await progress_tracker.set_progress(TaskState.STARTED, state_dict)\n\n    await asyncio.sleep(2)\n\n    # You can also use custom states, but progress will be rewritten on each call (it's update not merge)\n    state_dict.update({\"halfway_message\": \"Halfway done!\"})\n    await progress_tracker.set_progress(\"halfway\", state_dict)\n    await progress_tracker.set_progress(TaskState.STARTED, state_dict)\n\n    await asyncio.sleep(2)\n\n    return 42\n\nasync def main():\n    # 5. Start broker\n    await broker.startup()\n    task = await best_task_ever.kiq()\n\n    # 6. Check progress on start\n    await asyncio.sleep(1)\n    print(await task.get_progress())\n\n    # 7. Check progress on halfway\n    await asyncio.sleep(2)\n    print(await task.get_progress())\n\n    # 8. Get final result\n    print(await task.wait_result())\n\n    await broker.shutdown()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>If you run this code, you should see something like this in the console:</p> <pre><code>&gt; uv run python -m examples.example_with_progress\n\nstate='STARTED' meta={'start_message': 'Starting to solve problems'}\nstate='STARTED' meta={'start_message': 'Starting to solve problems', 'halfway_message': 'Halfway done!'}\nis_err=False log=None return_value=42 execution_time=4.01 labels={} error=None\n</code></pre>"},{"location":"tutorial/schedule_source/","title":"Schedule Source","text":""},{"location":"tutorial/schedule_source/#basic-usage","title":"Basic usage","text":"<p>The easiest way to schedule task with this library is to add <code>schedule</code> label to task. Schedule source will automatically parse this label and add new schedule to database on start of scheduler.</p> <p>You can define your scheduled task like this:</p> <pre><code>import asyncio\nfrom taskiq import TaskiqScheduler\nfrom taskiq_pg.asyncpg import AsyncpgBroker, AsyncpgScheduleSource\n\n\ndsn = \"postgres://taskiq_postgres:look_in_vault@localhost:5432/taskiq_postgres\"\nbroker = AsyncpgBroker(dsn)\nscheduler = TaskiqScheduler(\n    broker=broker,\n    sources=[AsyncpgScheduleSource(\n        dsn=dsn,\n        broker=broker,\n    )],\n)\n\n\n@broker.task(\n    task_name=\"solve_all_problems\",\n    schedule=[\n        {\n            \"cron\": \"*/1 * * * *\",  # type: str, either cron or time should be specified.\n            \"cron_offset\": None,  # type: str | None, can be omitted. For example \"Europe/Berlin\".\n            \"time\": None,  # type: datetime | None, either cron or time should be specified.\n            \"args\": [], # type list[Any] | None, can be omitted.\n            \"kwargs\": {}, # type: dict[str, Any] | None, can be omitted.\n            \"labels\": {}, # type: dict[str, Any] | None, can be omitted.\n        },\n    ],\n)\nasync def best_task_ever() -&gt; None:\n    \"\"\"Solve all problems in the world.\"\"\"\n    await asyncio.sleep(2)\n    print(\"All problems are solved!\")\n</code></pre>"},{"location":"tutorial/schedule_source/#adding-schedule-in-runtime","title":"Adding schedule in runtime","text":"<p>You can also add schedules in runtime using <code>add_schedule</code> method of the schedule source:</p> <pre><code>import asyncio\nfrom taskiq import TaskiqScheduler, ScheduledTask\nfrom taskiq_pg.asyncpg import AsyncpgBroker, AsyncpgScheduleSource\n\n\ndsn = \"postgres://taskiq_postgres:look_in_vault@localhost:5432/taskiq_postgres\"\nbroker = AsyncpgBroker(dsn)\nschedule_source = AsyncpgScheduleSource(\n    dsn=dsn,\n    broker=broker,\n)\nscheduler = TaskiqScheduler(\n    broker=broker,\n    sources=[schedule_source],\n)\n\n\n@broker.task(\n    task_name=\"solve_all_problems\",\n)\nasync def best_task_ever() -&gt; None:\n    \"\"\"Solve all problems in the world.\"\"\"\n    await asyncio.sleep(2)\n    print(\"All problems are solved!\")\n\n# Call this function somewhere in your code to add new schedule\nasync def add_new_schedule() -&gt; None:\n    await schedule_source.add_schedule(ScheduledTask(...))\n</code></pre>"},{"location":"tutorial/schedule_source/#using-multiple-schedules","title":"Using multiple schedules","text":"<p>You can use multiple schedules for one task. Just provide a list of schedules to the <code>@broker.task</code> decorator:</p> <pre><code>import asyncio\nfrom taskiq import TaskiqScheduler\nfrom taskiq_pg.asyncpg import AsyncpgBroker, AsyncpgScheduleSource\n\n\ndsn = \"postgres://taskiq_postgres:look_in_vault@localhost:5432/taskiq_postgres\"\nbroker = AsyncpgBroker(dsn)\nscheduler = TaskiqScheduler(\n    broker=broker,\n    sources=[AsyncpgScheduleSource(\n        dsn=dsn,\n        broker=broker,\n    )],\n)\n\n\n@broker.task(\n    task_name=\"solve_all_problems\",\n    schedule=[\n        {\n            \"cron\": \"*/1 * * * *\",\n            \"cron_offset\": None,\n            \"time\": None,\n            \"args\": [\"every minute\"],\n            \"kwargs\": {},\n            \"labels\": {},\n        },\n        {\n            \"cron\": \"0 */1 * * *\",\n            \"cron_offset\": None,\n            \"time\": None,\n            \"args\": [\"every hour\"],\n            \"kwargs\": {},\n            \"labels\": {},\n        },\n    ],\n)\nasync def best_task_ever(message: str) -&gt; None:\n    await asyncio.sleep(2)\n    print(f\"I run {message}\")\n</code></pre>"}]}